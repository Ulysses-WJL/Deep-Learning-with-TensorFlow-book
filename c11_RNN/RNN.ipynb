{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2rc1"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ulysses-WJL/Deep-Learning-with-TensorFlow-book/blob/master/c11_RNN/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "xkTnFIAkW6K2",
        "colab_type": "text"
      },
      "source": [
        "# 循环神经网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtb6xnNKW6K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMxIWMDIXRSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "try:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(gpu)\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCxWf4FlXO2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A85EutyOW6K7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers, Model, Input, Sequential, datasets\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26HKII0GW6K-",
        "colab_type": "text"
      },
      "source": [
        "## 序列\n",
        "具有先后顺序的数据一般叫作序列(Sequence). 我们把文字编码为数值的过程叫作**Word Embedding**.\n",
        "\n",
        "one-hot编码的优缺点:\n",
        "- 简单直观，编码过程不需要学习和训练;\n",
        "- 但高维度而且极其稀疏的，大量的位置为0，计算效率较低, 忽略了单词先天具有的语义相关性;\n",
        "\n",
        "余弦相关度(Cosine similarity), 衡量词向量(word vector)之间相关度:\n",
        "$$similarity(a, b) \\triangleq \\frac {a \\cdot b}{|a|\\cdot|b|}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZqDIkZUW6K_",
        "colab_type": "text"
      },
      "source": [
        "### Embedding层\n",
        "单词的表示层叫作Embedding层, 负责把单词编码为某个词向量𝒗\n",
        "\n",
        "$$v = f_{\\theta}(i|N_{vocab}, n)$$\n",
        "单词数量记为$N_{vocab}$, $v的长度为n$, $i$表示单词编号, 如2 表示“I”，3 表示“me”等."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTZ3ccPdW6LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.range(10)  # 代表10个不同单词的编码\n",
        "\n",
        "x = tf.random.shuffle(x)\n",
        "# 10个单词, 每个单词用长度4 的向量表示\n",
        "net = layers.Embedding(10, 4)\n",
        "out = net(x)\n",
        "out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF9TXmNJW6LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRhLx9yuW6LF",
        "colab_type": "text"
      },
      "source": [
        "### 预训练的词向量\n",
        "\n",
        "应用的比较广泛的预训练模型:Word2Vec 和GloVe模型.利用已预训练好的模型参数初始化Embedding层."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imwXtxrCW6LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embed(path):\n",
        "    # 建立映射关系: 单词: 词向量(长度50))\n",
        "    embedding_map = {}\n",
        "    with open(path, encoding='utf8') as f:\n",
        "        for line in f.readlines():\n",
        "            l = line.split()\n",
        "            word = l[0]\n",
        "            coefs = np.asarray(l[1:], dtype='float32')\n",
        "            embedding_map[word] = coefs\n",
        "    return embedding_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rq-q_Kx_W6LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_map = load_embed('glove.6B.50d.txt')\n",
        "print('Found %s word vectors.' % len(embedding_map))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fclqg79YW6LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_map['the']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZk1h3UrW6LP",
        "colab_type": "text"
      },
      "source": [
        "### 20newsgroups 测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjWJdlhXW6LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "# 加载20newsgroups数据集\n",
        "news20 = datasets.fetch_20newsgroups()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP5PdWSDW6LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news20.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7q_oFYkW6LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = news20.target_names  # 一共20类不同的新闻\n",
        "category"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNMLGaKKW6LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = news20['target']  # 每条新闻分属的类别"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaG_cPIGW6Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(news20['data'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bI2FmHzW6Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news20['data'][0], category[news20['target'][0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqq-yWdiW6Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NUM_WORDS = 20000  # 最多保留 20000-1 个不同的单词\n",
        "MAX_SEQUENCE_LENGTH = 1000  # 每个序列长度\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 50  # 用50维向量表示一个单词"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcXoJ-H-W6Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tokenizer?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEb40VbeW6Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vectorize the text samples into a 2D integer tensor\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)  #  Only the most common `num_words-1` words will be kept."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVw1tkxW6Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Updates internal vocabulary based on a list of texts\n",
        "tokenizer.fit_on_texts(news20['data'])\n",
        "sequences = tokenizer.texts_to_sequences(news20['data'])  # 语句 -> 单词序列号组成的sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE__Ah0FW6Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# matrix = tokenizer.texts_to_matrix(news20['data'])\n",
        "# matrix.shape  # (11314, 20000)  稀疏矩阵"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPDn20fbW6L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV7KUTF-W6L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将sequences 转成文本list\n",
        "# tokenizer.sequences_to_texts(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byREgVw4W6L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将单词映射为 index\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "word_index_list = list(word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFZZxT3ZW6L8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 从1开始编码 用0代表填充\n",
        "word_index_list[:10]  # news20group 出现频率最高的10个单词"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRMRLc_UW6L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index_list[19998]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcTce9WEW6MB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pads sequences to the same length.\n",
        "pad_sequences?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQv-ZBWLW6MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 每条新闻都被编码成 等长的 用数字表示的 序列\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At2AFm7PW6MF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3GP2BiBW6MJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(data), np.min(data) # "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Btox64ZW6MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, labels, test_size=VALIDATION_SPLIT, random_state=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IftbvWZLW6MP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c6xPmENW6MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将 单词序号-> 单词向量(长度50)\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "\n",
        "applied_vec_count = 0\n",
        "for word, i in word_index.items():\n",
        "    if i >= MAX_NUM_WORDS:\n",
        "        continue\n",
        "    # 根据glove.6B.50d 将单词转为词向量\n",
        "    embedding_vector = embedding_map.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        applied_vec_count += 1\n",
        "print(applied_vec_count, embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILM_W4J5W6MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new20group中最常用的19999 词向量 + 填充 + unknow\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TttC5yUoW6MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5ZJ33NEW6Ma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers.Embedding?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8KZuGEz4W6Md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    num_words, EMBEDDING_DIM,\n",
        "    weights = [embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LENGTH,\n",
        "    trainable=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vrWbDmrW6Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_input = Input((MAX_SEQUENCE_LENGTH, ), dtype=tf.int32)\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "preds = layers.Dense(len(category), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=sequence_input, outputs=preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpCOtNSXW6Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41OttaBYW6Mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpe1kQB4W6Mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhOdY2nUW6Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=128, epochs=15, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGX2RGhDW6Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.linspace(1, 15, 15), hist.history['loss'], label='loss')\n",
        "plt.plot(np.linspace(1, 15, 15), hist.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgL2hvUGW6Mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.linspace(1, 15, 15), hist.history['accuracy'], label='accuracy')\n",
        "plt.plot(np.linspace(1, 15, 15), hist.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-MsrIVcW6Mw",
        "colab_type": "text"
      },
      "source": [
        "## 循环神经网络\n",
        "\n",
        "\n",
        "$$h_t = \\sigma(W_{xh}x_t + W_{hh}h_{t-1} + b)$$\n",
        "在每个时间戳$t$, 网络层接受当前时间戳的输入$x_t$和上一个时间戳的网络状态向量$h_{t-1}$,经过\n",
        "$$h_t = f_{\\theta}(h_{t-1}, x_t)$$\n",
        "变换后得到当前时间戳的新状态向量$h_t$. 在每个时间戳上, 网络层均有输出$o_t = g_{\\phi}(h_t)$\n",
        "\n",
        "对于这种网络结构，我们把它叫做循环网络结构(Recurrent Neural Network，简称RNN)。\n",
        "\n",
        "在循环神经网络中，激活函数更多地采用tanh 函数.并且可以选择不使用偏执𝒃来进一步减少参数量。\n",
        "\n",
        "状态向量$h_t$可以直接用作输出，即$o_t = h_t$，也可以对$t$做一个简单的线性变换."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7muOX_W6Mx",
        "colab_type": "text"
      },
      "source": [
        "## 梯度传播\n",
        "\n",
        "参数$W_{hh}$的梯度计算\n",
        "$$\\frac {\\partial L}{\\partial W_{hh}} = \\sum_{i=1}^t \\frac {\\partial L}{\\partial o_t}\n",
        "\\frac {\\partial o_t}{\\partial h_t} \\frac {\\partial h_t}{\\partial h_i}\n",
        "\\frac {\\partial^+ h_i}{\\partial W_{hh}}\n",
        "$$\n",
        "其中\n",
        "$$\\frac {\\partial^+ h_i}{\\partial W_{hh}} = \\frac {\\partial \\sigma(W_{xh}x_t + W_{hh}h_{t-1} +b)}{\\partial W_{hh}}$$\n",
        "只考虑一个时间戳的梯度传播, 即\"直接\"偏导数.\n",
        "\n",
        "$$\n",
        "\\frac {\\partial h_t}{\\partial h_i} = \n",
        "\\frac {\\partial h_t}{\\partial h_{t-1}}\n",
        "\\frac {\\partial h_{t-1}}{\\partial h_{t-2}}\n",
        "\\cdots\n",
        "\\frac {\\partial h_{i+1}}{\\partial h_i}\n",
        "= \\prod_{k=i}^{t-1}\\frac {\\partial h_{k+1}}{\\partial h_{k}} $$\n",
        "\n",
        "\n",
        "$$\\frac {\\partial h_{k+1}}{\\partial h_{k}}\n",
        "= W^T_{hh}diag(\\sigma'(h_{k+1}))$$\n",
        "\n",
        "所以$$\\frac {\\partial h_t}{\\partial h_i} = \\prod_{j=i}^{t-1}diag(\\sigma'(W_{xh}x_{j+1} + W_{hh}h_j + b))W_{hh}$$\n",
        "\n",
        "其中包含雅克比矩阵和$W_{hh}$的连乘运算, 容易出现梯度消失(激活函数使用sigmoid或tanh时)或梯度爆炸(使用ReLU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-TEeKfiW6Mx",
        "colab_type": "text"
      },
      "source": [
        "## RNN层的使用\n",
        "\n",
        "- SimpleRNNCell: 完成了一个时间戳的前向运算($\\sigma(W_{xh}x_t + W_{hh}h_{t-1} +b)$)\n",
        "- SimpleRNN: 基于Cell 层实现的，它在内部已经完成了多个时间戳的循环运算，"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyXH4RxRW6Mx",
        "colab_type": "text"
      },
      "source": [
        "### SimpleRNNCell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo4r6xY9W6My",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers.SimpleRNNCell?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ob-YgSW6M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cell = layers.SimpleRNNCell(3)  # 内存向量h长度 3\n",
        "cell.build(input_shape=(None, 4))  # 输入x特征长度4\n",
        "cell.trainable_variables  # W_xh ,  W_hh, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Adm-BEW6M6",
        "colab_type": "text"
      },
      "source": [
        "前向运算\n",
        "$$o_t, [h_t] = Cell(x_t, [h_{t-1})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEZGv0a1W6M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初始化状态向量，用列表包裹，统一格式\n",
        "h0 = [tf.zeros([4, 64])]\n",
        "\n",
        "# (b, word_num, word_vec_length)\n",
        "x = tf.random.normal([4, 80, 100])\n",
        "xt = x[:, 0, :]  # 所有句子的第一个单词\n",
        "\n",
        "cell = layers.SimpleRNNCell(64)\n",
        "out1, h1 = cell(xt, h0)  # h1用list包裹, out1没有经过变换 = h1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srU9XqaaW6M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.shape, h1[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b0uQ6OLW6NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(id(out), id(h1[0]))  # 状态向量直接作为输出向量"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7yAiEVmW6NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = h0\n",
        "for x_t in tf.unstack(x, axis=1):  # 时间维度解开, 按时间输入单词\n",
        "    out, h = cell(x_t, h)\n",
        "out = out  # 只取最后时间戳的输出  N->1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-qe_yN1W6NG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2层循环神经网络\n",
        "x = tf.random.normal([4, 80, 100])\n",
        "xt = x[:, 0, :]\n",
        "cell0 = layers.SimpleRNNCell(64)\n",
        "cell1 = layers.SimpleRNNCell(64)\n",
        "# 2个cell的初始状态\n",
        "h0 = [tf.zeros((4, 64))]\n",
        "h1 = [tf.zeros((4, 64))]\n",
        "\n",
        "# 一个时间戳上完成2层传播在到下一个时间戳\n",
        "for xt in tf.unstack(x, axis=1):\n",
        "    out0, h0 = cell0(xt, h0)\n",
        "    \n",
        "    out1, h1 = cell1(out0, h1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CbdCIdAW6NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 先完成第一层所有时间的传播再完成第二层所有时间的传播\n",
        "middle_seqences = []\n",
        "\n",
        "for xt in tf.unstack(x, axis=1):\n",
        "    out0, h0 = cell0(xt, h0)\n",
        "    middle_seqences.append(out0)\n",
        "\n",
        "for xt in middle_seqences:\n",
        "    out1, h1 = cell1(xt, h1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9ThmjX_W6NJ",
        "colab_type": "text"
      },
      "source": [
        "### SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hawN2tQW6NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SimpleRNN  完成多个时间戳的计算\n",
        "layer = layers.SimpleRNN(64)\n",
        "x = tf.random.normal([4, 80, 100])\n",
        "out = layer(x)\n",
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0LqgjASW6NN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 返回所有时间戳上的输出\n",
        "layer = layers.SimpleRNN(64, return_sequences=True)\n",
        "out = layer(x)\n",
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkKkY8HcW6NQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 多层RNN网络\n",
        "net = Sequential([\n",
        "    # 除最末层外，都需要返回所有时间戳的输出，用作下一层的输入\n",
        "    layers.SimpleRNN(64, return_sequences=True),\n",
        "    layers.SimpleRNN(64, return_sequences=True),\n",
        "    layers.SimpleRNN(64)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfz0UNgIW6NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = net(x)\n",
        "out.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS08pUCgW6NX",
        "colab_type": "text"
      },
      "source": [
        "## RNN情感分类\n",
        "imdb评分>7 为1 positive; IMDB 评级<5 的用户评价标注为0 \n",
        "\n",
        "利用第2 层RNN 层的最后时间戳的状态向量h, 作为句子的全局语义特征表示, 送入全连接分类网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqobmBYhW6Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "TOTAL_WORDS = 10000  # 词汇表大小\n",
        "MAX_REVIEW_LEN = 80  # 句子长度\n",
        "EMBEDDING_LEN = 100  # 词向量长度"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCGKucsdW6Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets.imdb.load_data?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbTscrRZW6Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imdb数据集\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.imdb.load_data(\n",
        "    num_words=TOTAL_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBf6sxuqW6Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape, len(X_train[0]), y_train.shape)  # X 不等长的list 组成的array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5U2sbIOW6Nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_test.shape, len(X_test[0]), y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAbEvtjkW6Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 编码表\n",
        "word_index = datasets.imdb.get_word_index()\n",
        "\n",
        "pre_10 = list(word_index.items())[:10]\n",
        "for item in pre_10:  \n",
        "    print(item)  # 单词-数字"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY_bN6BGW6Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'total {len(word_index)} unique words')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMA8mCFvW6Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 添加标志位\n",
        "word_index = {k:(v+3) for k, v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0  # 表示填充\n",
        "word_index[\"<START>\"] = 1  # 表示起始\n",
        "word_index[\"<UNK>\"] = 2  # 表示未知单词\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# 翻转\n",
        "index_word = dict([(v, k) for k, v in word_index.items()]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrylgJzgW6Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_review(text):\n",
        "    # 数字序列 -> 文本\n",
        "    return ' '.join([index_word.get(i, '?') for i in text])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBkiJPryW6Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 截断 填充 成等长的序列\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_REVIEW_LEN)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_REVIEW_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zBbCr0LW6N1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_review(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20qJtuseW6N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decode_review(X_test[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGzdVgr0W6N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_db = tf.data.Dataset.from_tensor_slices(  # 舍弃最后一组 \n",
        "    (X_train, y_train)).shuffle(1000).batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_db = tf.data.Dataset.from_tensor_slices(\n",
        "    (X_test, y_test)).shuffle(1000).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HiMFQALW6N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_db))\n",
        "sample[0], sample[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1FclLW1W6N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_map = load_embed('glove.6B.100d.txt')\n",
        "print('Found %s word vectors.' % len(embedding_map))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcPJweEVW6OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将 单词序号-> 单词向量(长度50)\n",
        "num_words = min(TOTAL_WORDS, len(word_index))\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_LEN))\n",
        "\n",
        "applied_vec_count = 0\n",
        "for word, i in word_index.items():\n",
        "    if i >= TOTAL_WORDS:\n",
        "        continue\n",
        "    # 根据glove.6B.50d 将单词转为词向量\n",
        "    embedding_vector = embedding_map.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        applied_vec_count += 1\n",
        "print(applied_vec_count, embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6CB8AWkW6OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyRNN(Model):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        # 初始状态向量\n",
        "        self.state0 = [tf.zeros([BATCH_SIZE, units])]\n",
        "        self.state1 = [tf.zeros([BATCH_SIZE, units])]\n",
        "        # 词嵌入层\n",
        "        self.embedding = layers.Embedding(TOTAL_WORDS, EMBEDDING_LEN,\n",
        "                                          input_length=MAX_REVIEW_LEN,\n",
        "#                                           weights=[embedding_matrix],\n",
        "#                                          trainable=False\n",
        "                                         )\n",
        "        # RNNCell\n",
        "#         self.runcell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
        "#         self.runcell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
        "        # RNN layer\n",
        "        self.rnn = Sequential([\n",
        "            layers.SimpleRNN(units, dropout=0.5, return_sequences=True),\n",
        "            layers.SimpleRNN(units, dropout=0.5)\n",
        "        ])\n",
        "        # 分类层\n",
        "        self.out_layer = Sequential([\n",
        "            layers.Dense(32, activation='relu'),\n",
        "            layers.Dropout(rate=0.5),\n",
        "            layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        \n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.embedding(inputs)\n",
        "        state0, state1 = self.state0, self.state1\n",
        "#         for word in tf.unstack(x, axis=1):\n",
        "#             out0, state0 = self.runcell0(word, state0, training)\n",
        "#             out1, state1 = self.runcell1(out0, state1, training)\n",
        "        out1 = self.rnn(x)\n",
        "        # 最末层 最后一个时间戳的输出\n",
        "        out = self.out_layer(out1, training)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FImaiSTNW6OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyRNN(64)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(10e-3),\n",
        "             loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "             metrics=['accuracy'],\n",
        "#              experimental_run_tf_function=False  # 以cell方式运行需要设置\n",
        "             )  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meQH4x37W6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.build((None, MAX_REVIEW_LEN))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTpdL2oOW6OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "R8zkbKS8W6OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_db, epochs=10, validation_data=test_db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNuBAPQW6OL",
        "colab_type": "text"
      },
      "source": [
        "## 梯度弥散和梯度爆炸\n",
        "梯度下降\n",
        "$$\\theta := \\theta - \\eta\\nabla_{\\theta} L$$\n",
        "\n",
        "- 梯度弥散(Gradient Vanishing): $\\nabla_{\\theta} L \\approx 0$, 每次梯度更新后参数基本保持不变, ℒ几乎保持不变，其它评测指标，如准确度，也保持不变\n",
        "- 梯度爆炸(Gradient Exploding): $\\nabla_{\\theta} L \\gg 1$, 梯度更新的步长很大, 更新后的$\\theta$变化很大, L出现突变现象，甚至可能出现来回震荡、不收敛的现象"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFdA81wW6OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.ones([2, 2])\n",
        "eigenvalues = tf.linalg.eigh(W)[0]  # 获取特征值\n",
        "eigenvalues"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf3WaCpYW6ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 多次连乘\n",
        "val = [W]\n",
        "for _ in range(10):\n",
        "    val.append(val[-1]@W)\n",
        "\n",
        "# L2范数\n",
        "norm = list(map(lambda x:tf.norm(x).numpy(), val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvwA8awPW6OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(norm)\n",
        "plt.xlabel('n times')\n",
        "plt.ylabel('L2-norm')\n",
        "# Gradient Exploding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n9pXmtjW6OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.ones([2, 2]) * 0.4\n",
        "eigenvalues = tf.linalg.eigh(W)[0]  # 获取特征值\n",
        "# 多次连乘\n",
        "val = [W]\n",
        "for _ in range(10):\n",
        "    val.append(val[-1]@W)\n",
        "\n",
        "# L2范数\n",
        "norm = list(map(lambda x:tf.norm(x).numpy(), val))\n",
        "plt.plot(norm)\n",
        "plt.xlabel('n times')\n",
        "plt.ylabel('L2-norm')\n",
        "# Gradient Vanishing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4YEdrlCW6Oa",
        "colab_type": "text"
      },
      "source": [
        "### 梯度裁剪(Gradient Clipping)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qgn2YwQW6Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 简单裁剪, 直接对张量的数值进行限幅\n",
        "\n",
        "a = tf.random.uniform([2, 2])\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL-sOFWjW6Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.clip_by_value(a, 0.4, 0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1HSMoG1W6Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}