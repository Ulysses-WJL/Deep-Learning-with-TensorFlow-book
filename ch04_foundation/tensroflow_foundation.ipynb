{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "tf",
   "display_name": "tf"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TesorFlow 基础\n",
    "\n",
    "\n",
    "TensorFlow 是一个面向深度学习算法的科学计算库，内部数据保存在张量(Tensor)对象上，所有的运算操作(Operation，简称 OP)也都是基于张量对象进行的。复杂的神经网络算法本质上就是各种张量相乘、相加等基本运算操作的组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, datasets, preprocessing\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Default parameters for plots\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "matplotlib.rcParams['figure.titlesize'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 7]\n",
    "matplotlib.rcParams['font.family'] = ['STKaiTi']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False \n",
    "\n",
    "np.set_printoptions(threshold=16, suppress=True, precision=4)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 数据类型\n",
    "### 1.1数值类型\n",
    "\n",
    "数值类型的张量是 TensorFlow 的主要数据载体，根据维度数来区分，可分为：\n",
    "- 标量(scalar): 单个的实数，如 1.2, 3.4 等，维度(Dimension)数为 0，shape 为[]\n",
    "- 向量(vector): 𝑛个实数的有序集合，通过中括号包裹，如\\[1.2\\]，\\[1.2, 3.4\\]等，维度数为1，长度不定，shape为\\[n\\]\n",
    "- 张量(Tensor): 所有维度数dim > 2的数组统称为张量. 张量的每个维度也作轴(axis), 一般维度代表了具体的物理含义.\n",
    "  \\[2, 32, 32, 3\\] -> 2张图片,高宽均为32,有RGB3个通道\n",
    "\n",
    "在 TensorFlow 中间，为了表达方便，一般把标量、向量、矩阵也统称为张量，不作区分，需要根据张量的维度数或形状自行判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(float, tensorflow.python.framework.ops.EagerTensor, True)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量\n",
    "a = 2.4\n",
    "aa = tf.constant(1.2)  # 需要使用tf的方式创建张量, 否则不能使用tf的功能函数\n",
    "type(a), type(aa), tf.is_tensor(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向量\n",
    "a = tf.constant([1, 2])  # 向量的定义须通过 List 容器传给constant()函数\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1. , 2.1], dtype=float32)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([1, 2.1])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1. , 2.1], dtype=float32)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()  # 返回numpy类型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n array([[1, 2],\n        [3, 4]], dtype=int32)>,\n TensorShape([2, 2]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义矩阵\n",
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\narray([[[1, 2],\n        [3, 4]],\n\n       [[5, 6],\n        [7, 8]]], dtype=int32)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3维的张量\n",
    "a = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 字符串(String)类型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello, TensorFlow'>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = tf.constant('Hello, TensorFlow')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=string, numpy=b'hello, tensorflow'>,\n <tf.Tensor: shape=(), dtype=string, numpy=b'HELLO, TENSORFLOW'>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.lower(s), tf.strings.upper(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'Hello,', b'TensorFlow'], dtype=object)>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.split(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 布尔(Boolean)类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant([True, False])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow 的bool类型与python的bool类型不等价\n",
    "a is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == True  # 数值比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 数值精度\n",
    "对于数值类型的张量，可以保存为不同字节长度的精度,位越长，精度越高，同时占用的内存空间也就越大。常用的精度类型有 tf.int16、tf.int32、tf.int64、tf.float16、tf.float32、tf.float64(tf.double)等，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=int16, numpy=-13035>,\n <tf.Tensor: shape=(), dtype=int32, numpy=123456789>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 制定数值的精度\n",
    "a = tf.constant(123456789, dtype=tf.int16)  # -32768 ~ +32767\n",
    "b = tf.constant(123456789, dtype=tf.int32)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1415927>,\n <tf.Tensor: shape=(), dtype=float64, numpy=3.141592653589793>)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pi_1 = tf.constant(np.pi, dtype=tf.float32)\n",
    "pi_2 = tf.constant(np.pi, dtype=tf.float64)\n",
    "pi_1, pi_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分深度学习算法，一般使用 tf.int32 和 tf.float32 可满足大部分场合的运算精度要求(默认都是int32与float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "before: <dtype: 'float32'>\nafter: <dtype: 'float64'> tf.Tensor(3.1415927410125732, shape=(), dtype=float64)\n"
    }
   ],
   "source": [
    "# dtype 成员属性可以判断张量的保存精度\n",
    "\n",
    "print('before:', pi_1.dtype)\n",
    "if pi_1.dtype != tf.float64:\n",
    "    pi_1 = tf.cast(pi_1, tf.float64)  # 转化精度\n",
    "print('after:', pi_1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=3.140625>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类型转换 \n",
    "# 低->高\n",
    "a = tf.constant(np.pi, dtype=tf.float16)\n",
    "tf.cast(a, tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int16, numpy=-13035>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高 ->低　溢出风险\n",
    "a = tf.constant(123456789, tf.int32)\n",
    "tf.cast(a, tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0], dtype=int32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bool -> int\n",
    "a = tf.constant([True, False])\n",
    "tf.cast(a, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True, False,  True])>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int -> bool\n",
    "a = tf.constant([1, -1, 0, 2])  # 0 为False 其他皆为True\n",
    "tf.cast(a, tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 待优化的张量\n",
    "为了区分需要计算梯度信息的张量与不需要计算梯度信息的张量，TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录：tf.Variable. 它在普通张量类型基础上添加了name, trainable等属性来支持计算图的构建.\n",
    "\n",
    "对于不需要的优化的张量，如神经网络的输入𝑿，不需要通过 tf.Variable 封装；相反，对于需要计算梯度并优化的张量，如神经网络层的𝑾和𝒃，需要通过 tf.Variable 包裹以便 TensorFlow 跟踪相关梯度信息。\n",
    "通过 tf.Variable()函数可以将普通张量转换为待优化张量，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, -1, 2, 0])\n",
    "aa = tf.Variable(a)  # 转为Variable类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Variable:0'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.name  # 用于命名计算图中的变量, 内部维护"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.trainable  # 表征当前张量是否需要被优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\narray([[1, 2],\n       [3, 4]], dtype=int32)>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接创建tf.Variable类型\n",
    "a = tf.Variable([[1, 2], [3, 4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "待优化张量可视为普通张量的特殊类型，普通张量其实也可以通过`GradientTape.watch()`方法临时加入跟踪梯度信息的列表，从而支持自动求导功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 创建张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从数组 列表 创建\n",
    "tf.convert_to_tensor([1, 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\narray([[1., 2.],\n       [3., 4.]])>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从numpy数组中创建\n",
    "\n",
    "tf.convert_to_tensor(np.array([[1, 2.], [3, 4.]]))  # numpy 浮点型默认float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全零向量\n",
    "tf.zeros([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\narray([[[1., 1., 1.],\n        [1., 1., 1.]],\n\n       [[1., 1., 1.],\n        [1., 1., 1.]]], dtype=float32)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全1向量\n",
    "tf.ones([2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[0, 0],\n       [0, 0]], dtype=int32)>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])\n",
    "tf.zeros_like(a)  # 与某个张量一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[1, 1],\n       [1, 1]], dtype=int32)>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[11, 11],\n       [11, 11]], dtype=int32)>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义数值的张量\n",
    "\n",
    "tf.fill([2, 2], 11)  # 2行2列 数值都为11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 0.33070412, -1.2998165 , -0.9255365 ],\n       [-1.2821348 , -0.93905365, -1.1543428 ]], dtype=float32)>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定概率分布\n",
    "# 正态分布 均值0 标准差1 shape: (2, 3)\n",
    "tf.random.normal([2, 3], mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(6,), dtype=float32, numpy=\narray([0.8141229 , 0.2862265 , 0.4847622 , 0.07810807, 0.58806574,\n       0.13367999], dtype=float32)>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采样自[0, 1]的均匀分布\n",
    "\n",
    "tf.random.uniform([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[9.619311, 9.898686],\n       [9.006266, 9.290047]], dtype=float32)>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采样自区间[0,10)，shape 为[2,2]的矩阵\n",
    "tf.random.uniform([2, 2], maxval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[22, 48],\n       [ 3, 13]], dtype=int32)>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 类型为整数\n",
    "tf.random.uniform([2, 2], maxval=100, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建序列\n",
    "tf.range(10)  # np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8], dtype=int32)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10, delta=2)  # 指定步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 张量的典型应用\n",
    "---\n",
    "### 标量\n",
    "标量是简单的数字, 维度数为0, shape为[].典型用途是表示各种`误差值`, `测量指标`, 如精确度(Accuracy, acc), 查准度(Precisoin)和查全率(Recall).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=0.36886328>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tf.random.uniform([4, 10])  # 随机模拟网络输出\n",
    "y = tf.constant([2, 3, 2, 0])  # 随机构造样本真实标签\n",
    "y = tf.one_hot(y, depth=10)  # one-hot编码处理\n",
    "loss = tf.keras.losses.mse(y, out)  # 计算每个样本的MSE\n",
    "loss = tf.reduce_mean(loss)  # 平均MSE\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量\n",
    "\n",
    "向量是一种非常常见的数据载体，如在全连接层和卷积神经网络层中，偏置张量𝒃就使用向量来表示.\n",
    "\n",
    "例: 2个输出节点的网络层, 创建长度为2的偏置向量**b**, 并累加在每个输出节点上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\narray([[ 1.2154839 , -0.13426471],\n       [-0.1373093 ,  0.83707845],\n       [ 1.8495959 , -0.5648319 ],\n       [-0.5233701 ,  1.2768668 ]], dtype=float32)>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z = wx , 模拟z\n",
    "z = tf.random.normal([4, 2])\n",
    "b = tf.zeros([2])\n",
    "z = z + b  # 累加偏置向量\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一层网络层 张量𝑾和𝒃存储在类的内部，由类自动创建和管理\n",
    "fc = layers.Dense(3)  # 创建一层Wx + b, 输出节点为3个\n",
    "# 通过 build 函数创建 W,b 张量，输入节点为 4\n",
    "fc.build(input_shape=(2, 4))\n",
    "fc.bias  # 查看偏置向量\n",
    "# 类型为Variable(待优化), 向量的值初始化为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵\n",
    "\n",
    "例如全连接层的批量输入张量$X$的形状为$[b, d_{in}]$, b表示输入样本的个数(Batch size), $d_{in}$表示输入特征的长度.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[-0.07032794, -0.07032794, -0.07032794],\n       [-2.0724502 , -2.0724502 , -2.0724502 ]], dtype=float32)>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 线性变换网络层, 激活函数为空\n",
    "X = tf.random.normal([2, 4])  # 2个样本, 特征长度4\n",
    "w = tf.ones([4, 3])\n",
    "b = tf.zeros([3])\n",
    "\n",
    "out = X@w + b\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X 和 w张量都是矩阵. 。一般地，$\\sigma(X@W + b)$网络层称为`全连接层`，在 TensorFlow 中可以通过`Dense`类直接实现，特别地，当激活函数𝜎为空时，全连接层也称为`线性层`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\narray([[ 0.59064364,  0.9121344 ,  0.6652602 ],\n       [-0.55234253,  0.15975511,  0.26595378],\n       [-0.11956185,  0.77510226, -0.0103429 ],\n       [ 0.8747679 , -0.36924678, -0.4446111 ]], dtype=float32)>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = layers.Dense(3) # 定义全连接层的输出节点为 3\n",
    "fc.build(input_shape=(2,4)) # 定义全连接层的输入节点为 4\n",
    "fc.kernel # 查看权值矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三维张量\n",
    "三维张量的一个典型应用是表示`序列信号`, 格式是:\n",
    "$$X = [b, sequence \\; len, feature \\; len]$$\n",
    "\n",
    "其中𝑏表示序列信号的数量，sequence len 表示序列信号在时间维度上的采样点数或步数，feature len 表示每个点的特征长度.\n",
    "\n",
    "考虑自然语言处理(Natural Language Processing，简称 NLP)中句子的表示，如评价句子的是否为正面情绪的情感分类任务网络。为了能够方便字符串被神经网络处理，一般将单词通过嵌入层(Embedding Layer)编码为固定长度的向量，比如“a”编码为某个长度 3 的向量，那么 2 个等长(单词数量为 5)的句子序列可以表示为 shape 为\\[2,5,3\\]的 3 维张量，其中 2 示句子个数，5 表示单词数量，3 表示单词向量的长度\n",
    "\n",
    "![](./情感分类网络.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb 电影评价数据集\n",
    "(X_train, y_train), *_ = datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n       ...,\n       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n      dtype=object)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将句子填充 截断为等长的80个单词的句子\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(25000, 80)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape  # (句子个数, 每个句子单词数)每个单词用数字编码的方式表示 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tf.keras.layers.Embedding(\n",
    "    input_dim, output_dim, embeddings_initializer='uniform',\n",
    "    embeddings_regularizer=None, activity_regularizer=None,\n",
    "    embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- input_dim: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "- output_dim: int >= 0. Dimension of the dense embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建词向量 embedding层\n",
    "embedding = layers.Embedding(10000, 100)  # 每个单词都编码成长度100的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([25000, 80, 100])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = embedding(X_train)\n",
    "out.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四维张量\n",
    "四维张量在卷积神经网络中应用非常广泛，它用于保存`特征图`(Feature maps)数据，格式一般定义为\n",
    "$$[b, h, w, c]$$\n",
    "b表示输入样本的数量, h/w分别表示特征图的高/宽, c表示特征图的通道数.部分深度学习框架也会使用\\[𝑏, 𝑐, ℎ, w\\]格式的特征图张量，例如 PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 30, 30, 16])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 32x32彩色图片, 数量为4\n",
    "X = tf.random.normal([4, 32, 32, 3])\n",
    "# 创建卷积神经网络\n",
    "layer = layers.Conv2D(16, kernel_size=3)\n",
    "out = layer(X)  # 前向计算\n",
    "out.shape  # 输出大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([3, 3, 3, 16])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel.shape  # 卷积核张量 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引与切片\n",
    "\n",
    "与numpy中的索引和切片类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.normal([4, 32, 32, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 3), dtype=float32, numpy=\narray([[ 0.38626292,  0.48458055,  0.9753598 ],\n       [ 0.6152168 , -0.8783054 ,  1.1422373 ],\n       [ 1.5227828 ,  1.3751835 , -0.72983044],\n       [-0.6166592 ,  0.49567157, -0.5693984 ],\n       [-1.3355407 , -0.9289913 , -1.8335633 ],\n       [-1.1912423 ,  0.01054767, -1.4341239 ],\n       [ 0.30111122,  0.15251623, -0.3987652 ],\n       [-0.29142419,  0.611255  ,  0.16753303],\n       [-0.10661095, -0.55688256, -2.7441502 ],\n       [-0.99143326, -0.13468826, -0.0131203 ],\n       [ 0.50020736, -1.2164325 ,  1.9222027 ],\n       [ 0.95121336, -0.94877595,  0.56226194],\n       [-0.21165627, -1.1136016 , -1.2494175 ],\n       [-1.0335566 ,  0.773933  ,  0.05813967],\n       [-0.9157892 , -0.95739913, -0.07989726],\n       [ 0.5002486 ,  1.5189123 ,  1.4757575 ],\n       [-0.60369754,  0.36891344, -0.14120743],\n       [-1.7896798 ,  0.6288549 ,  1.5512767 ],\n       [-2.5050373 ,  0.5114778 ,  0.8379579 ],\n       [ 1.8362858 ,  0.35752925,  0.9732094 ],\n       [ 0.4081019 ,  1.6997422 ,  0.05624337],\n       [-0.6384228 , -0.66695845, -3.4149184 ],\n       [ 0.70528543,  1.0975934 , -0.56032896],\n       [ 0.07649989,  0.19975507, -0.15706956],\n       [-0.9232116 , -0.41649118, -1.2484378 ],\n       [-0.07918338,  1.1392806 ,  1.3567704 ],\n       [-0.5208137 , -1.6868236 ,  0.6707898 ],\n       [ 0.5644851 ,  0.5037961 , -0.20826899],\n       [ 0.12396188,  1.1647896 , -0.11373389],\n       [ 0.43765298, -1.007331  ,  0.34443325],\n       [ 1.201403  , -1.0205604 , -1.046515  ],\n       [ 0.8112357 ,  0.5972995 , -1.6848481 ]], dtype=float32)>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][-1]  # 第一张图片 最后一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=-0.8416042>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 1, 2, 1]  # 第一张图片, 2行3列B通道 颜色强度值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 3), dtype=float32, numpy=\narray([[[-0.1756,  1.4343,  0.3572],\n        [-1.8175, -0.8416,  1.6837],\n        [-2.1726,  0.3714,  0.4909],\n        [ 1.4304,  1.4152, -0.6769]],\n\n       [[ 0.1144,  1.5118,  0.1508],\n        [ 1.3896,  1.543 , -1.93  ],\n        [-0.8983, -0.5082,  0.7367],\n        [ 0.7095, -1.0134, -0.1436]]], dtype=float32)>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start: end: step\n",
    "X[0, 1:3, :8:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32), dtype=float32, numpy=\narray([[[-1.0976, -1.6566,  0.6943, ...,  0.7708, -1.412 ,  0.3265],\n        [ 1.4343, -0.1896, -0.8416, ...,  0.8973,  1.2024,  1.2788],\n        [ 1.5118,  0.0038,  1.543 , ..., -1.2033, -0.9243,  1.0292],\n        ...,\n        [-0.7541, -2.0584,  2.4961, ...,  0.7793, -0.9003, -0.9882],\n        [-0.4767, -0.9161, -0.8443, ..., -0.7434,  0.9984,  0.0643],\n        [ 0.4846, -0.8783,  1.3752, ..., -1.0073, -1.0206,  0.5973]],\n\n       [[ 0.0845, -1.3828, -0.1253, ..., -0.6026, -0.9142, -1.0079],\n        [ 0.1749,  0.6091,  0.7482, ..., -0.0227, -0.3177, -0.3681],\n        [ 1.2783, -0.3136,  1.6343, ...,  0.1607, -1.0614, -0.1347],\n        ...,\n        [-0.3303, -0.685 ,  1.6297, ...,  1.6337,  1.3217,  1.5199],\n        [-0.8877, -0.0002, -1.9721, ..., -1.4153,  0.046 ,  1.7619],\n        [ 0.9173, -2.0606,  0.6922, ..., -0.1284,  1.2786, -0.2942]]],\n      dtype=float32)>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用⋯符号表示取多个维度上所有的数据，其中维度的数量需根据规则自动推断\n",
    "X[0:2, ..., 1]  # 高和宽全部采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=\narray([[[[ 0.4494,  0.8135, -0.7077],\n         [ 0.6427,  0.8531,  1.9176],\n         [ 0.59  ,  0.3249, -0.7983],\n         ...,\n         [ 0.632 ,  0.2936,  1.186 ],\n         [-1.3732,  0.4363,  0.8158],\n         [ 0.6319,  1.6061, -0.61  ]],\n\n        [[-1.0711, -1.3315, -0.4079],\n         [ 0.2425, -0.4494, -0.2964],\n         [-0.0149, -0.9606, -0.3528],\n         ...,\n         [ 1.0203, -0.4396,  0.9588],\n         [ 1.3297,  0.67  ,  2.0149],\n         [-0.2295, -0.4115, -0.2137]],\n\n        [[ 0.4033, -0.7814, -0.2517],\n         [ 0.544 , -1.4219, -0.7449],\n         [-0.2854,  0.726 , -1.0103],\n         ...,\n         [ 1.8681,  0.4935, -0.3727],\n         [-0.7118,  0.0807,  3.0895],\n         [-0.103 , -0.183 , -0.2882]],\n\n        ...,\n\n        [[ 2.0299, -0.0994, -1.8217],\n         [-0.7688, -0.5339, -1.3172],\n         [ 1.1124, -0.8966, -0.3222],\n         ...,\n         [-1.7915, -0.102 ,  1.0022],\n         [-0.4167, -1.3346,  0.2084],\n         [ 1.9049, -1.3921,  1.5586]],\n\n        [[-0.2847,  1.2162, -1.0917],\n         [ 0.9528,  0.4289, -1.0166],\n         [-0.2161, -0.6173,  0.7961],\n         ...,\n         [-0.5066, -0.5906, -0.2719],\n         [-1.1225, -0.9709, -0.5916],\n         [-2.1387,  0.0508,  0.3846]],\n\n        [[-0.7528,  0.0087, -1.5872],\n         [ 0.4964, -1.3278,  1.4105],\n         [-1.3062,  0.7542, -0.371 ],\n         ...,\n         [ 0.2183,  1.22  ,  0.3608],\n         [-0.3679,  0.9869,  0.1917],\n         [ 0.0699, -2.1463, -1.4648]]],\n\n\n       [[[ 0.2297,  0.8235,  0.7952],\n         [-1.8491,  0.7634, -0.3802],\n         [-0.8339, -0.1602,  0.3158],\n         ...,\n         [-0.7405, -0.5101,  0.3173],\n         [ 1.4968, -1.8411, -0.1381],\n         [-0.2787,  1.1644, -0.3478]],\n\n        [[ 0.5699, -0.9441, -0.1736],\n         [-1.1933,  0.9403, -0.6194],\n         [ 1.1149,  0.4244,  0.3633],\n         ...,\n         [-0.65  , -0.4937, -0.4437],\n         [-0.7006, -1.3006, -0.5345],\n         [-1.5592,  0.2351, -0.5692]],\n\n        [[-0.7727, -0.5805,  1.6148],\n         [ 0.0148, -1.9884,  0.202 ],\n         [ 0.0679,  0.7925,  0.442 ],\n         ...,\n         [ 0.3506, -0.6404,  2.1088],\n         [-1.9379, -0.4549,  0.8977],\n         [ 2.4779,  1.0048, -0.8226]],\n\n        ...,\n\n        [[-0.6342,  0.1579, -0.2746],\n         [ 0.9008, -1.5341,  0.3385],\n         [-1.5438,  0.9765, -0.6768],\n         ...,\n         [-0.1284,  1.3095,  1.2761],\n         [ 0.3229,  0.2944,  0.7502],\n         [-1.4142, -1.4365, -0.7149]],\n\n        [[ 0.2914,  0.7033, -0.3469],\n         [ 0.8029, -0.7146,  0.0434],\n         [ 0.1108,  0.133 ,  0.991 ],\n         ...,\n         [-1.1958, -1.1235, -0.7268],\n         [ 0.455 ,  0.018 ,  1.5978],\n         [-1.1311, -0.3651,  0.5586]],\n\n        [[-0.8445,  0.4575, -0.0171],\n         [ 2.1965,  1.4456,  2.0179],\n         [-1.5148,  1.2228,  0.7913],\n         ...,\n         [ 1.577 ,  0.2711, -1.219 ],\n         [-0.3355,  1.6145,  1.1187],\n         [-0.1234,  0.917 ,  1.1012]]]], dtype=float32)>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-2:, ...]  # 最后2张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 32, 32, 2), dtype=float32, numpy=\narray([[[[-0.9676, -1.0976],\n         [ 0.3849, -1.6566],\n         [-0.9155,  0.6943],\n         ...,\n         [ 0.8401,  0.7708],\n         [ 0.1111, -1.412 ],\n         [ 0.1091,  0.3265]],\n\n        [[-0.1756,  1.4343],\n         [-1.7394, -0.1896],\n         [-1.8175, -0.8416],\n         ...,\n         [ 0.1745,  0.8973],\n         [ 0.0008,  1.2024],\n         [-0.5203,  1.2788]],\n\n        [[ 0.1144,  1.5118],\n         [ 1.6678,  0.0038],\n         [ 1.3896,  1.543 ],\n         ...,\n         [ 0.4403, -1.2033],\n         [-0.0553, -0.9243],\n         [-0.9238,  1.0292]],\n\n        ...,\n\n        [[ 1.142 , -0.7541],\n         [-0.5814, -2.0584],\n         [ 1.2934,  2.4961],\n         ...,\n         [ 0.0072,  0.7793],\n         [-0.098 , -0.9003],\n         [-1.2378, -0.9882]],\n\n        [[-1.3678, -0.4767],\n         [-0.4042, -0.9161],\n         [ 1.7686, -0.8443],\n         ...,\n         [-0.6023, -0.7434],\n         [ 1.4283,  0.9984],\n         [-0.7412,  0.0643]],\n\n        [[ 0.3863,  0.4846],\n         [ 0.6152, -0.8783],\n         [ 1.5228,  1.3752],\n         ...,\n         [ 0.4377, -1.0073],\n         [ 1.2014, -1.0206],\n         [ 0.8112,  0.5973]]],\n\n\n       [[[ 0.2042,  0.0845],\n         [-0.5337, -1.3828],\n         [ 0.4417, -0.1253],\n         ...,\n         [-0.3678, -0.6026],\n         [ 0.6046, -0.9142],\n         [-0.0988, -1.0079]],\n\n        [[-1.2971,  0.1749],\n         [ 0.1526,  0.6091],\n         [-0.6774,  0.7482],\n         ...,\n         [-0.5669, -0.0227],\n         [ 0.7106, -0.3177],\n         [-0.1887, -0.3681]],\n\n        [[ 0.766 ,  1.2783],\n         [-0.8204, -0.3136],\n         [-1.2575,  1.6343],\n         ...,\n         [-1.1165,  0.1607],\n         [-1.63  , -1.0614],\n         [-0.6018, -0.1347]],\n\n        ...,\n\n        [[ 0.5817, -0.3303],\n         [ 2.1459, -0.685 ],\n         [-1.3933,  1.6297],\n         ...,\n         [ 2.0846,  1.6337],\n         [ 2.4965,  1.3217],\n         [ 0.0968,  1.5199]],\n\n        [[-1.1478, -0.8877],\n         [-0.0713, -0.0002],\n         [ 0.225 , -1.9721],\n         ...,\n         [-0.6599, -1.4153],\n         [ 0.6481,  0.046 ],\n         [ 1.0635,  1.7619]],\n\n        [[ 0.0986,  0.9173],\n         [ 0.4289, -2.0606],\n         [ 0.6747,  0.6922],\n         ...,\n         [ 1.2905, -0.1284],\n         [ 0.0327,  1.2786],\n         [-1.6098, -0.2942]]],\n\n\n       [[[ 0.4494,  0.8135],\n         [ 0.6427,  0.8531],\n         [ 0.59  ,  0.3249],\n         ...,\n         [ 0.632 ,  0.2936],\n         [-1.3732,  0.4363],\n         [ 0.6319,  1.6061]],\n\n        [[-1.0711, -1.3315],\n         [ 0.2425, -0.4494],\n         [-0.0149, -0.9606],\n         ...,\n         [ 1.0203, -0.4396],\n         [ 1.3297,  0.67  ],\n         [-0.2295, -0.4115]],\n\n        [[ 0.4033, -0.7814],\n         [ 0.544 , -1.4219],\n         [-0.2854,  0.726 ],\n         ...,\n         [ 1.8681,  0.4935],\n         [-0.7118,  0.0807],\n         [-0.103 , -0.183 ]],\n\n        ...,\n\n        [[ 2.0299, -0.0994],\n         [-0.7688, -0.5339],\n         [ 1.1124, -0.8966],\n         ...,\n         [-1.7915, -0.102 ],\n         [-0.4167, -1.3346],\n         [ 1.9049, -1.3921]],\n\n        [[-0.2847,  1.2162],\n         [ 0.9528,  0.4289],\n         [-0.2161, -0.6173],\n         ...,\n         [-0.5066, -0.5906],\n         [-1.1225, -0.9709],\n         [-2.1387,  0.0508]],\n\n        [[-0.7528,  0.0087],\n         [ 0.4964, -1.3278],\n         [-1.3062,  0.7542],\n         ...,\n         [ 0.2183,  1.22  ],\n         [-0.3679,  0.9869],\n         [ 0.0699, -2.1463]]],\n\n\n       [[[ 0.2297,  0.8235],\n         [-1.8491,  0.7634],\n         [-0.8339, -0.1602],\n         ...,\n         [-0.7405, -0.5101],\n         [ 1.4968, -1.8411],\n         [-0.2787,  1.1644]],\n\n        [[ 0.5699, -0.9441],\n         [-1.1933,  0.9403],\n         [ 1.1149,  0.4244],\n         ...,\n         [-0.65  , -0.4937],\n         [-0.7006, -1.3006],\n         [-1.5592,  0.2351]],\n\n        [[-0.7727, -0.5805],\n         [ 0.0148, -1.9884],\n         [ 0.0679,  0.7925],\n         ...,\n         [ 0.3506, -0.6404],\n         [-1.9379, -0.4549],\n         [ 2.4779,  1.0048]],\n\n        ...,\n\n        [[-0.6342,  0.1579],\n         [ 0.9008, -1.5341],\n         [-1.5438,  0.9765],\n         ...,\n         [-0.1284,  1.3095],\n         [ 0.3229,  0.2944],\n         [-1.4142, -1.4365]],\n\n        [[ 0.2914,  0.7033],\n         [ 0.8029, -0.7146],\n         [ 0.1108,  0.133 ],\n         ...,\n         [-1.1958, -1.1235],\n         [ 0.455 ,  0.018 ],\n         [-1.1311, -0.3651]],\n\n        [[-0.8445,  0.4575],\n         [ 2.1965,  1.4456],\n         [-1.5148,  1.2228],\n         ...,\n         [ 1.577 ,  0.2711],\n         [-0.3355,  1.6145],\n         [-0.1234,  0.917 ]]]], dtype=float32)>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[..., :2]  # 所有图片前2个通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度变换\n",
    "---\n",
    "张量的存储(Storage)和视图(View):\n",
    "- 视图就是我们理解张量的方式\n",
    "- 存储体现在张量在内存上保存为一段连续的内存区域\n",
    "- 同一个存储, 从不同角度观察数据可以产生不同的视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4, 4, 3), dtype=int32, numpy=\narray([[[[ 0,  1,  2],\n         [ 3,  4,  5],\n         [ 6,  7,  8],\n         [ 9, 10, 11]],\n\n        [[12, 13, 14],\n         [15, 16, 17],\n         [18, 19, 20],\n         [21, 22, 23]],\n\n        [[24, 25, 26],\n         [27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44],\n         [45, 46, 47]]],\n\n\n       [[[48, 49, 50],\n         [51, 52, 53],\n         [54, 55, 56],\n         [57, 58, 59]],\n\n        [[60, 61, 62],\n         [63, 64, 65],\n         [66, 67, 68],\n         [69, 70, 71]],\n\n        [[72, 73, 74],\n         [75, 76, 77],\n         [78, 79, 80],\n         [81, 82, 83]],\n\n        [[84, 85, 86],\n         [87, 88, 89],\n         [90, 91, 92],\n         [93, 94, 95]]]], dtype=int32)>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape 改变视图  numpy reshape\n",
    "\n",
    "X = tf.range(96)\n",
    "X = tf.reshape(X, [2, 4, 4, 3])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在存储数据时，内存并不支持这个维度层级概念，只能以平铺方式按序写入内存. 在优先写入小维度的设定下，上述张量的内存布局为\n",
    "\n",
    "0, 1, 2, 3, ..., 95\n",
    "\n",
    "在通过 reshape 改变视图时，必须始终记住张量的存储顺序，新视图的维度顺序不能与存储顺序相悖，否则需要通过交换维度操作将存储顺序同步过来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(4, TensorShape([2, 4, 4, 3]))"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim, X.shape  # 获取维度和形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 24), dtype=int32, numpy=\narray([[ 0,  1,  2, ..., 21, 22, 23],\n       [24, 25, 26, ..., 45, 46, 47],\n       [48, 49, 50, ..., 69, 70, 71],\n       [72, 73, 74, ..., 93, 94, 95]], dtype=int32)>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(X, [4, -1])  # -1当前轴上长度需要根据张量总元素不变的法则自动推导，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28), dtype=int32, numpy=\narray([[227,  14,  78, ...,  22,  49, 208],\n       [ 60,   8, 147, ..., 105,   7,  15],\n       [ 63, 191, 251, ..., 147, 206, 139],\n       ...,\n       [193, 186, 231, ..., 251, 212, 183],\n       [ 84,  71, 155, ..., 201, 207, 227],\n       [229, 205, 187, ...,  59,  71, 136]], dtype=int32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加维度  增加一个长度为 1 的维度相当于给原有的数据添加一个新维度的概念\n",
    "# 28x28的灰度图片\n",
    "x = tf.random.uniform([28, 28], maxval=255, dtype=tf.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28, 1), dtype=int32, numpy=\narray([[[227],\n        [ 14],\n        [ 78],\n        ...,\n        [ 22],\n        [ 49],\n        [208]],\n\n       [[ 60],\n        [  8],\n        [147],\n        ...,\n        [105],\n        [  7],\n        [ 15]],\n\n       [[ 63],\n        [191],\n        [251],\n        ...,\n        [147],\n        [206],\n        [139]],\n\n       ...,\n\n       [[193],\n        [186],\n        [231],\n        ...,\n        [251],\n        [212],\n        [183]],\n\n       [[ 84],\n        [ 71],\n        [155],\n        ...,\n        [201],\n        [207],\n        [227]],\n\n       [[229],\n        [205],\n        [187],\n        ...,\n        [ 59],\n        [ 71],\n        [136]]], dtype=int32)>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(x, axis=2)  # axis=2 表示宽维度后面的一个维度\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 28, 28, 1), dtype=int32, numpy=\narray([[[[227],\n         [ 14],\n         [ 78],\n         ...,\n         [ 22],\n         [ 49],\n         [208]],\n\n        [[ 60],\n         [  8],\n         [147],\n         ...,\n         [105],\n         [  7],\n         [ 15]],\n\n        [[ 63],\n         [191],\n         [251],\n         ...,\n         [147],\n         [206],\n         [139]],\n\n        ...,\n\n        [[193],\n         [186],\n         [231],\n         ...,\n         [251],\n         [212],\n         [183]],\n\n        [[ 84],\n         [ 71],\n         [155],\n         ...,\n         [201],\n         [207],\n         [227]],\n\n        [[229],\n         [205],\n         [187],\n         ...,\n         [ 59],\n         [ 71],\n         [136]]]], dtype=int32)>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(x, axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "axis 为正时，表示在当前维度之前插入一个新维度；为负时，表示当前维度之后插入一个新的维度\n",
    "\n",
    "![](./增加维度.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28, 1), dtype=int32, numpy=\narray([[[227],\n        [ 14],\n        [ 78],\n        ...,\n        [ 22],\n        [ 49],\n        [208]],\n\n       [[ 60],\n        [  8],\n        [147],\n        ...,\n        [105],\n        [  7],\n        [ 15]],\n\n       [[ 63],\n        [191],\n        [251],\n        ...,\n        [147],\n        [206],\n        [139]],\n\n       ...,\n\n       [[193],\n        [186],\n        [231],\n        ...,\n        [251],\n        [212],\n        [183]],\n\n       [[ 84],\n        [ 71],\n        [155],\n        ...,\n        [201],\n        [207],\n        [227]],\n\n       [[229],\n        [205],\n        [187],\n        ...,\n        [ 59],\n        [ 71],\n        [136]]], dtype=int32)>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除维度只能删除长度为 1 的维度，\n",
    "x = tf.squeeze(x, axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(28, 28), dtype=int32, numpy=\narray([[227,  14,  78, ...,  22,  49, 208],\n       [ 60,   8, 147, ..., 105,   7,  15],\n       [ 63, 191, 251, ..., 147, 206, 139],\n       ...,\n       [193, 186, 231, ..., 251, 212, 183],\n       [ 84,  71, 155, ..., 201, 207, 227],\n       [229, 205, 187, ...,  59,  71, 136]], dtype=int32)>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.squeeze(x, axis=2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8, 8), dtype=float32, numpy=\narray([[0.0162, 0.8471, 0.3252, ..., 0.0686, 0.8832, 0.1266],\n       [0.1285, 0.9692, 0.2529, ..., 0.5457, 0.2686, 0.8352],\n       [0.7545, 0.0208, 0.6539, ..., 0.5697, 0.6033, 0.9746],\n       ...,\n       [0.2471, 0.9987, 0.9648, ..., 0.4483, 0.3133, 0.7795],\n       [0.0709, 0.8017, 0.9218, ..., 0.0332, 0.8879, 0.0278],\n       [0.3776, 0.4904, 0.1002, ..., 0.3115, 0.7275, 0.3854]],\n      dtype=float32)>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不指定维度参数 axis，即 tf.squeeze(x)，那么它会默认删除所有长度为 1 的维度\n",
    "x = tf.random.uniform([1, 8, 8, 1])\n",
    "tf.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3, 32, 32), dtype=float32, numpy=\narray([[[[ 1.6445, -0.2121, -1.0621, ...,  1.121 ,  0.9723,  1.4606],\n         [ 0.868 , -0.4396, -1.2934, ...,  1.777 ,  0.8638,  2.306 ],\n         [ 0.003 ,  0.0575,  1.9425, ...,  2.4887, -0.7341,  0.8839],\n         ...,\n         [-0.0633,  0.8911,  0.3263, ...,  0.2943, -0.3763, -2.0715],\n         [-0.1403, -1.203 , -0.8123, ..., -0.4894, -1.0556, -1.6299],\n         [-1.7972, -1.2354, -0.1114, ...,  1.2531, -1.6232,  0.8396]],\n\n        [[-0.9919,  0.1023,  1.4613, ..., -1.6071,  1.4713, -2.1798],\n         [ 0.3426,  0.6119,  0.5327, ..., -0.4732, -1.1353,  0.1271],\n         [-0.9392,  1.004 ,  0.2645, ...,  0.8801, -0.2601,  0.4133],\n         ...,\n         [-1.2034, -0.7826, -0.9239, ..., -0.2851, -1.1869,  0.2215],\n         [-2.3126, -0.8373,  1.0206, ...,  0.8212, -0.3453, -2.0803],\n         [ 0.5528, -0.6221, -1.6782, ..., -2.0969,  0.1865, -0.3055]],\n\n        [[-0.6711,  0.3085, -0.5608, ..., -1.8704,  0.3606, -0.8953],\n         [ 1.6784,  0.5808, -0.1662, ...,  0.4201, -0.8203,  0.0734],\n         [-0.7683, -0.3484, -0.0868, ...,  1.4526, -0.5221,  1.3409],\n         ...,\n         [ 0.7294, -0.5022, -2.2663, ...,  1.2613,  0.7938, -1.529 ],\n         [-0.4625, -0.271 , -1.3552, ..., -0.0768,  0.1188, -1.0853],\n         [ 1.0534, -0.7027, -0.1518, ..., -0.2991, -1.4643,  1.5654]]],\n\n\n       [[[-0.1636,  0.1352,  0.9479, ...,  0.5299, -0.1556, -2.2035],\n         [-0.7369, -0.3928, -0.4362, ...,  0.4891, -0.9871,  2.0788],\n         [-1.2321,  2.3606,  0.9821, ...,  0.01  , -0.4505,  0.8018],\n         ...,\n         [-0.293 ,  0.0775,  0.088 , ..., -1.9124,  2.0119,  0.5721],\n         [-3.4679, -1.4528,  1.5238, ..., -0.8345,  1.5752,  0.6385],\n         [-0.6081,  1.2572,  0.2895, ...,  0.8539, -1.6428, -0.0225]],\n\n        [[ 0.1168, -1.9001,  0.4037, ...,  0.159 , -0.2319,  0.104 ],\n         [-0.0972, -0.1505,  1.9076, ...,  0.2949, -0.1547, -0.451 ],\n         [ 1.1614,  0.3322,  0.2948, ..., -1.5235,  0.4544,  1.9234],\n         ...,\n         [ 2.8428,  0.0436, -0.1547, ..., -0.2101, -0.197 , -0.2533],\n         [-0.7709,  0.8262,  0.9583, ..., -0.6464, -0.2529, -0.3246],\n         [-1.0657,  0.2993,  0.1073, ...,  0.3205, -0.3429,  1.072 ]],\n\n        [[ 0.8165, -1.0459,  0.7252, ...,  0.7422, -0.8703,  0.1185],\n         [-1.0295,  1.0324,  1.6434, ...,  0.4995,  0.2517, -0.1517],\n         [-0.9437, -0.046 ,  0.1351, ..., -0.6582,  0.4488, -1.861 ],\n         ...,\n         [ 2.3939, -1.316 , -0.1081, ...,  0.8991, -0.352 ,  1.1353],\n         [-1.1717,  2.3534, -1.5631, ...,  1.441 , -2.3683,  0.9379],\n         [-0.8145, -0.2935,  0.4689, ...,  0.6929,  0.8689, -0.0257]]]],\n      dtype=float32)>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交换维度 transpose\n",
    "x = tf.random.normal([2, 32, 32, 3])  # b, h, w, c -> b, c, h, w\n",
    "tf.transpose(x, perm=[0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.transpose 完成维度交换后，张量的存储顺序已经改变，视图也随之改变，后续的所有操作必须基于新的存续顺序和视图进行。相对于改变视图操作，维度交换操作的计算代价更高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[1, 2, 3]], dtype=int32)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 复制数据\n",
    "b = tf.constant([1, 2, 3])  # (3, )\n",
    "b = tf.expand_dims(b, axis=0)  # 插入新维度 -> (1, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\narray([[1, 2, 3],\n       [1, 2, 3]], dtype=int32)>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.tile(b, multiples=[2, 1])  # 0轴复制一次 1轴不复制\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\narray([[0, 1],\n       [2, 3]], dtype=int32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动实现插入维度\n",
    "\n",
    "x = tf.range(4)\n",
    "x = tf.reshape(x, [2, 2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\narray([[0, 1],\n       [2, 3],\n       [0, 1],\n       [2, 3]], dtype=int32)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(x, multiples=[2, 1])  # 行复制一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\narray([[0, 1, 0, 1],\n       [2, 3, 2, 3]], dtype=int32)>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(x, multiples=[1, 2])  # 列复制一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\narray([[0, 1, 0, 1],\n       [2, 3, 2, 3],\n       [0, 1, 0, 1],\n       [2, 3, 2, 3]], dtype=int32)>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(x, [2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting 广播(自动扩展)\n",
    "\n",
    "类似numpy 中的广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 1.6466,  0.5488,  3.4398],\n       [ 1.0131,  2.4012, -0.0811]], dtype=float32)>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2, 4])\n",
    "w = tf.random.normal([4, 3])\n",
    "b = tf.random.normal([3])\n",
    "\n",
    "y = x @ w + b  # broadcasting\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[ 1.6466,  0.5488,  3.4398],\n       [ 1.0131,  2.4012, -0.0811]], dtype=float32)>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x @ w + tf.broadcast_to(b, [2,3])# 手动广播\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting 机制的核心思想是普适性，即同一份数据能普遍适合于其他位置。在验证普适性之前，需要先将张量 shape 靠右对齐，然后进行普适性判断：对于长度为 1 的维度，默认这个数据普遍适合于当前维度的其他位置；对于不存在的维度，则在增加新维度后默认当前数据也是普适于新维度的，从而可以扩展为更多维度数、任意长度的张量形状\n",
    "\n",
    "广播成功的例子:\n",
    "\n",
    "![](./广播成功.png)\n",
    "\n",
    "广播失败的例子:\n",
    "\n",
    "![](./广播失败.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学运算\n",
    "--- \n",
    "加、减、乘、除是最基本的数学运算，分别通过 tf.add, tf.subtract, tf.multiply, tf.divide函数实现，TensorFlow 已经重载了+、 − 、 ∗ 、/运算符. 整除和取余数: //, %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 1, 2], dtype=int32)>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(5)\n",
    "b = tf.constant(2)\n",
    "a // b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 1, 0], dtype=int32)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a % b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 1,  8, 27], dtype=int32)>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乘方 power\n",
    "x = tf.range(1, 4)\n",
    "tf.pow(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 4, 9], dtype=int32)>,\n <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 4, 9], dtype=int32)>)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x ** 2 , tf.square(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开方\n",
    "x = tf.constant([1., 4., 9.])\n",
    "x ** (0.5), tf.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 4., 8.], dtype=float32)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指数 tf.pow , ** \n",
    "x = tf.constant([1., 2, 3])\n",
    "2 ** x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=2.7182817>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自然指数 e\n",
    "tf.exp(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自然对数\n",
    "x = tf.exp(3.)\n",
    "tf.math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 换底公式log10(x)\n",
    "x = tf.constant([1., 2.])\n",
    "x = 10 ** x\n",
    "tf.math.log(x) / tf.math.log(10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  矩阵乘法\n",
    "TensorFlow 中的矩阵相乘可以使用批量方式，也就是张量𝑨和𝑩的维度数可以大于 2。当张量𝑨和𝑩维度数大于 2 时，TensorFlow 会选择𝑨和𝑩的最后两个维度进行矩阵相乘，前面所有的维度都视作Batch 维度。\n",
    "\n",
    "根据矩阵相乘的定义，𝑨和𝑩能够矩阵相乘的条件是，𝑨的倒数第一个维度长度(列)和𝑩的倒数第二个维度长度(行)必须相等。比如张量 a shape:\\[4,3,28,32\\]可以与张量 bshape:\\[4,3,32,2\\]进行矩阵相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 3, 28, 2), dtype=float32, numpy=\narray([[[[ -1.0934,   2.2801],\n         [  7.191 ,  -4.5564],\n         [  5.615 ,  -0.7883],\n         ...,\n         [ -5.4651, -18.2195],\n         [  1.4142,   1.4663],\n         [ -1.1554,   1.713 ]],\n\n        [[  2.5084,  -4.3073],\n         [  4.7264,   9.0906],\n         [  0.2972,   9.9935],\n         ...,\n         [ 13.4975,  -7.6285],\n         [  1.6347,   3.6777],\n         [  3.311 ,  -9.0082]],\n\n        [[  3.1924,   6.1756],\n         [ -3.6798,  12.1598],\n         [  3.6036,  -4.7887],\n         ...,\n         [  2.2526,   2.4374],\n         [ -0.6003,   8.3296],\n         [ -8.5861,   7.0863]]],\n\n\n       [[[  4.4293,   1.147 ],\n         [  3.6171,   5.3617],\n         [ 10.7696,   0.8449],\n         ...,\n         [  6.4209,   6.9002],\n         [  6.4495,   6.3447],\n         [ -1.5835,   4.6992]],\n\n        [[  3.0381,   3.4137],\n         [ -4.5553,   3.6361],\n         [ -3.4704,  -3.2785],\n         ...,\n         [  1.2236,  -4.6076],\n         [  8.0657,   2.2008],\n         [  6.7475,  -9.3116]],\n\n        [[ -3.4222,   2.3745],\n         [  0.5884,  11.817 ],\n         [  6.5467,  -1.0322],\n         ...,\n         [  3.2023,  -1.6419],\n         [  4.5564,  -7.8335],\n         [  9.933 ,  -4.1094]]],\n\n\n       [[[  3.0546,   3.6826],\n         [ -2.0884,   1.7004],\n         [ -2.6613,  -0.751 ],\n         ...,\n         [ -5.1646,   7.612 ],\n         [ -1.0209,   7.5943],\n         [ -4.252 ,  -7.7034]],\n\n        [[  2.1462,  -3.979 ],\n         [  2.6541,   6.3256],\n         [ 10.0295,   4.7876],\n         ...,\n         [  1.1298,  -0.4751],\n         [ 18.587 ,   5.1403],\n         [  3.013 ,   7.9275]],\n\n        [[ -5.3654,   0.9556],\n         [ -1.0362,  -1.6778],\n         [  2.2467,  -8.0838],\n         ...,\n         [ -5.2743,   1.6186],\n         [ -8.1768,   5.2064],\n         [  0.4849,  -3.4544]]],\n\n\n       [[[ -2.4122,  -0.263 ],\n         [ -3.0638,   6.6072],\n         [  5.9438,   8.3495],\n         ...,\n         [  5.1732,  -3.9244],\n         [ -9.0572,   1.4014],\n         [  0.7876,   1.5975]],\n\n        [[-10.2856,  -0.5561],\n         [ -1.6112,  -0.4504],\n         [ -5.0974,  -7.1571],\n         ...,\n         [  7.2643,  -4.47  ],\n         [ -0.4408,   0.3155],\n         [  0.8482,  -0.3668]],\n\n        [[  7.4087,  -0.1004],\n         [  4.4797,   2.4929],\n         [ -2.346 ,  -7.4076],\n         ...,\n         [  7.5688,  -0.5353],\n         [ -3.8206,   5.8859],\n         [ -2.1591,  -1.9346]]]], dtype=float32)>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4, 3, 28, 32])\n",
    "b = tf.random.normal([4, 3, 32, 2])\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 3, 16), dtype=float32, numpy=\narray([[[  2.9606,   2.2013,   0.0198, ...,   7.1217,  -7.1193,\n           2.0865],\n        [  5.6084,  10.2564,  -6.916 , ...,   0.1774,   2.428 ,\n          -1.0326],\n        [  0.3027,  -7.7884,   4.1111, ...,   4.1389,  -4.255 ,\n           2.0816]],\n\n       [[ -0.9867,  -2.1044,  -2.3265, ...,  -8.6665,   9.8111,\n          -0.9919],\n        [ -8.6593,   6.3916,   3.2853, ...,  11.795 ,  -7.6118,\n          -8.131 ],\n        [  4.2047,  -0.7984,   8.431 , ...,  -0.3777,  -3.4946,\n           2.0063]],\n\n       [[  9.9131,   2.8745,  -6.1947, ...,   9.8241,   6.1531,\n          -0.6255],\n        [  6.9507, -12.186 ,   6.8275, ..., -16.4829,  -2.0571,\n           1.3972],\n        [  1.1048,   2.4879,  -5.5001, ...,   6.224 ,   0.3461,\n          -7.3151]],\n\n       [[ -0.8993,   1.2174,  -7.5666, ...,   3.2458, -10.0192,\n           3.5283],\n        [  0.6466,  -4.6528,   2.4219, ...,   0.9483,  -0.5631,\n          -9.5658],\n        [ -0.5276,   4.6382,  -2.0319, ...,  -2.8188,   5.2267,\n           6.6509]]], dtype=float32)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法的自动广播\n",
    "\n",
    "a = tf.random.normal([4, 3, 32])\n",
    "b = tf.random.normal([32, 16])\n",
    "tf.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播实战\n",
    "\n",
    "创建三层神经网络:\n",
    "$$ out = ReLU\\{ReLU\\{ReLU[X@W_1+b_1]@W_2 + b_2\\}@W_3 + b_3\\}$$\n",
    "输入节点784(28*28), 第一层输出256, 第二层输出128, 第三层输出10(10类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), _ = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(28, 28)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(X, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.float32, tf.int32)>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每步梯度下降取处理128张图片\n",
    "train_db = tf.data.Dataset.from_tensor_slices((X,y)).batch(128)\n",
    "train_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每层w使用截断正态分布\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "# 偏置b初始化为0\n",
    "b1 = tf.Variable(tf.zeros([256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epoch:0, step:0, loss:0.4660964906215668\nepoch:0, step:200, loss:0.19841830432415009\nepoch:0, step:400, loss:0.16902323067188263\nepoch:1, step:0, loss:0.14736661314964294\nepoch:1, step:200, loss:0.15791429579257965\nepoch:1, step:400, loss:0.1429259479045868\nepoch:2, step:0, loss:0.12623052299022675\nepoch:2, step:200, loss:0.13699081540107727\nepoch:2, step:400, loss:0.12663671374320984\nepoch:3, step:0, loss:0.11241404712200165\nepoch:3, step:200, loss:0.12284965813159943\nepoch:3, step:400, loss:0.11558668315410614\nepoch:4, step:0, loss:0.10262427479028702\nepoch:4, step:200, loss:0.11268937587738037\nepoch:4, step:400, loss:0.10737975686788559\nepoch:5, step:0, loss:0.09523322433233261\nepoch:5, step:200, loss:0.10495035350322723\nepoch:5, step:400, loss:0.10104880481958389\nepoch:6, step:0, loss:0.08938302099704742\nepoch:6, step:200, loss:0.09882988035678864\nepoch:6, step:400, loss:0.09600754827260971\nepoch:7, step:0, loss:0.08464780449867249\nepoch:7, step:200, loss:0.0938461571931839\nepoch:7, step:400, loss:0.09189482033252716\nepoch:8, step:0, loss:0.08077947795391083\nepoch:8, step:200, loss:0.08973335474729538\nepoch:8, step:400, loss:0.08844859898090363\nepoch:9, step:0, loss:0.07751395553350449\nepoch:9, step:200, loss:0.08620648086071014\nepoch:9, step:400, loss:0.08550514280796051\nepoch:10, step:0, loss:0.07469278573989868\nepoch:10, step:200, loss:0.0831359401345253\nepoch:10, step:400, loss:0.08297554403543472\nepoch:11, step:0, loss:0.07225258648395538\nepoch:11, step:200, loss:0.08046997338533401\nepoch:11, step:400, loss:0.0807533860206604\nepoch:12, step:0, loss:0.07012633979320526\nepoch:12, step:200, loss:0.07811679691076279\nepoch:12, step:400, loss:0.07878700643777847\nepoch:13, step:0, loss:0.06824759393930435\nepoch:13, step:200, loss:0.07600660622119904\nepoch:13, step:400, loss:0.0770246759057045\nepoch:14, step:0, loss:0.0665697306394577\nepoch:14, step:200, loss:0.07409408688545227\nepoch:14, step:400, loss:0.07541413605213165\nepoch:15, step:0, loss:0.06505925953388214\nepoch:15, step:200, loss:0.07236579805612564\nepoch:15, step:400, loss:0.0739363506436348\nepoch:16, step:0, loss:0.06367869675159454\nepoch:16, step:200, loss:0.07079102843999863\nepoch:16, step:400, loss:0.07258282601833344\nepoch:17, step:0, loss:0.06242866441607475\nepoch:17, step:200, loss:0.0693509429693222\nepoch:17, step:400, loss:0.0713326558470726\nepoch:18, step:0, loss:0.061287544667720795\nepoch:18, step:200, loss:0.06803172826766968\nepoch:18, step:400, loss:0.07016732543706894\nepoch:19, step:0, loss:0.06023407727479935\nepoch:19, step:200, loss:0.0668240338563919\nepoch:19, step:400, loss:0.0690813809633255\nfindfont: Font family ['STKaiTi'] not found. Falling back to DejaVu Sans.\n"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"444.6325pt\" version=\"1.1\" viewBox=\"0 0 591.4875 444.6325\" width=\"591.4875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 444.6325 \nL 591.4875 444.6325 \nL 591.4875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 82.0875 387.72 \nL 584.2875 387.72 \nL 584.2875 7.2 \nL 82.0875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3b3e0cc27e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"104.914773\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(98.552273 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.295358\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(169.570358 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.675944\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(246.950944 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"337.056529\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(324.331529 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"414.437115\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(401.712115 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"491.8177\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(479.0927 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"569.198286\" xlink:href=\"#m3b3e0cc27e\" y=\"387.72\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(556.473286 409.916875)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(302.565625 433.273125)scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0c0e31349a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"379.146411\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.05 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(30.55625 386.744849)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"336.530088\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.10 -->\n      <g transform=\"translate(30.55625 344.128526)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"293.913766\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.15 -->\n      <g transform=\"translate(30.55625 301.512203)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"251.297443\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.20 -->\n      <g transform=\"translate(30.55625 258.89588)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"208.68112\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.25 -->\n      <g transform=\"translate(30.55625 216.279557)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"166.064797\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.30 -->\n      <g transform=\"translate(30.55625 173.663234)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"123.448474\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.35 -->\n      <g transform=\"translate(30.55625 131.046912)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"80.832151\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.40 -->\n      <g transform=\"translate(30.55625 88.430589)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"82.0875\" xlink:href=\"#m0c0e31349a\" y=\"38.215828\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.45 -->\n      <g transform=\"translate(30.55625 45.814266)scale(0.2 -0.2)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- MSE -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n      <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n     </defs>\n     <g transform=\"translate(22.396875 218.755312)rotate(-90)scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"149.755859\" xlink:href=\"#DejaVuSans-69\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc7168ea186)\" d=\"M 104.914773 24.496364 \nL 112.652831 252.645564 \nL 120.39089 277.699763 \nL 128.128948 296.158271 \nL 135.867007 287.168202 \nL 143.605065 299.943167 \nL 151.343124 314.17312 \nL 159.081183 305.001838 \nL 166.819241 313.826912 \nL 174.5573 325.949268 \nL 182.295358 317.05472 \nL 190.033417 323.245146 \nL 197.771475 334.29335 \nL 205.509534 325.714598 \nL 213.247592 330.240126 \nL 220.985651 340.592937 \nL 228.72371 332.310771 \nL 236.461768 335.636164 \nL 244.199827 345.57922 \nL 251.937885 337.527412 \nL 259.675944 339.932961 \nL 267.414002 349.615171 \nL 275.152061 341.775171 \nL 282.890119 343.438347 \nL 290.628178 352.912248 \nL 298.366237 345.280622 \nL 306.104295 346.375653 \nL 313.842354 355.695539 \nL 321.580412 348.28667 \nL 329.318471 348.884439 \nL 337.056529 358.100097 \nL 344.794588 350.903773 \nL 352.532646 351.040483 \nL 360.270705 360.179943 \nL 368.008763 353.176047 \nL 375.746822 352.934487 \nL 383.484881 361.992199 \nL 391.222939 355.181721 \nL 398.960998 354.610484 \nL 406.699056 363.593504 \nL 414.437115 356.980293 \nL 422.175173 356.112565 \nL 429.913232 365.023591 \nL 437.65129 358.610383 \nL 445.389349 357.485271 \nL 453.127408 366.311006 \nL 460.865466 360.08345 \nL 468.603525 358.744826 \nL 476.341583 367.487696 \nL 484.079642 361.425668 \nL 491.8177 359.898471 \nL 499.555759 368.553132 \nL 507.293817 362.653091 \nL 515.031876 360.964024 \nL 522.769935 369.525738 \nL 530.507993 363.777492 \nL 538.246052 361.957266 \nL 545.98411 370.423636 \nL 553.722169 364.806842 \nL 561.460227 362.882845 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    <defs>\n     <path d=\"M -3 3 \nL 3 3 \nL 3 -3 \nL -3 -3 \nz\n\" id=\"mb00a2ea2a4\" style=\"stroke:#1f77b4;stroke-linejoin:miter;\"/>\n    </defs>\n    <g clip-path=\"url(#pc7168ea186)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"104.914773\" xlink:href=\"#mb00a2ea2a4\" y=\"24.496364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"112.652831\" xlink:href=\"#mb00a2ea2a4\" y=\"252.645564\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"120.39089\" xlink:href=\"#mb00a2ea2a4\" y=\"277.699763\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"128.128948\" xlink:href=\"#mb00a2ea2a4\" y=\"296.158271\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"135.867007\" xlink:href=\"#mb00a2ea2a4\" y=\"287.168202\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"143.605065\" xlink:href=\"#mb00a2ea2a4\" y=\"299.943167\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"151.343124\" xlink:href=\"#mb00a2ea2a4\" y=\"314.17312\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"159.081183\" xlink:href=\"#mb00a2ea2a4\" y=\"305.001838\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"166.819241\" xlink:href=\"#mb00a2ea2a4\" y=\"313.826912\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"174.5573\" xlink:href=\"#mb00a2ea2a4\" y=\"325.949268\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"182.295358\" xlink:href=\"#mb00a2ea2a4\" y=\"317.05472\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"190.033417\" xlink:href=\"#mb00a2ea2a4\" y=\"323.245146\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"197.771475\" xlink:href=\"#mb00a2ea2a4\" y=\"334.29335\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"205.509534\" xlink:href=\"#mb00a2ea2a4\" y=\"325.714598\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"213.247592\" xlink:href=\"#mb00a2ea2a4\" y=\"330.240126\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"220.985651\" xlink:href=\"#mb00a2ea2a4\" y=\"340.592937\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"228.72371\" xlink:href=\"#mb00a2ea2a4\" y=\"332.310771\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"236.461768\" xlink:href=\"#mb00a2ea2a4\" y=\"335.636164\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"244.199827\" xlink:href=\"#mb00a2ea2a4\" y=\"345.57922\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"251.937885\" xlink:href=\"#mb00a2ea2a4\" y=\"337.527412\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"259.675944\" xlink:href=\"#mb00a2ea2a4\" y=\"339.932961\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"267.414002\" xlink:href=\"#mb00a2ea2a4\" y=\"349.615171\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"275.152061\" xlink:href=\"#mb00a2ea2a4\" y=\"341.775171\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"282.890119\" xlink:href=\"#mb00a2ea2a4\" y=\"343.438347\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"290.628178\" xlink:href=\"#mb00a2ea2a4\" y=\"352.912248\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"298.366237\" xlink:href=\"#mb00a2ea2a4\" y=\"345.280622\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"306.104295\" xlink:href=\"#mb00a2ea2a4\" y=\"346.375653\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"313.842354\" xlink:href=\"#mb00a2ea2a4\" y=\"355.695539\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"321.580412\" xlink:href=\"#mb00a2ea2a4\" y=\"348.28667\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"329.318471\" xlink:href=\"#mb00a2ea2a4\" y=\"348.884439\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"337.056529\" xlink:href=\"#mb00a2ea2a4\" y=\"358.100097\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"344.794588\" xlink:href=\"#mb00a2ea2a4\" y=\"350.903773\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"352.532646\" xlink:href=\"#mb00a2ea2a4\" y=\"351.040483\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"360.270705\" xlink:href=\"#mb00a2ea2a4\" y=\"360.179943\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"368.008763\" xlink:href=\"#mb00a2ea2a4\" y=\"353.176047\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"375.746822\" xlink:href=\"#mb00a2ea2a4\" y=\"352.934487\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"383.484881\" xlink:href=\"#mb00a2ea2a4\" y=\"361.992199\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"391.222939\" xlink:href=\"#mb00a2ea2a4\" y=\"355.181721\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"398.960998\" xlink:href=\"#mb00a2ea2a4\" y=\"354.610484\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"406.699056\" xlink:href=\"#mb00a2ea2a4\" y=\"363.593504\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"414.437115\" xlink:href=\"#mb00a2ea2a4\" y=\"356.980293\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"422.175173\" xlink:href=\"#mb00a2ea2a4\" y=\"356.112565\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"429.913232\" xlink:href=\"#mb00a2ea2a4\" y=\"365.023591\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"437.65129\" xlink:href=\"#mb00a2ea2a4\" y=\"358.610383\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"445.389349\" xlink:href=\"#mb00a2ea2a4\" y=\"357.485271\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"453.127408\" xlink:href=\"#mb00a2ea2a4\" y=\"366.311006\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"460.865466\" xlink:href=\"#mb00a2ea2a4\" y=\"360.08345\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"468.603525\" xlink:href=\"#mb00a2ea2a4\" y=\"358.744826\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"476.341583\" xlink:href=\"#mb00a2ea2a4\" y=\"367.487696\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"484.079642\" xlink:href=\"#mb00a2ea2a4\" y=\"361.425668\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"491.8177\" xlink:href=\"#mb00a2ea2a4\" y=\"359.898471\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"499.555759\" xlink:href=\"#mb00a2ea2a4\" y=\"368.553132\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"507.293817\" xlink:href=\"#mb00a2ea2a4\" y=\"362.653091\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"515.031876\" xlink:href=\"#mb00a2ea2a4\" y=\"360.964024\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"522.769935\" xlink:href=\"#mb00a2ea2a4\" y=\"369.525738\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"530.507993\" xlink:href=\"#mb00a2ea2a4\" y=\"363.777492\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"538.246052\" xlink:href=\"#mb00a2ea2a4\" y=\"361.957266\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"545.98411\" xlink:href=\"#mb00a2ea2a4\" y=\"370.423636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"553.722169\" xlink:href=\"#mb00a2ea2a4\" y=\"364.806842\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"561.460227\" xlink:href=\"#mb00a2ea2a4\" y=\"362.882845\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 82.0875 387.72 \nL 82.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 584.2875 387.72 \nL 584.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 82.0875 387.72 \nL 584.2875 387.72 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 82.0875 7.2 \nL 584.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 482.28125 52.55625 \nL 570.2875 52.55625 \nQ 574.2875 52.55625 574.2875 48.55625 \nL 574.2875 21.2 \nQ 574.2875 17.2 570.2875 17.2 \nL 482.28125 17.2 \nQ 478.28125 17.2 478.28125 21.2 \nL 478.28125 48.55625 \nQ 478.28125 52.55625 482.28125 52.55625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 486.28125 33.396875 \nL 526.28125 33.396875 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <g>\n      <use style=\"fill:#1f77b4;stroke:#1f77b4;stroke-linejoin:miter;\" x=\"506.28125\" xlink:href=\"#mb00a2ea2a4\" y=\"33.396875\"/>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- 训练 -->\n     <defs>\n      <path d=\"M 4.984375 -17.671875 \nL 4.984375 70.515625 \nL 54.984375 70.515625 \nL 54.984375 -17.671875 \nz\nM 10.59375 -12.109375 \nL 49.421875 -12.109375 \nL 49.421875 64.890625 \nL 10.59375 64.890625 \nz\n\" id=\"DejaVuSans-35757\"/>\n      <path d=\"M 4.984375 -17.671875 \nL 4.984375 70.515625 \nL 54.984375 70.515625 \nL 54.984375 -17.671875 \nz\nM 10.59375 -12.109375 \nL 49.421875 -12.109375 \nL 49.421875 64.890625 \nL 10.59375 64.890625 \nz\n\" id=\"DejaVuSans-32451\"/>\n     </defs>\n     <g transform=\"translate(542.28125 40.396875)scale(0.2 -0.2)\">\n      <use xlink:href=\"#DejaVuSans-35757\"/>\n      <use x=\"60.009766\" xlink:href=\"#DejaVuSans-32451\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc7168ea186\">\n   <rect height=\"380.52\" width=\"502.2\" x=\"82.0875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 648x504 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "losses = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    for step , (x, y) in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 第一层计算 [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x @ w1 + b1\n",
    "            h1 = tf.nn.relu(h1)  # 通过激活函数(ReLU)\n",
    "            \n",
    "            h2 = h1 @ w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            out = h2 @ w3 + b3\n",
    "            \n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "            # 计算误差\n",
    "            loss = tf.reduce_mean(tf.square(out - y_onehot))\n",
    "        # 自动计算梯度 \n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # 梯度更新，assign_sub 将当前值减去参数值，原地更新\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "        if step %  200 == 0:\n",
    "            losses.append(loss)\n",
    "            print(f'epoch:{epoch}, step:{step}, loss:{loss}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses, color='C0', marker='s', label='训练')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylabel('MSE')\n",
    "plt.savefig('forward.svg')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ]
}