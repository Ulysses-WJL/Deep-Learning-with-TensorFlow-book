{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络(Convolutional Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[最容易理解的对卷积(convolution)的解释](https://blog.csdn.net/bitcarmanlee/article/details/54729807)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import data, color\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积的意义\n",
    "\n",
    "卷积的重要的物理意义是：一个函数（如：单位响应）在另一个函数（如：输入信号）上的**加权叠加**。\n",
    "\n",
    "对于线性时不变系统，如果知道该系统的单位响应，那么将单位响应和输入信号求卷积，就相当于把输入信号的各个时间点的单位响应 加权叠加，就直接得到了输出信号。\n",
    "\n",
    "例子:\n",
    "\n",
    "已知$x[0] = a, x[1] = b, x[2]=c$, 已知$y[0] = i, y[1] = j, y[2]=k$, 求$(x \\otimes y)(n)$\n",
    "![](./卷积1.png)\n",
    "\n",
    "最后，把上面三个图叠加，就得到了$(x \\otimes y)(n)$\n",
    "![](./卷积2.png)\n",
    "\n",
    "## 1D连续卷积\n",
    "\n",
    "数学定义: $$(f \\otimes g)(n) = \\int_{-\\infty}^{\\infty} f(\\tau)g(n-\\tau)d\\tau$$\n",
    "\n",
    "例子: 做馒头\n",
    "\n",
    "假设馒头的生产速度是 $f(t)$, 馒头生产出来之后，就会慢慢腐败，假设腐败函数为$g(t)$, 那么一天后馒头总共腐败了：\n",
    "$$\\int_0^{24}f(t)g(24-t)dt$$\n",
    "\n",
    "## 离散卷积\n",
    "\n",
    "将积分运算换成累加运算:\n",
    "$$s(n) = (f\\otimes g)(n) = \\sum_{\\tau=-\\infty}^{\\infty}f(\\tau)g(n-\\tau)$$\n",
    "例子: 掷骰子\n",
    "\n",
    "设现有两枚骰子, 这两枚骰子掷出去, 求两枚骰子点数加起来为4的概率是多少?\n",
    "\n",
    "令$f(n), g(n)$分别代表2枚骰子点数的概率, 两枚骰子点数加起来为4的概率为：\n",
    "$$f(1)g(3)+f(2)g(2)+f(3)g(1)$$\n",
    "符合卷积的定义，把它写成标准的形式就是：\n",
    "$$(f\\otimes g)(4) = \\sum_{m=1}^{3}f(4-m)g(m)$$\n",
    "\n",
    "> 暴力解释: 扇巴掌 - -\n",
    "\n",
    "在卷积网络的术语中, 卷积的第一个参数(函数f)通常叫作**输入**(Input), 第二个参数(函数g)叫作**核函数**(kernel function). 输出有时被称作**特征映射**(feature map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([[2., 3, 1], [0, 5, 1], [1, 0, 8]])\n",
    "g = np.array([[-1, -1., -1], [-1, 8, -1], [-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.convolve([1, 2, 3, 4], [1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D离散卷积\n",
    "在计算机视觉中，卷积运算基于2D 图片函数$f(m, n)$和2D卷积核$g(m, n)$，其中$f(i, j)$和$g(i, j)$仅在各自窗口有效区域存在值，其它区域视为0.此时, 2D离散卷积定义为:\n",
    "$$S(m,n) = [f\\otimes g](m, n) = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty}f(i, j)g(m-i, n-j)$$\n",
    "卷积是可交换的(commutative), 可以等价的写作:\n",
    "$$S(m, n) = [f\\otimes g](m, n) = \\sum_i \\sum_j f(m-i, n-j)g(i, j)$$\n",
    "\n",
    "卷积运算的可交换性的出现是因为我们将核相对输入进行了**翻转**(filp), 这里二维的反转就是将卷积核沿x轴和y轴各翻转一次，比如：\n",
    "![](./核翻转.png)\n",
    "\n",
    "\n",
    "许多神经网络库会实现一个相关的函数,称为**互相关函数**(cross-correlation), 和卷积运算几乎一样但是并没有对核进行翻转:\n",
    "$$S(m, n) =[f\\otimes g](m, n) = \\sum_i \\sum_j f(m+i, n+j)g(i, j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部相关性\n",
    "\n",
    "全连接层也称为稠密连接层(Dense Layer)，输出与输入的关系为:\n",
    "$$o_j = \\sigma(\\sum_{i \\in nodes(I)} w_{ij}x_i + b_j)$$\n",
    "简化上述模型, 分析输入节点对输出节点的重要性分布, 仅考虑较重要的一部分输入节点而抛弃重要性较低的部分节点, 输出节点只需要与部分输入节点相连接:\n",
    "$$o_j = \\sigma(\\sum_{i \\in top(I, J, k)} w_{ij}x_i + b_j)$$\n",
    "其中$top(I, J, k)$表示第I层中对第J层中的j号节点重要性最高的k个节点集合.将全连接层的$||I|| \\cdot ||J||$个权值连接减少到$k\\cdot ||J||$个.\n",
    "\n",
    "根据先验知识, 可以得知图片每个像素点和周边像素点的关联度更大(位置相关). 以2D 图片数据为例，如果简单地认为与当前像素欧式距离(Euclidean Distance)小于和等于$\\frac {k}{\\sqrt 2}$的像素点重要性较高，欧式距离大于$\\frac {k}{\\sqrt 2}的像素点重要性较低，那么我们就很轻松地简化了每个像素点的重要性分布问题。\n",
    "\n",
    "以实心网格所在的像素为参考点，它周边欧式距离小于或等于$\\frac {k}{\\sqrt 2}$的像素点以矩形网格表示，网格内的像素点重要性较高，网格外的像素点较低。这个高宽为𝑘的窗口称为**感受域**(Receptive Field)，它表征了每个像素对于中心像素的重要性分布情况，网格内的像素才会被考虑，网格外的像素对于中心像素会被简单忽略.\n",
    "\n",
    "这种基于距离的重要性分布假设特性称为**局部相关性**.\n",
    "\n",
    "当前位置的节点与大小为𝑘的窗口内的所有像素相连接，与窗口外的其它像素点无关，此时网络层的输入输出关系:\n",
    "$$o_j = \\sigma \\left(\\sum_{dist(i, j)\\leq \\frac {k}{\\sqrt 2}} w_{ij}x_i + b_j\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数共享\n",
    "参数共享(parameter sharing)是指在一个模型的多个函数汇总使用相同的参数.在卷积神经网络中, 核的每一个元素都作用在输入的每一个位置上, 保证了我们只需要学习一个参数集合, 而不是对于每一位置都需要学习一个单独的参数集合.\n",
    "\n",
    "即每个输出节点仅与感受域区域内$k \\times k$个输入节点相连接，输出层节点数为$‖J‖$，则当前层的参数量为$k \\times k \\times ||J||$，对于每个输出节点$o_j$，均使用相同的权值矩阵$𝑾$，那么无论输出节点的数量$‖J‖$是多少，网络层的参数量总是$k\\times k$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|卷积作用|卷积核|\n",
    "|:---------------------------:|:------------------------------:|\n",
    "|输出原图|$\\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$|\n",
    "|边缘检测（突出边缘差异）|$\\begin{bmatrix} 1 & 0 & -1 \\\\ 0 & 0 & 0 \\\\ -1 & 0 & 1 \\end{bmatrix}$|\n",
    "|边缘检测（突出中间值）|$\\begin{bmatrix} -1 & -1 & -1 \\\\ -1 & 8 & -1 \\\\ -1 & -1 & -1 \\end{bmatrix}$|\n",
    "|方块模糊|$\\begin{bmatrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix} \\times \\frac{1}{9}$|\n",
    "|图像锐化|$\\begin{bmatrix} 0 & -1 & 0 \\\\ -1 & 5 & -1 \\\\ 0 & -1 & 0 \\end{bmatrix}$|\n",
    "|高斯模糊|$\\begin{bmatrix} 1 & 2 & 1 \\\\ 2 & 4 & 2 \\\\ 1 & 2 & 1 \\end{bmatrix} \\times \\frac{1}{16}$|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data.chelsea()\n",
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = cat / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1 = np.rollaxis(cat, 2, 0)\n",
    "cat_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_2 = np.swapaxes(cat, 2, 0)\n",
    "cat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_grey = color.rgb2gray(cat)\n",
    "cat_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat_grey.T, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现2D卷积**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.insert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.ones([3,3 ])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.ones([3,3 ])\n",
    "image = np.insert(image, 3, np.zeros(3), axis=0)\n",
    "image = np.insert(image, 0, np.zeros(3), axis=0)\n",
    "image = np.insert(image, 3, np.zeros(5), axis=1)\n",
    "image = np.insert(image, 0, np.zeros(5), axis=1)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多通道输入 单卷积核\n",
    "def conv2d(image, kernel, padding='SAME', strides=[1]):\n",
    "    # image  (height, width, in_channels)\n",
    "    # kernel (filter_height, f_width, in_channels, out_channels)\n",
    "    h, w, channels = image.shape\n",
    "    res = np.zeros_like(image)\n",
    "    kh, kw, in_c, out_c = kernel.shape\n",
    "#     kernel = kernel[..., np.newaxis]\n",
    "    image = np.rollaxis(image, 2, 0)  # 转为 c, h, w, 排布\n",
    "    if padding == 'SAME': \n",
    "        # 需要填充一圈0(步长为1时)\n",
    "        image = np.insert(image, h, np.zeros(w), axis=1)\n",
    "        image = np.insert(image, 0, np.zeros(w), axis=1)\n",
    "        image = np.insert(image, w, np.zeros(h + 2), axis=2)\n",
    "        image = np.insert(image, 0, np.zeros(h + 2), axis=2)\n",
    "#         new = np.zeros([h+2, w+2])\n",
    "#         new[1:-1, 1:-1] = image\n",
    "    if out_c == 1:  # 3 通道相加  输出到1个通道 \n",
    "        res = res[..., 0]\n",
    "        for i in range(h):  # 使用原来的h和w\n",
    "            for j in range(w):\n",
    "                temp = image[:, i:i+kh, j:j+kh]\n",
    "                res[i, j] = np.sum(temp * kernel)\n",
    "    else:  # 各通道 各自进行卷积\n",
    "        for c in range(channels):\n",
    "            for i in range(h):  # 使用原来的h和w\n",
    "                for j in range(w):\n",
    "                    temp = image[c, i:i+kh, j:j+kh]\n",
    "                    res[i, j, c] = np.sum(temp * kernel)\n",
    "        \n",
    "    res = (res - res.min())/(res.max() - res.min()) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((3,3 )) * 1/ 9  # 方块模糊\n",
    "\n",
    "# kernel = np.zeros([3, 3])\n",
    "# kernel[1, 1] = 1  # 原图\n",
    "# kernel = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1.]])  # 突出边缘差异\n",
    "kernel = np.ones((3,3 )) * -1\n",
    "kernel[1, 1] = 8  # 突出中间值\n",
    "kernel = np.tile(kernel[..., np.newaxis, np.newaxis], [1, 1, 3, 3])\n",
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2 = conv2d(cat, kernel)\n",
    "cat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tensorflow实现2d卷积**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [batch, in_height, in_width, in_channels]\n",
    "cat1 = tf.nn.conv2d(cat[np.newaxis, ...], kernel, strides=[1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = (cat1 - tf.reduce_min(cat1)) / (tf.reduce_max(cat1) - tf.reduce_min(cat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(cat1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于卷积, 参数共享的特殊形式使得神经网络层具有对平移**等变**(equivariance)的性质"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步长(Stride)\n",
    "步长是指感受域窗口每次移动的长度单位，对于2D输入来说，分为沿𝑥(向右)方向和𝑦(向下)方向的移动长度.\n",
    "\n",
    "可以看到，通过设定步长𝑠，可以有效地控制信息密度的提取。当步长设计的较小时，感受域以较小幅度移动窗口，有利于提取到更多的特征信息，输出张量的尺寸也更大；当步长设计的较大时，感受域以较大幅度移动窗口，有利于减少计算代价，过滤冗余信息，输出张量的尺寸也更小."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填充(Padding)\n",
    "经过卷积运算后的输出𝑶的高宽一般会小于输入𝑿的高宽，即使是步长s = 1时，输出𝑶的高宽也会略小于输入𝑿高宽. \n",
    "\n",
    "为了让输出𝑶的高宽能够与输入𝑿的相等，一般通过在原输入𝑿的高和宽维度上面进行填充(Padding)若干无效元素操作，得到增大的输入𝑿′"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经层地输出尺寸$[b, h', w', c_{out}]$由卷积核的数量$c_{out}$卷积核的大小𝑘，步长𝑠，填充数𝑝(只考虑上下填充数量$𝑝_ℎ$相同，左右填充数量$𝑝_𝑤$相同的情况)以及输入𝑿的高宽ℎ/𝑤共同决定:\n",
    "$$h' = \\frac {h + 2\\cdot p_h - k}{s} + 1 \\\\\n",
    "w' = \\frac {w + 2 \\cdot p_w -k}{s} +  1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([2, 5, 5, 3])  # 3通道 宽高为5 \n",
    "w = tf.random.normal([3, 3, 3, 4])  # [k, k, cin, cout]  3通道输入  4个3x3的卷积核\n",
    "out = tf.nn.conv2d(x, w, strides=1, padding=[[0,0],[0,0],[0,0],[0,0]])  # 不填充\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中padding 参数的设置格式为：\n",
    "\n",
    "padding=[[0,0],[上,下],[左,右],[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.conv2d(x, w, strides=1, padding=[[0,0],[1,1],[1,1],[0,0]])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.conv2d(x, w, strides=1, padding='SAME')  # 步长为1  SAME 模式下 输出与输入同大小\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.nn.conv2d(x, w, strides=1, padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**卷积层**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, datasets, losses, optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下创建了4 个3 × 3大小的卷积核的卷积层，步长为1，padding 方案为'SAME'\n",
    "layer = layers.Conv2D(4, kernel_size=3, padding='SAME', strides=1)\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h=3, w=3, c_in=3 c_out=4\n",
    "layer.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4个3X4大小卷积核, 竖直方向步长2 水平方向步长1\n",
    "layer = layers.Conv2D(4, kernel_size=(3, 4), padding='SAME', strides=(2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet-5\n",
    "LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络. 一共包含7层（输入层不作为网络结构），分别由2个卷积层、2个下采样层和3个连接层组成."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.mnist.load_data()\n",
    "(X_train, y_train), (X_dev, y_dev) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(28, 28)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f5de0512590>"
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p58118a0ddd)\">\n    <image height=\"218\" id=\"image1ccc490af8\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8466d888fb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m8466d888fb\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"med3d1ea9a4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#med3d1ea9a4\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p58118a0ddd\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "print(y_train[10])\n",
    "plt.imshow(X_train[10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y):\n",
    "    X = tf.cast(X, dtype=tf.float32) / 255.\n",
    "    # X = tf.reshape(X, (-1, 28*28))\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_dev, y_dev))\n",
    "train_db = train_db.shuffle(100000).batch(256).map(preprocessing).repeat(30)\n",
    "test_db = test_db.shuffle(100000).batch(256).map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(TensorShape([256, 28, 28]), TensorShape([256]))"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "X1, y1 = next(iter(train_db))\n",
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            multiple                  60        \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 multiple                  0         \n_________________________________________________________________\nre_lu_2 (ReLU)               multiple                  0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            multiple                  880       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 multiple                  0         \n_________________________________________________________________\nre_lu_3 (ReLU)               multiple                  0         \n_________________________________________________________________\nflatten_1 (Flatten)          multiple                  0         \n_________________________________________________________________\ndense_3 (Dense)              multiple                  48120     \n_________________________________________________________________\ndense_4 (Dense)              multiple                  10164     \n_________________________________________________________________\ndense_5 (Dense)              multiple                  850       \n=================================================================\nTotal params: 60,074\nTrainable params: 60,074\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Conv2D(6, kernel_size=3, strides=1),  # 6个 3X3的 卷积核 6 * 9 + 6 = 60个参数  \n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),  # 高宽各减半\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(16, kernel_size=3, strides=1), \n",
    "    layers.MaxPooling2D(pool_size=2, strides=2),  # 高宽各减半\n",
    "    layers.ReLU(),\n",
    "    layers.Flatten(),  # 展平 方便全连接层处理\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "network.build(input_shape=(None, 28, 28, 1))  # 28X28 1通道\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵\n",
    "criten = losses.CategoricalCrossentropy(from_logits=True) \n",
    "optimizer = optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nApply gradients to variables.\n\nThis is the second part of `minimize()`. It returns an `Operation` that\napplies gradients.\n\nArgs:\n  grads_and_vars: List of (gradient, variable) pairs.\n  name: Optional name for the returned operation.  Default to the name\n    passed to the `Optimizer` constructor.\n\nReturns:\n  An `Operation` that applies the specified gradients. The `iterations`\n  will be automatically increased by 1.\n\nRaises:\n  TypeError: If `grads_and_vars` is malformed.\n  ValueError: If none of the variables have gradients.\n\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\n\u001b[0;31mType:\u001b[0m      method\n",
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "optimizer.apply_gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_acc = metrics.Accuracy()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "step:0 cost:2.313047409057617\ndev 正确率:0.18780000507831573\nstep:100 cost:0.10444694012403488\ndev 正确率:0.575950026512146\nstep:200 cost:0.06578396260738373\ndev 正确率:0.7103000283241272\nstep:300 cost:0.05805310606956482\ndev 正确率:0.7777000069618225\nstep:400 cost:0.056566882878541946\ndev 正确率:0.8187000155448914\nstep:500 cost:0.039628222584724426\ndev 正确率:0.8462666869163513\nstep:600 cost:0.07804673165082932\ndev 正确率:0.8661999702453613\nstep:700 cost:0.07342112064361572\ndev 正确率:0.881262481212616\nstep:800 cost:0.0555611252784729\ndev 正确率:0.8929444551467896\nstep:900 cost:0.07327509671449661\ndev 正确率:0.9024699926376343\nstep:1000 cost:0.025775428861379623\ndev 正确率:0.9102363586425781\nstep:1100 cost:0.0504230298101902\ndev 正确率:0.9166833162307739\nstep:1200 cost:0.006781408563256264\ndev 正确率:0.9221461415290833\nstep:1300 cost:0.015395808033645153\ndev 正确率:0.926885724067688\nstep:1400 cost:0.034457016736269\ndev 正确率:0.9310399889945984\nstep:1500 cost:0.03598139062523842\ndev 正确率:0.9346625208854675\nstep:1600 cost:0.022872459143400192\ndev 正确率:0.9376941323280334\nstep:1700 cost:0.014055712148547173\ndev 正确率:0.9405500292778015\nstep:1800 cost:0.008660576306283474\ndev 正确率:0.9430368542671204\nstep:1900 cost:0.002467554295435548\ndev 正确率:0.9453099966049194\nstep:2000 cost:0.015318232588469982\ndev 正确率:0.9472761750221252\nstep:2100 cost:0.027858378365635872\ndev 正确率:0.9492090940475464\nstep:2200 cost:0.009842144325375557\ndev 正确率:0.9509782791137695\nstep:2300 cost:0.05426361411809921\ndev 正确率:0.9525874853134155\nstep:2400 cost:0.00721193989738822\ndev 正确率:0.9540640115737915\nstep:2500 cost:0.012164345942437649\ndev 正确率:0.9553884863853455\nstep:2600 cost:0.0027013865765184164\ndev 正确率:0.956681489944458\nstep:2700 cost:0.03133028745651245\ndev 正确率:0.9578428864479065\nstep:2800 cost:0.021019719541072845\ndev 正确率:0.9589517116546631\nstep:2900 cost:0.019220896065235138\ndev 正确率:0.9599733352661133\nstep:3000 cost:0.009531034156680107\ndev 正确率:0.9609032273292542\nstep:3100 cost:0.003430216573178768\ndev 正确率:0.961746871471405\nstep:3200 cost:0.023109711706638336\ndev 正确率:0.9625757336616516\nstep:3300 cost:0.010427935048937798\ndev 正确率:0.9633294343948364\nstep:3400 cost:0.007254884112626314\ndev 正确率:0.9640799760818481\nstep:3500 cost:0.006249746307730675\ndev 正确率:0.9648028016090393\nstep:3600 cost:0.013373883441090584\ndev 正确率:0.9654729962348938\nstep:3700 cost:0.0013149789301678538\ndev 正确率:0.9660763144493103\nstep:3800 cost:0.007769579999148846\ndev 正确率:0.9666743874549866\nstep:3900 cost:0.004644869826734066\ndev 正确率:0.9672499895095825\nstep:4000 cost:0.01766357012093067\ndev 正确率:0.9678000211715698\nstep:4100 cost:0.010553604923188686\ndev 正确率:0.9683142900466919\nstep:4200 cost:0.0026029155123978853\ndev 正确率:0.9688023328781128\nstep:4300 cost:0.01712126098573208\ndev 正确率:0.9692659378051758\nstep:4400 cost:0.0036228743847459555\ndev 正确率:0.9697244167327881\nstep:4500 cost:0.008161600679159164\ndev 正确率:0.9701673984527588\nstep:4600 cost:0.003462834283709526\ndev 正确率:0.9706042408943176\nstep:4700 cost:0.004061196930706501\ndev 正确率:0.9709312319755554\nstep:4800 cost:0.0020940969698131084\ndev 正确率:0.9713020324707031\nstep:4900 cost:0.002400526311248541\ndev 正确率:0.9716640114784241\nstep:5000 cost:0.02065219357609749\ndev 正确率:0.972000002861023\nstep:5100 cost:0.0025428072549402714\ndev 正确率:0.9723634719848633\nstep:5200 cost:0.0002798495115712285\ndev 正确率:0.9727056622505188\nstep:5300 cost:0.00368738011457026\ndev 正确率:0.9730148315429688\nstep:5400 cost:0.009374660439789295\ndev 正确率:0.9733399748802185\nstep:5500 cost:0.00019310515199322253\ndev 正确率:0.9736267924308777\nstep:5600 cost:0.0005205411580391228\ndev 正确率:0.9739087820053101\nstep:5700 cost:0.0006357493111863732\ndev 正确率:0.9741654992103577\nstep:5800 cost:0.0018229786073789\ndev 正确率:0.9744338989257812\nstep:5900 cost:0.006720824167132378\ndev 正确率:0.974696695804596\nstep:6000 cost:0.0012895786203444004\ndev 正确率:0.9749475121498108\nstep:6100 cost:0.017888043075799942\ndev 正确率:0.9751999974250793\nstep:6200 cost:9.951539686881006e-05\ndev 正确率:0.975426971912384\nstep:6300 cost:0.004188332706689835\ndev 正确率:0.9756656289100647\nstep:6400 cost:0.0025775276590138674\ndev 正确率:0.9758892059326172\nstep:6500 cost:0.00044359418097883463\ndev 正确率:0.97606360912323\nstep:6600 cost:0.007186323404312134\ndev 正确率:0.976279079914093\nstep:6700 cost:0.0013402821496129036\ndev 正确率:0.976469099521637\nstep:6800 cost:0.0010473700240254402\ndev 正确率:0.9766579866409302\nstep:6900 cost:5.8159865147899836e-05\ndev 正确率:0.976844310760498\nstep:7000 cost:0.008040748536586761\ndev 正确率:0.9770253300666809\n"
    }
   ],
   "source": [
    "# loss = []\n",
    "acc = []\n",
    "metric_acc.reset_states()\n",
    "for step, (x, y) in enumerate(train_db):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = tf.expand_dims(x, axis=3)  # [b, 28, 28, 1]\n",
    "        out = network(x)\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        cost = criten(y_onehot, out)\n",
    "    grads = tape.gradient(cost, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(f'step:{step} cost:{float(cost)}', )\n",
    "        for x, y in test_db:\n",
    "            x = tf.expand_dims(x, axis=3)\n",
    "            out = network(x)\n",
    "            # 可以不进过softmax\n",
    "            y_pred = tf.argmax(out, axis=-1)\n",
    "            metric_acc.update_state(y, y_pred)\n",
    "        print(f\"dev 正确率:{float(metric_acc.result())}\")\n",
    "        acc.append(float(metric_acc.result()))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}