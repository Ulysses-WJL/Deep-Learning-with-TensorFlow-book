{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 ä¸ VGG13 å®æˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.family'] = ['SimHei'] # ['Noto Sans CJK JP']\n",
    "plt.rcParams['axes.unicode_minus']=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, losses, metrics, Sequential, layers, optimizers, Model, Input\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "import pydot\n",
    "# import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y):\n",
    "    X = tf.cast(X, dtype=tf.float32) / 255\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    return X, y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_db = train_db.shuffle(10000).batch(128).map(preprocessing)\n",
    "test_db = test_db.shuffle(10000).batch(128).map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_db))\n",
    "tf.reduce_max(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f8b401bb150>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 16, 16, 3])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
    "out_1 = pool_layer(X_train[4][np.newaxis])\n",
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 32, 32, 3])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=1, padding='same')\n",
    "out_2 = pool_layer(X_train[4][tf.newaxis])\n",
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array_equal(out_1, out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 å›¾ç‰‡è¯†åˆ«ä»»åŠ¡å¹¶ä¸ç®€å•ï¼Œè¿™ä¸»è¦æ˜¯ç”±äº CIFAR10 çš„å›¾ç‰‡å†…å®¹éœ€è¦å¤§é‡ç»†èŠ‚æ‰èƒ½å‘ˆç°ï¼Œè€Œä¿å­˜çš„å›¾ç‰‡åˆ†è¾¨ç‡ä»…æœ‰32 Ã— 32ï¼Œä½¿å¾—éƒ¨åˆ†ä¸»ä½“ä¿¡æ¯è¾ƒä¸ºæ¨¡ç³Šï¼Œç”šè‡³äººçœ¼éƒ½å¾ˆéš¾åˆ†è¾¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å·ç§¯å­ç½‘ç»œ\n",
    "conv_layers = [\n",
    "    # 64ä¸ª 3X3 çš„å·ç§¯æ ¸ è¾“å‡ºä¸è¾“å…¥åŒå¤§å°\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(32,32,3)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    # æ± åŒ–å±‚ é«˜å®½å‡åŠ\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ2  è¾“å‡ºé€šé“æå‡è‡³ 128ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ3  è¾“å‡ºé€šé“æå‡è‡³ 256ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ4  è¾“å‡ºé€šé“æå‡è‡³ 512ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ4  è¾“å‡ºé€šé“æå‡è‡³ 512ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),                       \n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu', input_shape=(1, 1, 512)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13 = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(VGG13, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 3 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 64 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*64 + 1) * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50000 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG13():\n",
    "    loss = []\n",
    "    acc = []\n",
    "    metric_acc = metrics.Accuracy()\n",
    "    optimizer = optimizers.Adam(0.0001)\n",
    "    conv_net.build(input_shape=(None, 32, 32, 3))\n",
    "    fc_net.build(input_shape=(None, 512)) \n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for step, (x, y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                out = VGG(x)\n",
    "                # print(out.shape)\n",
    "                # y_onehot = tf.one_hot(y, depth=10)\n",
    "                cost = losses.categorical_crossentropy(y, out, from_logits=True)\n",
    "                cost =tf.reduce_mean(cost)\n",
    "            grads = tape.gradient(cost, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss.append(float(cost))\n",
    "                print(f\"epoch: {epoch}, step: {step}, loss: {float(cost)}\")\n",
    "        \n",
    "        # æ¯ä¸ªepoch æ£€æµ‹ä¸€æ¬¡test\n",
    "        metric_acc.reset_states()\n",
    "        for x, y in test_db:\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, (-1, 512))\n",
    "\n",
    "            out = fc_net(out)\n",
    "            y_pred = tf.argmax(out, axis=-1)\n",
    "            metric_acc.update_state(y, y_pred)\n",
    "        print(f\"epoch :{epoch},  accuracy: {float(metric_acc.result())}\")\n",
    "        acc.append(float(metric_acc.result()))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å·ç§¯å±‚å˜ç§\n",
    "\n",
    "### ç©ºæ´å·ç§¯(Dilated/Atrous Convolution)\n",
    "\n",
    "æ™®é€šçš„å·ç§¯å±‚ä¸ºäº†å‡å°‘ç½‘ç»œçš„å‚æ•°é‡ï¼Œå·ç§¯æ ¸çš„è®¾è®¡é€šå¸¸é€‰æ‹©è¾ƒå°çš„ $1\\times1$ å’Œ$3 \\times 3$æ„Ÿå—é‡å¤§å°ã€‚å°å·ç§¯æ ¸ä½¿å¾—ç½‘ç»œæå–ç‰¹å¾æ—¶çš„æ„Ÿå—é‡åŒºåŸŸæœ‰é™ï¼Œä½†æ˜¯å¢å¤§æ„Ÿå—é‡çš„åŒºåŸŸåˆä¼šå¢åŠ ç½‘ç»œçš„å‚æ•°é‡å’Œè®¡ç®—ä»£ä»·.\n",
    "\n",
    "ç©ºæ´å·ç§¯åœ¨æ™®é€šå·ç§¯çš„æ„Ÿå—é‡ä¸Šå¢åŠ ä¸€ä¸ªDilation Rate å‚æ•°, ç”¨äºæ§åˆ¶æ„Ÿå—é‡åŒºåŸŸçš„é‡‡æ ·æ­¥é•¿\n",
    "![](./ç©ºæ´å·ç§¯.png)\n",
    "\n",
    "å°½ç®¡Dilation Rate çš„å¢å¤§ä¼šä½¿å¾—æ„Ÿå—é‡åŒºåŸŸå¢å¤§ï¼Œä½†æ˜¯å®é™…å‚ä¸è¿ç®—çš„ç‚¹æ•°ä»ç„¶ä¿æŒä¸å˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([1, 7, 7, 1])\n",
    "# ç©ºæ´å·ç§¯  1ä¸ª 3 X 3 çš„æ ¸\n",
    "layer = layers.Conv2D(1, kernel_size=(3, 3), strides=1, dilation_rate=2)\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è½¬ç½®å·ç§¯\n",
    "è½¬ç½®å·ç§¯(Transposed Convolutionï¼Œæˆ–Fractionally Strided Convolution)é€šè¿‡åœ¨è¾“å…¥ä¹‹é—´å¡«å……å¤§é‡çš„padding æ¥å®ç°è¾“å‡ºé«˜å®½å¤§äºè¾“å…¥é«˜å®½çš„æ•ˆæœï¼Œä»è€Œå®ç°å‘ä¸Šé‡‡æ ·çš„ç›®çš„.è½¬ç½®å·ç§¯å…·æœ‰â€œ**æ”¾å¤§ç‰¹å¾å›¾**â€çš„åŠŸèƒ½\n",
    "\n",
    "è½¬ç½®å·ç§¯ä¸æ™®é€šå·ç§¯å¹¶ä¸æ˜¯äº’ä¸ºé€†è¿‡ç¨‹ï¼Œä¸èƒ½æ¢å¤å‡ºå¯¹æ–¹çš„è¾“å…¥å†…å®¹ï¼Œä»…èƒ½æ¢å¤å‡ºç­‰å¤§å°çš„å¼ é‡.\n",
    "\n",
    "ä¾‹: \n",
    "- è¾“å…¥$i = 2 \\times 2$ å•é€šé“ç‰¹å¾å›¾, è½¬ç½®å·ç§¯æ ¸$k=3 \\times 3$, å¡«å……$p=0$, æ­¥é•¿$s=2$;\n",
    "- $2 \\times 2$ å†…éƒ¨å‡åŒ€å¡«å……$s-1$ä¸ªç©ºç™½è¾“å…¥ç‚¹ ---> $3 \\times 3$;\n",
    "- $3 \\times 3$ å‘¨å›´å¡«å……$ğ‘˜ âˆ’ ğ‘ âˆ’1 = 3 âˆ’ 0âˆ’1 = 2è¡Œ/åˆ—$, ---> $7 \\times 7$;\n",
    "- $7 \\times 7$ ä¸ $3 \\times 3$çš„å·ç§¯æ ¸å·ç§¯, æ­¥é•¿$s' = 1$(å›ºå®š), å¡«å……$p=0$ ---> $o = 5 \\times 5$çš„è¾“å‡º;\n",
    "\n",
    "- æ¢å¤: $5 \\times 5$ ä¸ $3 \\times 3$çš„å·ç§¯æ ¸å·ç§¯, å¡«å……$p=0$, æ­¥é•¿$s=2$ ----> $2 \\times 2$çš„è¾“å…¥ \n",
    "\n",
    "åœ¨ğ‘œ + 2ğ‘ âˆ’ ğ‘˜ä¸ºs å€æ•°æ—¶ï¼Œæ»¡è¶³å…³ç³»:\n",
    "$$o = (i-1)s +k-2p$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(25) + 1\n",
    "# [b, h, w, c]\n",
    "x = tf.reshape(x, [1, 5, 5, 1])\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "# 3X3 å·ç§¯æ ¸\n",
    "w = tf.constant([[-1, 2, -3.], [4, -5, 6], [-7, 8, -9]])\n",
    "w = tf.expand_dims(w, axis=2)\n",
    "w =  tf.expand_dims(w, axis=3)\n",
    "# [f_w, f_h, c_in, c_out]\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[ -67.],\n",
       "         [ -77.]],\n",
       "\n",
       "        [[-117.],\n",
       "         [-127.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¡«å……0, æ­¥é•¿2\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d_transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†æ™®é€šå·ç§¯ä½œä¸ºè½¬ç½®å·ç§¯çš„è¾“å…¥\n",
    "# è¾“å…¥:2*2   æ ¸:3*3\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   67.,  -134.,   278.,  -154.,   231.],\n",
       "       [ -268.,   335.,  -710.,   385.,  -462.],\n",
       "       [  586.,  -770.,  1620.,  -870.,  1074.],\n",
       "       [ -468.,   585., -1210.,   635.,  -762.],\n",
       "       [  819.,  -936.,  1942., -1016.,  1143.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(xx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å·ç§¯è¿ç®—çš„è¾“å‡ºå¤§å°\n",
    "$$o = âŒŠ\\frac {i + 2\\cdot p_h - k}{s}âŒ‹ + 1$$\n",
    "å½“ğ’ + ğŸğ’‘ âˆ’ ğ’Œä¸ä¸ºğ’”å€æ•°æ—¶, å½“s>1, å‘ä¸‹å–æ•´ä¼šä½¿å¾—å¤šç§ä¸åŒå¤§å°çš„è¾“å…¥iå¾—åˆ°ç›¸åŒå¤§å°çš„è¾“å‡ºo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 2, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([1,6,6,1])\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æŒ‡å®šoutput_shape å¾—åˆ°è¾“å‡ºå°ºå¯¸\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=3, padding='SAME', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.arange(16) + 1\n",
    "I = I.reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[1, 0, 1], [0, 0, 0], [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[..., np.newaxis, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[np.newaxis, ..., np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=170, shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = tf.nn.conv2d(tf.cast(I[np.newaxis, ..., np.newaxis], dtype=tf.float32), K[..., np.newaxis, np.newaxis], strides=1, padding='VALID')\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=180, shape=(1, 4, 4, 1), dtype=float32, numpy=\n",
       "array([[[[24.],\n",
       "         [28.],\n",
       "         [24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.],\n",
       "         [40.],\n",
       "         [44.]],\n",
       "\n",
       "        [[24.],\n",
       "         [28.],\n",
       "         [24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.],\n",
       "         [40.],\n",
       "         [44.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åªèƒ½æ¢å¤ç›¸åŒçš„å½¢çŠ¶\n",
    "tf.nn.conv2d_transpose(O,  K[..., np.newaxis, np.newaxis], strides=1, padding='VALID', output_shape=[1, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### çŸ©é˜µè§’åº¦ç†è§£\n",
    "æ™®é€šConv2dè¿ç®—:\n",
    "- X:(4, 4), W:(3, 3), æ­¥é•¿ä¸º1ï¼Œæ— padding\n",
    "- Xæ‰“å¹³X'(1, 16), Wè½¬ä¸ºç¨€ç–çŸ©é˜µW'(4, 16)\n",
    "- è¾“å‡º$O'= W'@X'$ (4,1), reshape å¾—åˆ°O(2, 2)\n",
    "\n",
    "è½¬ç½®å·ç§¯\n",
    "- $W'$è½¬ç½®åä¸$O'$çŸ©é˜µç›¸ä¹˜$X'=W'^T@O'$å¤§å°ä¸º(16, 1), reshapeå¾—åˆ°(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  è½¬ç½®å·ç§¯å±‚\n",
    "\n",
    "- å½“padding=â€™VALIDâ€™æ—¶ï¼Œè¾“å‡ºå¤§å°è¡¨è¾¾ä¸º:\n",
    "   $$o=(i-1)s+k$$\n",
    "- å½“è®¾ç½®padding=â€™SAMEâ€™æ—¶ï¼Œè¾“å‡ºå¤§å°è¡¨è¾¾ä¸º:\n",
    "   $$o = i \\cdot s$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding='VALID')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=3, padding='SAME')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†ç¦»å·ç§¯(Separable Convolution)\n",
    "\n",
    "æ™®é€šå·ç§¯åœ¨å¯¹å¤šé€šé“è¾“å…¥è¿›è¡Œè¿ç®—æ—¶ï¼Œå·ç§¯æ ¸çš„æ¯ä¸ªé€šé“ä¸è¾“å…¥çš„æ¯ä¸ªé€šé“åˆ†åˆ«è¿›è¡Œå·ç§¯è¿ç®—ï¼Œå¾—åˆ°å¤šé€šé“çš„ç‰¹å¾å›¾ï¼Œå†å¯¹åº”å…ƒç´ ç›¸åŠ äº§ç”Ÿå•ä¸ªå·ç§¯æ ¸çš„æœ€ç»ˆè¾“å‡º\n",
    "$$è¾“å…¥[1, h, w, 3] \\odot å¤šå·ç§¯æ ¸[3, 3, 3, 4] \\rightarrow ä¸­é—´ç‰¹å¾ \\rightarrow \\sumå¯¹åº”å…ƒç´ æ±‚å’Œ = \n",
    "è¾“å‡º[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "åˆ†ç¦»å·ç§¯æµç¨‹:\n",
    "$$è¾“å…¥[1, h, w, 3] \\odot å•å·ç§¯æ ¸[3, 3, 3, 1] \\rightarrow ä¸­é—´ç‰¹å¾ \\rightarrow \\\\ \\odot 4ä¸ª1\\times 1 å·ç§¯æ ¸[1, 1, 3, 4] =\n",
    "è¾“å‡º[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°ï¼Œåˆ†ç¦»å·ç§¯å±‚åŒ…å«äº†ä¸¤æ­¥å·ç§¯è¿ç®—ï¼Œç¬¬ä¸€æ­¥å·ç§¯è¿ç®—æ˜¯å•ä¸ªå·ç§¯æ ¸ï¼Œç¬¬äºŒä¸ªå·ç§¯è¿ç®—åŒ…å«äº†å¤šä¸ªå·ç§¯æ ¸ã€‚\n",
    "\n",
    "ä¼˜åŠ¿:\n",
    "- ç›¸åŒè¾“å…¥è¦äº§ç”Ÿç›¸åŒå¤§å°è¾“å‡º, åˆ†ç¦»å·ç§¯çš„å‚æ•°é‡çº¦æ˜¯æ™®é€šå·ç§¯çš„$\\frac 1 3$\n",
    "\n",
    "$1 \\times 1$å·ç§¯æ ¸çš„ä½œç”¨:\n",
    "- å®ç°ä¿¡æ¯çš„è·¨é€šé“äº¤äº’å’Œæ•´åˆã€‚\n",
    "- å¯¹å·ç§¯æ ¸é€šé“æ•°è¿›è¡Œé™ç»´å’Œå‡ç»´ï¼Œå‡å°å‚æ•°é‡, é™ä½è®¡ç®—æˆæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ·±åº¦æ®‹å·®ç½‘ç»œResNet\n",
    "å½“æ¨¡å‹åŠ æ·±ä»¥åï¼Œç½‘ç»œå˜å¾—è¶Šæ¥è¶Šéš¾è®­ç»ƒï¼Œè¿™ä¸»è¦æ˜¯ç”±äº**æ¢¯åº¦å¼¥æ•£**å’Œ**æ¢¯åº¦çˆ†ç‚¸**ç°è±¡é€ æˆçš„ã€‚åœ¨è¾ƒæ·±å±‚æ•°çš„ç¥ç»ç½‘ç»œä¸­ï¼Œæ¢¯åº¦ä¿¡æ¯ç”±ç½‘ç»œçš„æœ«å±‚é€å±‚ä¼ å‘ç½‘ç»œçš„é¦–å±‚æ—¶ï¼Œä¼ é€’çš„è¿‡ç¨‹ä¸­ä¼šå‡ºç°æ¢¯åº¦æ¥è¿‘äº0 æˆ–æ¢¯åº¦å€¼éå¸¸å¤§çš„ç°è±¡ã€‚ç½‘ç»œå±‚æ•°è¶Šæ·±ï¼Œè¿™ç§ç°è±¡å¯èƒ½ä¼šè¶Šä¸¥é‡ã€‚\n",
    "\n",
    "é€šè¿‡åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æ·»åŠ ä¸€æ¡ç›´æ¥è¿æ¥çš„**Skip Connection**å¯ä»¥è®©ç¥ç»ç½‘ç»œå…·æœ‰å›é€€çš„èƒ½åŠ›.å®ƒå¯ä»¥ä»æŸä¸€å±‚ç½‘ç»œå±‚è·å–æ¿€æ´»ï¼Œç„¶åè¿…é€Ÿåé¦ˆç»™å¦å¤–ä¸€å±‚ï¼Œç”šè‡³æ˜¯ç¥ç»ç½‘ç»œçš„æ›´æ·±å±‚ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è·³è·ƒè¿æ¥æ„å»ºèƒ½å¤Ÿè®­ç»ƒæ·±åº¦ç½‘ç»œçš„**ResNet**.\n",
    "\n",
    "### ResNet åŸç†\n",
    "ResNet é€šè¿‡åœ¨å·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æ·»åŠ Skip Connection å®ç°å±‚æ•°å›é€€æœºåˆ¶, è¾“å…¥$x$é€šè¿‡2ä¸ªå·ç§¯å±‚, å¾—åˆ°ç‰¹å¾å˜æ¢åçš„è¾“å‡º$\\mathcal F(x)$, ä¸è¾“å…¥$x$è¿›è¡Œå¯¹åº”å…ƒç´ çš„ç›¸åŠ è¿ç®—, å¾—åˆ°æœ€ç»ˆè¾“å‡º$\\mathcal H(x)$:\n",
    "$$\\mathcal H(x) = x + \\mathcal F(x)$$\n",
    "> éœ€è¦ä¿æŒè¾“å…¥$x$çš„shapeä¸$\\mathcal F(x)$çš„shapeå®Œå…¨ä¸€è‡´\n",
    "\n",
    "![](./æ®‹å·®æ¨¡å—.png)\n",
    "$\\mathcal H(x)$å«ä½œæ®‹å·®æ¨¡å—(Residual Block, ResBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResBlockçš„å®ç°\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, fliter_num, stride=1):\n",
    "        super().__init__()\n",
    "        # f(x)å‡½æ•°åŒ…æ‹¬2ä¸ªæ™®é€šçš„å·ç§¯å±‚\n",
    "        self.conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # ç¬¬äºŒä¸ªå·ç§¯å±‚æ­¥é•¿ä¸º1,\n",
    "        self.conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1:  # F ä¸ xçš„å½¢çŠ¶ä¸ç›¸åŒ\n",
    "            self.downsample = Sequential()\n",
    "            # ä½¿ç”¨ 1X1 å·ç§¯æ ¸\n",
    "            self.downsample.add(layers.Conv2D(fliter_num, (1, 1), strides=stride))\n",
    "        else:\n",
    "            # ç›´æ¥è¿æ¥\n",
    "            self.downsample = lambda x:x\n",
    "            \n",
    "    def call(self, x):\n",
    "        # å‰å‘ä¼ æ’­  H(x) = x + F(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        identity = self.downsample(x)\n",
    "        \n",
    "        output = layers.add([out, identity])\n",
    "        # å¾—åˆ°H(x)åå†è¿›è¿‡æ¿€æ´»å‡½æ•° \n",
    "        output = tf.nn.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(Model):\n",
    "    def __init__(self, layer_blocks, num_classe=10):\n",
    "        super().__init__()\n",
    "         # æ ¹ç½‘ç»œ\n",
    "        self.stem = Sequential([\n",
    "            layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=(32, 32, 3)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
    "        ])\n",
    "        # 4ä¸ªblock æ¯ä¸ªblockæœ‰å¤šä¸ªæ®‹å·®æ¨¡å—\n",
    "        self.layer1 = self.build_resblock(64, layer_blocks[0])\n",
    "        self.layer2 = self.build_resblock(128, layer_blocks[1], stride=2)\n",
    "        self.layer3 = self.build_resblock(256, layer_blocks[2], stride=2)\n",
    "        self.layer4 = self.build_resblock(512, layer_blocks[3], stride=2)\n",
    "        \n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classe)\n",
    "    \n",
    "    def build_resblock(self, fliter_num, block_num, stride=1):\n",
    "        res_blocks = Sequential([])\n",
    "        # 2ä¸ªä¸åŒçš„blockä¹‹é—´ æ®‹å·®æ¨¡å—shortcutä¸Šä½¿ç”¨1x1å·ç§¯\n",
    "        res_blocks.add(ResBlock(fliter_num, stride))\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # å…¶ä»–çš„resblock  æ­¥é•¿å…¨ä¸º1\n",
    "            res_blocks.add(ResBlock(fliter_num, stride=1))\n",
    "        return res_blocks\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # æ ¹ç½‘ç»œ\n",
    "        x = self.stem(inputs)\n",
    "        # 4ä¸ªæ¨¡å—\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # æ± åŒ–å±‚\n",
    "        x = self.avgpool(x)\n",
    "        # å…¨è¿æ¥å±‚\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.GlobalAveragePooling2D?\n",
    "# ç©ºé—´ç»´åº¦(heightå’Œwidth)çš„å…¨å±€å¹³å‡ \n",
    "# Output shape:\n",
    "#     2D tensor with shape `(batch_size, channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(layer_blocks, input_shape, num_classe=10):\n",
    "    \"\"\"\n",
    "    layer_blocks: æ¯\"å±‚\"çš„æ®‹å·®æ¨¡å—æ•°é‡\n",
    "    \"\"\"\n",
    "    def resblock(X, fliter_num, stride=1):\n",
    "        \"\"\"\n",
    "        æ¯ä¸ªæ®‹å·®æ¨¡å—ç”±2ä¸ªå·ç§¯å±‚ç»„æˆ\n",
    "        \"\"\"\n",
    "        # é€šè¿‡è®¾ç½®ç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„å·ç§¯æ­¥é•¿ æ”¹å˜hå’Œw\n",
    "        conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        bn1 = layers.BatchNormalization()\n",
    "        relu = layers.ReLU()\n",
    "\n",
    "        # ç¬¬äºŒä¸ªå·ç§¯å±‚æ­¥é•¿ä¸º1\n",
    "        conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        bn2 = layers.BatchNormalization()\n",
    "\n",
    "        if stride != 1:  # F ä¸ xçš„å½¢çŠ¶ä¸ç›¸åŒ\n",
    "            downsample = layers.Conv2D(fliter_num, (1, 1), strides=stride)\n",
    "            # ä½¿ç”¨ 1X1 å·ç§¯æ ¸\n",
    "        else:\n",
    "            # ç›´æ¥è¿æ¥\n",
    "            downsample = lambda x:x\n",
    "\n",
    "        out = conv(X)\n",
    "        out = bn1(out)\n",
    "        out = relu(out)\n",
    "        out = conv2(out)\n",
    "        out = bn2(out)\n",
    "        identity = downsample(X)\n",
    "        # skip-connection \n",
    "        # out = layers.Add()([out, identity])\n",
    "        out = layers.add([out, identity])\n",
    "        out = layers.ReLU()(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def build_resblock(X, fliter_num, block_num, stride=1):\n",
    "\n",
    "        # ç¬¬ä¸€ä¸ªblock è¦æ³¨æ„è¿›è¡Œ 1x1å·ç§¯å¤„ç†\n",
    "\n",
    "        out = resblock(X, fliter_num, stride)\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # å…¶ä»–çš„resblock  æ­¥é•¿å…¨ä¸º1\n",
    "            out = resblock(out, fliter_num, stride=1)\n",
    "        return out\n",
    "    \n",
    "    X_inputs = Input(input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=input_shape)(X_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = build_resblock(x, 64, layer_blocks[0])\n",
    "    x = build_resblock(x, 128, layer_blocks[1], stride=2)\n",
    "    x = build_resblock(x, 256, layer_blocks[2], stride=2)k\n",
    "    x = build_resblock(x, 512, layer_blocks[3], stride=2)\n",
    "    \n",
    "    # ç©ºé—´ç»´åº¦(heightå’Œwidth)çš„å…¨å±€å¹³å‡ \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(num_classe)(x)\n",
    "    \n",
    "    model = Model(inputs=X_inputs, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10035200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*32*5*5*16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = resnet([2,2,2,2], (32, 32, 3), 10)\n",
    "plot_model(model2, show_shapes=True, to_file='ResNet18.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_dot(model2, show_shapes=True).write('ResNet18', prog='dot', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydot.Dot.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphviz.Source(model_to_dot(model2, show_shapes=True)).render('ResNet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet([2, 2, 2, 2], 10)\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*3+1)*64 + 4*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((3*3*64 +1) *64 *2 + 4*64*2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "hist = model2.fit(train_db, epochs=20, validation_data=test_db, validation_freq=4)\n",
    "model.save('resnet18.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "DenseNet å°†å‰é¢æ‰€æœ‰å±‚çš„ç‰¹å¾å›¾ä¿¡æ¯é€šè¿‡Skip Connection ä¸å½“å‰å±‚è¾“å‡ºè¿›è¡Œèšåˆï¼Œä¸ResNetçš„å¯¹åº”ä½ç½®ç›¸åŠ æ–¹å¼ä¸åŒï¼ŒDenseNet é‡‡ç”¨åœ¨é€šé“è½´ğ‘ç»´åº¦è¿›è¡Œæ‹¼æ¥æ“ä½œï¼Œèšåˆç‰¹å¾ä¿¡æ¯ã€‚\n",
    "\n",
    "DenseNet:\n",
    "\n",
    "https://github.com/liuzhuang13/DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python37664bittf2conda2a75a45106264ceab7472c43279a5d24",
   "language": "python",
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}