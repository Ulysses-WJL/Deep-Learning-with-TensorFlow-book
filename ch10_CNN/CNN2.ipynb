{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 与 VGG13 实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.family'] = ['SimHei'] # ['Noto Sans CJK JP']\n",
    "plt.rcParams['axes.unicode_minus']=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, losses, metrics, Sequential, layers, optimizers, Model, Input\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "import pydot\n",
    "# import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 1) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y):\n",
    "    X = tf.cast(X, dtype=tf.float32) / 255\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    return X, y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_db = train_db.shuffle(10000).batch(128).map(preprocessing)\n",
    "test_db = test_db.shuffle(10000).batch(128).map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_db))\n",
    "tf.reduce_max(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f8b401bb150>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 16, 16, 3])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
    "out_1 = pool_layer(X_train[4][np.newaxis])\n",
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([1, 32, 32, 3])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=1, padding='same')\n",
    "out_2 = pool_layer(X_train[4][tf.newaxis])\n",
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array_equal(out_1, out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 图片识别任务并不简单，这主要是由于 CIFAR10 的图片内容需要大量细节才能呈现，而保存的图片分辨率仅有32 × 32，使得部分主体信息较为模糊，甚至人眼都很难分辨。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 卷积子网络\n",
    "conv_layers = [\n",
    "    # 64个 3X3 的卷积核 输出与输入同大小\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(32,32,3)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    # 池化层 高宽减半\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling 单元2  输出通道提升至 128，高宽大小减半\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling 单元3  输出通道提升至 256，高宽大小减半\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling 单元4  输出通道提升至 512，高宽大小减半\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling 单元4  输出通道提升至 512，高宽大小减半\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),                       \n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu', input_shape=(1, 1, 512)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13 = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(VGG13, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 3 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 64 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*64 + 1) * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50000 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG13():\n",
    "    loss = []\n",
    "    acc = []\n",
    "    metric_acc = metrics.Accuracy()\n",
    "    optimizer = optimizers.Adam(0.0001)\n",
    "    conv_net.build(input_shape=(None, 32, 32, 3))\n",
    "    fc_net.build(input_shape=(None, 512)) \n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for step, (x, y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                out = VGG(x)\n",
    "                # print(out.shape)\n",
    "                # y_onehot = tf.one_hot(y, depth=10)\n",
    "                cost = losses.categorical_crossentropy(y, out, from_logits=True)\n",
    "                cost =tf.reduce_mean(cost)\n",
    "            grads = tape.gradient(cost, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss.append(float(cost))\n",
    "                print(f\"epoch: {epoch}, step: {step}, loss: {float(cost)}\")\n",
    "        \n",
    "        # 每个epoch 检测一次test\n",
    "        metric_acc.reset_states()\n",
    "        for x, y in test_db:\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, (-1, 512))\n",
    "\n",
    "            out = fc_net(out)\n",
    "            y_pred = tf.argmax(out, axis=-1)\n",
    "            metric_acc.update_state(y, y_pred)\n",
    "        print(f\"epoch :{epoch},  accuracy: {float(metric_acc.result())}\")\n",
    "        acc.append(float(metric_acc.result()))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积层变种\n",
    "\n",
    "### 空洞卷积(Dilated/Atrous Convolution)\n",
    "\n",
    "普通的卷积层为了减少网络的参数量，卷积核的设计通常选择较小的 $1\\times1$ 和$3 \\times 3$感受野大小。小卷积核使得网络提取特征时的感受野区域有限，但是增大感受野的区域又会增加网络的参数量和计算代价.\n",
    "\n",
    "空洞卷积在普通卷积的感受野上增加一个Dilation Rate 参数, 用于控制感受野区域的采样步长\n",
    "![](./空洞卷积.png)\n",
    "\n",
    "尽管Dilation Rate 的增大会使得感受野区域增大，但是实际参与运算的点数仍然保持不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([1, 7, 7, 1])\n",
    "# 空洞卷积  1个 3 X 3 的核\n",
    "layer = layers.Conv2D(1, kernel_size=(3, 3), strides=1, dilation_rate=2)\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转置卷积\n",
    "转置卷积(Transposed Convolution，或Fractionally Strided Convolution)通过在输入之间填充大量的padding 来实现输出高宽大于输入高宽的效果，从而实现向上采样的目的.转置卷积具有“**放大特征图**”的功能\n",
    "\n",
    "转置卷积与普通卷积并不是互为逆过程，不能恢复出对方的输入内容，仅能恢复出等大小的张量.\n",
    "\n",
    "例: \n",
    "- 输入$i = 2 \\times 2$ 单通道特征图, 转置卷积核$k=3 \\times 3$, 填充$p=0$, 步长$s=2$;\n",
    "- $2 \\times 2$ 内部均匀填充$s-1$个空白输入点 ---> $3 \\times 3$;\n",
    "- $3 \\times 3$ 周围填充$𝑘 − 𝑝 −1 = 3 − 0−1 = 2行/列$, ---> $7 \\times 7$;\n",
    "- $7 \\times 7$ 与 $3 \\times 3$的卷积核卷积, 步长$s' = 1$(固定), 填充$p=0$ ---> $o = 5 \\times 5$的输出;\n",
    "\n",
    "- 恢复: $5 \\times 5$ 与 $3 \\times 3$的卷积核卷积, 填充$p=0$, 步长$s=2$ ----> $2 \\times 2$的输入 \n",
    "\n",
    "在𝑜 + 2𝑝 − 𝑘为s 倍数时，满足关系:\n",
    "$$o = (i-1)s +k-2p$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(25) + 1\n",
    "# [b, h, w, c]\n",
    "x = tf.reshape(x, [1, 5, 5, 1])\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "# 3X3 卷积核\n",
    "w = tf.constant([[-1, 2, -3.], [4, -5, 6], [-7, 8, -9]])\n",
    "w = tf.expand_dims(w, axis=2)\n",
    "w =  tf.expand_dims(w, axis=3)\n",
    "# [f_w, f_h, c_in, c_out]\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[ -67.],\n",
       "         [ -77.]],\n",
       "\n",
       "        [[-117.],\n",
       "         [-127.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充0, 步长2\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d_transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将普通卷积作为转置卷积的输入\n",
    "# 输入:2*2   核:3*3\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   67.,  -134.,   278.,  -154.,   231.],\n",
       "       [ -268.,   335.,  -710.,   385.,  -462.],\n",
       "       [  586.,  -770.,  1620.,  -870.,  1074.],\n",
       "       [ -468.,   585., -1210.,   635.,  -762.],\n",
       "       [  819.,  -936.,  1942., -1016.,  1143.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(xx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积运算的输出大小\n",
    "$$o = ⌊\\frac {i + 2\\cdot p_h - k}{s}⌋ + 1$$\n",
    "当𝒐 + 𝟐𝒑 − 𝒌不为𝒔倍数时, 当s>1, 向下取整会使得多种不同大小的输入i得到相同大小的输出o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 2, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([1,6,6,1])\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 5, 5, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定output_shape 得到输出尺寸\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=3, padding='SAME', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.arange(16) + 1\n",
    "I = I.reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[1, 0, 1], [0, 0, 0], [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 1, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[..., np.newaxis, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[np.newaxis, ..., np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=170, shape=(1, 2, 2, 1), dtype=float32, numpy=\n",
       "array([[[[24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = tf.nn.conv2d(tf.cast(I[np.newaxis, ..., np.newaxis], dtype=tf.float32), K[..., np.newaxis, np.newaxis], strides=1, padding='VALID')\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=180, shape=(1, 4, 4, 1), dtype=float32, numpy=\n",
       "array([[[[24.],\n",
       "         [28.],\n",
       "         [24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.],\n",
       "         [40.],\n",
       "         [44.]],\n",
       "\n",
       "        [[24.],\n",
       "         [28.],\n",
       "         [24.],\n",
       "         [28.]],\n",
       "\n",
       "        [[40.],\n",
       "         [44.],\n",
       "         [40.],\n",
       "         [44.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只能恢复相同的形状\n",
    "tf.nn.conv2d_transpose(O,  K[..., np.newaxis, np.newaxis], strides=1, padding='VALID', output_shape=[1, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵角度理解\n",
    "普通Conv2d运算:\n",
    "- X:(4, 4), W:(3, 3), 步长为1，无padding\n",
    "- X打平X'(1, 16), W转为稀疏矩阵W'(4, 16)\n",
    "- 输出$O'= W'@X'$ (4,1), reshape 得到O(2, 2)\n",
    "\n",
    "转置卷积\n",
    "- $W'$转置后与$O'$矩阵相乘$X'=W'^T@O'$大小为(16, 1), reshape得到(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  转置卷积层\n",
    "\n",
    "- 当padding=’VALID’时，输出大小表达为:\n",
    "   $$o=(i-1)s+k$$\n",
    "- 当设置padding=’SAME’时，输出大小表达为:\n",
    "   $$o = i \\cdot s$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 4, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding='VALID')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 6, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=3, padding='SAME')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分离卷积(Separable Convolution)\n",
    "\n",
    "普通卷积在对多通道输入进行运算时，卷积核的每个通道与输入的每个通道分别进行卷积运算，得到多通道的特征图，再对应元素相加产生单个卷积核的最终输出\n",
    "$$输入[1, h, w, 3] \\odot 多卷积核[3, 3, 3, 4] \\rightarrow 中间特征 \\rightarrow \\sum对应元素求和 = \n",
    "输出[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "分离卷积流程:\n",
    "$$输入[1, h, w, 3] \\odot 单卷积核[3, 3, 3, 1] \\rightarrow 中间特征 \\rightarrow \\\\ \\odot 4个1\\times 1 卷积核[1, 1, 3, 4] =\n",
    "输出[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "可以看到，分离卷积层包含了两步卷积运算，第一步卷积运算是单个卷积核，第二个卷积运算包含了多个卷积核。\n",
    "\n",
    "优势:\n",
    "- 相同输入要产生相同大小输出, 分离卷积的参数量约是普通卷积的$\\frac 1 3$\n",
    "\n",
    "$1 \\times 1$卷积核的作用:\n",
    "- 实现信息的跨通道交互和整合。\n",
    "- 对卷积核通道数进行降维和升维，减小参数量, 降低计算成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度残差网络ResNet\n",
    "当模型加深以后，网络变得越来越难训练，这主要是由于**梯度弥散**和**梯度爆炸**现象造成的。在较深层数的神经网络中，梯度信息由网络的末层逐层传向网络的首层时，传递的过程中会出现梯度接近于0 或梯度值非常大的现象。网络层数越深，这种现象可能会越严重。\n",
    "\n",
    "通过在输入和输出之间添加一条直接连接的**Skip Connection**可以让神经网络具有回退的能力.它可以从某一层网络层获取激活，然后迅速反馈给另外一层，甚至是神经网络的更深层。我们可以利用跳跃连接构建能够训练深度网络的**ResNet**.\n",
    "\n",
    "### ResNet 原理\n",
    "ResNet 通过在卷积层的输入和输出之间添加Skip Connection 实现层数回退机制, 输入$x$通过2个卷积层, 得到特征变换后的输出$\\mathcal F(x)$, 与输入$x$进行对应元素的相加运算, 得到最终输出$\\mathcal H(x)$:\n",
    "$$\\mathcal H(x) = x + \\mathcal F(x)$$\n",
    "> 需要保持输入$x$的shape与$\\mathcal F(x)$的shape完全一致\n",
    "\n",
    "![](./残差模块.png)\n",
    "$\\mathcal H(x)$叫作残差模块(Residual Block, ResBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResBlock的实现\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, fliter_num, stride=1):\n",
    "        super().__init__()\n",
    "        # f(x)函数包括2个普通的卷积层\n",
    "        self.conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # 第二个卷积层步长为1,\n",
    "        self.conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1:  # F 与 x的形状不相同\n",
    "            self.downsample = Sequential()\n",
    "            # 使用 1X1 卷积核\n",
    "            self.downsample.add(layers.Conv2D(fliter_num, (1, 1), strides=stride))\n",
    "        else:\n",
    "            # 直接连接\n",
    "            self.downsample = lambda x:x\n",
    "            \n",
    "    def call(self, x):\n",
    "        # 前向传播  H(x) = x + F(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        identity = self.downsample(x)\n",
    "        \n",
    "        output = layers.add([out, identity])\n",
    "        # 得到H(x)后再进过激活函数 \n",
    "        output = tf.nn.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(Model):\n",
    "    def __init__(self, layer_blocks, num_classe=10):\n",
    "        super().__init__()\n",
    "         # 根网络\n",
    "        self.stem = Sequential([\n",
    "            layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=(32, 32, 3)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
    "        ])\n",
    "        # 4个block 每个block有多个残差模块\n",
    "        self.layer1 = self.build_resblock(64, layer_blocks[0])\n",
    "        self.layer2 = self.build_resblock(128, layer_blocks[1], stride=2)\n",
    "        self.layer3 = self.build_resblock(256, layer_blocks[2], stride=2)\n",
    "        self.layer4 = self.build_resblock(512, layer_blocks[3], stride=2)\n",
    "        \n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classe)\n",
    "    \n",
    "    def build_resblock(self, fliter_num, block_num, stride=1):\n",
    "        res_blocks = Sequential([])\n",
    "        # 2个不同的block之间 残差模块shortcut上使用1x1卷积\n",
    "        res_blocks.add(ResBlock(fliter_num, stride))\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # 其他的resblock  步长全为1\n",
    "            res_blocks.add(ResBlock(fliter_num, stride=1))\n",
    "        return res_blocks\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # 根网络\n",
    "        x = self.stem(inputs)\n",
    "        # 4个模块\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # 池化层\n",
    "        x = self.avgpool(x)\n",
    "        # 全连接层\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.GlobalAveragePooling2D?\n",
    "# 空间维度(height和width)的全局平均 \n",
    "# Output shape:\n",
    "#     2D tensor with shape `(batch_size, channels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(layer_blocks, input_shape, num_classe=10):\n",
    "    \"\"\"\n",
    "    layer_blocks: 每\"层\"的残差模块数量\n",
    "    \"\"\"\n",
    "    def resblock(X, fliter_num, stride=1):\n",
    "        \"\"\"\n",
    "        每个残差模块由2个卷积层组成\n",
    "        \"\"\"\n",
    "        # 通过设置第一个卷积层的卷积步长 改变h和w\n",
    "        conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        bn1 = layers.BatchNormalization()\n",
    "        relu = layers.ReLU()\n",
    "\n",
    "        # 第二个卷积层步长为1\n",
    "        conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        bn2 = layers.BatchNormalization()\n",
    "\n",
    "        if stride != 1:  # F 与 x的形状不相同\n",
    "            downsample = layers.Conv2D(fliter_num, (1, 1), strides=stride)\n",
    "            # 使用 1X1 卷积核\n",
    "        else:\n",
    "            # 直接连接\n",
    "            downsample = lambda x:x\n",
    "\n",
    "        out = conv(X)\n",
    "        out = bn1(out)\n",
    "        out = relu(out)\n",
    "        out = conv2(out)\n",
    "        out = bn2(out)\n",
    "        identity = downsample(X)\n",
    "        # skip-connection \n",
    "        # out = layers.Add()([out, identity])\n",
    "        out = layers.add([out, identity])\n",
    "        out = layers.ReLU()(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def build_resblock(X, fliter_num, block_num, stride=1):\n",
    "\n",
    "        # 第一个block 要注意进行 1x1卷积处理\n",
    "\n",
    "        out = resblock(X, fliter_num, stride)\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # 其他的resblock  步长全为1\n",
    "            out = resblock(out, fliter_num, stride=1)\n",
    "        return out\n",
    "    \n",
    "    X_inputs = Input(input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=input_shape)(X_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = build_resblock(x, 64, layer_blocks[0])\n",
    "    x = build_resblock(x, 128, layer_blocks[1], stride=2)\n",
    "    x = build_resblock(x, 256, layer_blocks[2], stride=2)k\n",
    "    x = build_resblock(x, 512, layer_blocks[3], stride=2)\n",
    "    \n",
    "    # 空间维度(height和width)的全局平均 \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(num_classe)(x)\n",
    "    \n",
    "    model = Model(inputs=X_inputs, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10035200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*32*5*5*16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = resnet([2,2,2,2], (32, 32, 3), 10)\n",
    "plot_model(model2, show_shapes=True, to_file='ResNet18.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_dot(model2, show_shapes=True).write('ResNet18', prog='dot', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydot.Dot.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphviz.Source(model_to_dot(model2, show_shapes=True)).render('ResNet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet([2, 2, 2, 2], 10)\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*3+1)*64 + 4*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((3*3*64 +1) *64 *2 + 4*64*2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "hist = model2.fit(train_db, epochs=20, validation_data=test_db, validation_freq=4)\n",
    "model.save('resnet18.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "DenseNet 将前面所有层的特征图信息通过Skip Connection 与当前层输出进行聚合，与ResNet的对应位置相加方式不同，DenseNet 采用在通道轴𝑐维度进行拼接操作，聚合特征信息。\n",
    "\n",
    "DenseNet:\n",
    "\n",
    "https://github.com/liuzhuang13/DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 = tf.keras.applications.ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python37664bittf2conda2a75a45106264ceab7472c43279a5d24",
   "language": "python",
   "display_name": "Python 3.7.6 64-bit ('tf2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}