{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 ä¸ VGG13 å®æˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "plt.rcParams['figure.figsize'] = [12, 10]\n",
    "plt.rcParams['font.family'] = ['SimHei'] # ['Noto Sans CJK JP']\n",
    "plt.rcParams['axes.unicode_minus']=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, losses, metrics, Sequential, layers, optimizers, Model, Input\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X, y):\n",
    "    X = tf.cast(X, dtype=tf.float32) / 255\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_db = train_db.shuffle(10000).batch(128).map(preprocessing)\n",
    "test_db = test_db.shuffle(10000).batch(128).map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_db))\n",
    "tf.reduce_max(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[4]/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same')\n",
    "out_1 = pool_layer(X_train[4][np.newaxis])\n",
    "out_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_layer = layers.MaxPool2D(pool_size=(2, 2), strides=1, padding='same')\n",
    "out_2 = pool_layer(X_train[4][np.newaxis])\n",
    "out_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.array_equal(out_1, out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 å›¾ç‰‡è¯†åˆ«ä»»åŠ¡å¹¶ä¸ç®€å•ï¼Œè¿™ä¸»è¦æ˜¯ç”±äº CIFAR10 çš„å›¾ç‰‡å†…å®¹éœ€è¦å¤§é‡ç»†èŠ‚æ‰èƒ½å‘ˆç°ï¼Œè€Œä¿å­˜çš„å›¾ç‰‡åˆ†è¾¨ç‡ä»…æœ‰32 Ã— 32ï¼Œä½¿å¾—éƒ¨åˆ†ä¸»ä½“ä¿¡æ¯è¾ƒä¸ºæ¨¡ç³Šï¼Œç”šè‡³äººçœ¼éƒ½å¾ˆéš¾åˆ†è¾¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. å·ç§¯å­ç½‘ç»œ\n",
    "conv_layers = [\n",
    "    # 64ä¸ª 3X3 çš„å·ç§¯æ ¸ è¾“å‡ºä¸è¾“å…¥åŒå¤§å°\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(32,32,3)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    # æ± åŒ–å±‚ é«˜å®½å‡åŠ\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ2  è¾“å‡ºé€šé“æå‡è‡³ 128ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ3  è¾“å‡ºé€šé“æå‡è‡³ 256ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ4  è¾“å‡ºé€šé“æå‡è‡³ 512ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    # Conv-Conv-Pooling å•å…ƒ4  è¾“å‡ºé€šé“æå‡è‡³ 512ï¼Œé«˜å®½å¤§å°å‡åŠ\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),                       \n",
    "    layers.Conv2D(512, kernel_size=(3, 3), padding='SAME', activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same'),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu', input_shape=(1, 1, 512)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13 = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(VGG13, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 3 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3 * 3 * 64 + 1) * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*64 + 1) * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50000 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG13():\n",
    "    loss = []\n",
    "    acc = []\n",
    "    metric_acc = metrics.Accuracy()\n",
    "    optimizer = optimizers.Adam(0.0001)\n",
    "    conv_net.build(input_shape=(None, 32, 32, 3))\n",
    "    fc_net.build(input_shape=(None, 512)) \n",
    "    variables = conv_net.trainable_variables + fc_net.trainable_variables\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for step, (x, y) in enumerate(train_db):\n",
    "            with tf.GradientTape() as tape:\n",
    "                out = VGG(x)\n",
    "                # print(out.shape)\n",
    "                # y_onehot = tf.one_hot(y, depth=10)\n",
    "                cost = losses.categorical_crossentropy(y, out, from_logits=True)\n",
    "                cost =tf.reduce_mean(cost)\n",
    "            grads = tape.gradient(cost, variables)\n",
    "            optimizer.apply_gradients(zip(grads, variables))\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                loss.append(float(cost))\n",
    "                print(f\"epoch: {epoch}, step: {step}, loss: {float(cost)}\")\n",
    "        \n",
    "        # æ¯ä¸ªepoch æ£€æµ‹ä¸€æ¬¡test\n",
    "        metric_acc.reset_states()\n",
    "        for x, y in test_db:\n",
    "            out = conv_net(x)\n",
    "            out = tf.reshape(out, (-1, 512))\n",
    "\n",
    "            out = fc_net(out)\n",
    "            y_pred = tf.argmax(out, axis=-1)\n",
    "            metric_acc.update_state(y, y_pred)\n",
    "        print(f\"epoch :{epoch},  accuracy: {float(metric_acc.result())}\")\n",
    "        acc.append(float(metric_acc.result()))\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å·ç§¯å±‚å˜ç§\n",
    "\n",
    "### ç©ºæ´å·ç§¯(Dilated/Atrous Convolution)\n",
    "\n",
    "æ™®é€šçš„å·ç§¯å±‚ä¸ºäº†å‡å°‘ç½‘ç»œçš„å‚æ•°é‡ï¼Œå·ç§¯æ ¸çš„è®¾è®¡é€šå¸¸é€‰æ‹©è¾ƒå°çš„ $1\\times1$ å’Œ$3 \\times 3$æ„Ÿå—é‡å¤§å°ã€‚å°å·ç§¯æ ¸ä½¿å¾—ç½‘ç»œæå–ç‰¹å¾æ—¶çš„æ„Ÿå—é‡åŒºåŸŸæœ‰é™ï¼Œä½†æ˜¯å¢å¤§æ„Ÿå—é‡çš„åŒºåŸŸåˆä¼šå¢åŠ ç½‘ç»œçš„å‚æ•°é‡å’Œè®¡ç®—ä»£ä»·.\n",
    "\n",
    "ç©ºæ´å·ç§¯åœ¨æ™®é€šå·ç§¯çš„æ„Ÿå—é‡ä¸Šå¢åŠ ä¸€ä¸ªDilation Rate å‚æ•°, ç”¨äºæ§åˆ¶æ„Ÿå—é‡åŒºåŸŸçš„é‡‡æ ·æ­¥é•¿\n",
    "![](./ç©ºæ´å·ç§¯.png)\n",
    "\n",
    "å°½ç®¡Dilation Rate çš„å¢å¤§ä¼šä½¿å¾—æ„Ÿå—é‡åŒºåŸŸå¢å¤§ï¼Œä½†æ˜¯å®é™…å‚ä¸è¿ç®—çš„ç‚¹æ•°ä»ç„¶ä¿æŒä¸å˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([1, 7, 7, 1])\n",
    "# ç©ºæ´å·ç§¯  1ä¸ª 3 X 3 çš„æ ¸\n",
    "layer = layers.Conv2D(1, kernel_size=(3, 3), strides=1, dilation_rate=2)\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è½¬ç½®å·ç§¯\n",
    "è½¬ç½®å·ç§¯(Transposed Convolutionï¼Œæˆ–Fractionally Strided Convolution)é€šè¿‡åœ¨è¾“å…¥ä¹‹é—´å¡«å……å¤§é‡çš„padding æ¥å®ç°è¾“å‡ºé«˜å®½å¤§äºè¾“å…¥é«˜å®½çš„æ•ˆæœï¼Œä»è€Œå®ç°å‘ä¸Šé‡‡æ ·çš„ç›®çš„.è½¬ç½®å·ç§¯å…·æœ‰â€œ**æ”¾å¤§ç‰¹å¾å›¾**â€çš„åŠŸèƒ½\n",
    "\n",
    "è½¬ç½®å·ç§¯ä¸æ™®é€šå·ç§¯å¹¶ä¸æ˜¯äº’ä¸ºé€†è¿‡ç¨‹ï¼Œä¸èƒ½æ¢å¤å‡ºå¯¹æ–¹çš„è¾“å…¥å†…å®¹ï¼Œä»…èƒ½æ¢å¤å‡ºç­‰å¤§å°çš„å¼ é‡.\n",
    "\n",
    "ä¾‹: \n",
    "- è¾“å…¥$i = 2 \\times 2$ å•é€šé“ç‰¹å¾å›¾, è½¬ç½®å·ç§¯æ ¸$k=3 \\times 3$, å¡«å……$p=0$, æ­¥é•¿$s=2$;\n",
    "- $2 \\times 2$ å†…éƒ¨å‡åŒ€å¡«å……$s-1$ä¸ªç©ºç™½è¾“å…¥ç‚¹ ---> $3 \\times 3$;\n",
    "- $3 \\times 3$ å‘¨å›´å¡«å……$ğ‘˜ âˆ’ ğ‘ âˆ’1 = 3 âˆ’ 0âˆ’1 = 2è¡Œ/åˆ—$, ---> $7 \\times 7$;\n",
    "- $7 \\times 7$ ä¸ $3 \\times 3$çš„å·ç§¯æ ¸å·ç§¯, æ­¥é•¿$s' = 1$(å›ºå®š), å¡«å……$p=0$ ---> $o = 5 \\times 5$çš„è¾“å‡º;\n",
    "\n",
    "- æ¢å¤: $5 \\times 5$ ä¸ $3 \\times 3$çš„å·ç§¯æ ¸å·ç§¯, å¡«å……$p=0$, æ­¥é•¿$s=2$ ----> $2 \\times 2$çš„è¾“å…¥ \n",
    "\n",
    "åœ¨ğ‘œ + 2ğ‘ âˆ’ ğ‘˜ä¸ºs å€æ•°æ—¶ï¼Œæ»¡è¶³å…³ç³»:\n",
    "$$o = (i-1)s +k-2p$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(25) + 1\n",
    "# [b, h, w, c]\n",
    "x = tf.reshape(x, [1, 5, 5, 1])\n",
    "x = tf.cast(x, dtype=tf.float32)\n",
    "\n",
    "# 3X3 å·ç§¯æ ¸\n",
    "w = tf.constant([[-1, 2, -3.], [4, -5, 6], [-7, 8, -9]])\n",
    "w = tf.expand_dims(w, axis=2)\n",
    "w =  tf.expand_dims(w, axis=3)\n",
    "# [f_w, f_h, c_in, c_out]\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¡«å……0, æ­¥é•¿2\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d_transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†æ™®é€šå·ç§¯ä½œä¸ºè½¬ç½®å·ç§¯çš„è¾“å…¥\n",
    "\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å·ç§¯è¿ç®—çš„è¾“å‡ºå¤§å°\n",
    "$$o = âŒŠ\\frac {i + 2\\cdot p_h - k}{s}âŒ‹ + 1$$\n",
    "å½“ğ’ + ğŸğ’‘ âˆ’ ğ’Œä¸ä¸ºğ’”å€æ•°æ—¶, å½“s>1, å‘ä¸‹å–æ•´ä¼šä½¿å¾—å¤šç§ä¸åŒå¤§å°çš„è¾“å…¥iå¾—åˆ°ç›¸åŒå¤§å°çš„è¾“å‡ºo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([1,6,6,1])\n",
    "out = tf.nn.conv2d(x, w, strides=2, padding='VALID')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 5, 5, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‡å®šoutput_shape å¾—åˆ°è¾“å‡ºå°ºå¯¸\n",
    "xx = tf.nn.conv2d_transpose(out, w, strides=2, padding='VALID', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = tf.nn.conv2d_transpose(out, w, strides=3, padding='SAME', output_shape=[1, 6, 6, 1])\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### çŸ©é˜µè§’åº¦ç†è§£\n",
    "æ™®é€šConv2dè¿ç®—:\n",
    "- X:(4, 4), W:(3, 3), æ­¥é•¿ä¸º1ï¼Œæ— padding\n",
    "- Xæ‰“å¹³X'(1, 16), Wè½¬ä¸ºç¨€ç–çŸ©é˜µW'(4, 16)\n",
    "- è¾“å‡º$O'= W'@X'$ (4,1), reshape å¾—åˆ°O(2, 2)\n",
    "\n",
    "è½¬ç½®å·ç§¯\n",
    "- $W'$è½¬ç½®åä¸$O'$çŸ©é˜µç›¸ä¹˜$X'=W'^T@O'$å¤§å°ä¸º(16, 1), reshapeå¾—åˆ°(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  è½¬ç½®å·ç§¯å±‚\n",
    "\n",
    "- å½“padding=â€™VALIDâ€™æ—¶ï¼Œè¾“å‡ºå¤§å°è¡¨è¾¾ä¸º:\n",
    "   $$o=(i-1)s+k$$\n",
    "- å½“è®¾ç½®padding=â€™SAMEâ€™æ—¶ï¼Œè¾“å‡ºå¤§å°è¡¨è¾¾ä¸º:\n",
    "   $$o = i \\cdot s$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=1, padding='VALID')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Conv2DTranspose(1, kernel_size=3, strides=3, padding='SAME')\n",
    "xx2 = layer(out)\n",
    "xx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†ç¦»å·ç§¯(Separable Convolution)\n",
    "\n",
    "æ™®é€šå·ç§¯åœ¨å¯¹å¤šé€šé“è¾“å…¥è¿›è¡Œè¿ç®—æ—¶ï¼Œå·ç§¯æ ¸çš„æ¯ä¸ªé€šé“ä¸è¾“å…¥çš„æ¯ä¸ªé€šé“åˆ†åˆ«è¿›è¡Œå·ç§¯è¿ç®—ï¼Œå¾—åˆ°å¤šé€šé“çš„ç‰¹å¾å›¾ï¼Œå†å¯¹åº”å…ƒç´ ç›¸åŠ äº§ç”Ÿå•ä¸ªå·ç§¯æ ¸çš„æœ€ç»ˆè¾“å‡º\n",
    "$$è¾“å…¥[1, h, w, 3] \\otimes å¤šå·ç§¯æ ¸[3, 3, 3, 4] \\rightarrow ä¸­é—´ç‰¹å¾ \\rightarrow \\sumå¯¹åº”å…ƒç´ æ±‚å’Œ = \n",
    "è¾“å‡º[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "åˆ†ç¦»å·ç§¯æµç¨‹:\n",
    "$$è¾“å…¥[1, h, w, 3] \\otimes å•å·ç§¯æ ¸[3, 3, 3, 1] \\rightarrow ä¸­é—´ç‰¹å¾ \\rightarrow \\\\ \\otimes 4ä¸ª1\\times 1 å·ç§¯æ ¸[1, 1, 3, 4] =\n",
    "è¾“å‡º[1, h', w', 4]\n",
    "$$\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°ï¼Œåˆ†ç¦»å·ç§¯å±‚åŒ…å«äº†ä¸¤æ­¥å·ç§¯è¿ç®—ï¼Œç¬¬ä¸€æ­¥å·ç§¯è¿ç®—æ˜¯å•ä¸ªå·ç§¯æ ¸ï¼Œç¬¬äºŒä¸ªå·ç§¯è¿ç®—åŒ…å«äº†å¤šä¸ªå·ç§¯æ ¸ã€‚\n",
    "\n",
    "ä¼˜åŠ¿:\n",
    "- ç›¸åŒè¾“å…¥è¦äº§ç”Ÿç›¸åŒå¤§å°è¾“å‡º, åˆ†ç¦»å·ç§¯çš„å‚æ•°é‡çº¦æ˜¯æ™®é€šå·ç§¯çš„$\\frac 1 3$\n",
    "\n",
    "$1 \\times 1$å·ç§¯æ ¸çš„ä½œç”¨:\n",
    "- å®ç°ä¿¡æ¯çš„è·¨é€šé“äº¤äº’å’Œæ•´åˆã€‚\n",
    "- å¯¹å·ç§¯æ ¸é€šé“æ•°è¿›è¡Œé™ç»´å’Œå‡ç»´ï¼Œå‡å°å‚æ•°é‡, é™ä½è®¡ç®—æˆæœ¬ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ·±åº¦æ®‹å·®ç½‘ç»œResNet\n",
    "å½“æ¨¡å‹åŠ æ·±ä»¥åï¼Œç½‘ç»œå˜å¾—è¶Šæ¥è¶Šéš¾è®­ç»ƒï¼Œè¿™ä¸»è¦æ˜¯ç”±äº**æ¢¯åº¦å¼¥æ•£**å’Œ**æ¢¯åº¦çˆ†ç‚¸**ç°è±¡é€ æˆçš„ã€‚åœ¨è¾ƒæ·±å±‚æ•°çš„ç¥ç»ç½‘ç»œä¸­ï¼Œæ¢¯åº¦ä¿¡æ¯ç”±ç½‘ç»œçš„æœ«å±‚é€å±‚ä¼ å‘ç½‘ç»œçš„é¦–å±‚æ—¶ï¼Œä¼ é€’çš„è¿‡ç¨‹ä¸­ä¼šå‡ºç°æ¢¯åº¦æ¥è¿‘äº0 æˆ–æ¢¯åº¦å€¼éå¸¸å¤§çš„ç°è±¡ã€‚ç½‘ç»œå±‚æ•°è¶Šæ·±ï¼Œè¿™ç§ç°è±¡å¯èƒ½ä¼šè¶Šä¸¥é‡ã€‚\n",
    "\n",
    "é€šè¿‡åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æ·»åŠ ä¸€æ¡ç›´æ¥è¿æ¥çš„**Skip Connection**å¯ä»¥è®©ç¥ç»ç½‘ç»œå…·æœ‰å›é€€çš„èƒ½åŠ›.å®ƒå¯ä»¥ä»æŸä¸€å±‚ç½‘ç»œå±‚è·å–æ¿€æ´»ï¼Œç„¶åè¿…é€Ÿåé¦ˆç»™å¦å¤–ä¸€å±‚ï¼Œç”šè‡³æ˜¯ç¥ç»ç½‘ç»œçš„æ›´æ·±å±‚ã€‚æˆ‘ä»¬å¯ä»¥åˆ©ç”¨è·³è·ƒè¿æ¥æ„å»ºèƒ½å¤Ÿè®­ç»ƒæ·±åº¦ç½‘ç»œçš„**ResNet**.\n",
    "\n",
    "### ResNet åŸç†\n",
    "ResNet é€šè¿‡åœ¨å·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºä¹‹é—´æ·»åŠ Skip Connection å®ç°å±‚æ•°å›é€€æœºåˆ¶, è¾“å…¥$x$é€šè¿‡2ä¸ªå·ç§¯å±‚, å¾—åˆ°ç‰¹å¾å˜æ¢åçš„è¾“å‡º$\\mathcal F(x)$, ä¸è¾“å…¥$x$è¿›è¡Œå¯¹åº”å…ƒç´ çš„ç›¸åŠ è¿ç®—, å¾—åˆ°æœ€ç»ˆè¾“å‡º$\\mathcal H(x)$:\n",
    "$$\\mathcal H(x) = x + \\mathcal F(x)$$\n",
    "> éœ€è¦ä¿æŒè¾“å…¥$x$çš„shapeä¸$\\mathcal F(x)$çš„shapeå®Œå…¨ä¸€è‡´\n",
    "\n",
    "![](./æ®‹å·®æ¨¡å—.png)\n",
    "$\\mathcal H(x)$å«ä½œæ®‹å·®æ¨¡å—(Residual Block, ResBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResBlockçš„å®ç°\n",
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, fliter_num, stride=1):\n",
    "        super().__init__()\n",
    "        # f(x)å‡½æ•°åŒ…æ‹¬2ä¸ªæ™®é€šçš„å·ç§¯å±‚\n",
    "        self.conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "        # ç¬¬äºŒä¸ªå·ç§¯å±‚æ­¥é•¿ä¸º1,\n",
    "        self.conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        \n",
    "        if stride != 1:  # F ä¸ xçš„å½¢çŠ¶ä¸ç›¸åŒ\n",
    "            self.downsample = Sequential()\n",
    "            # ä½¿ç”¨ 1X1 å·ç§¯æ ¸\n",
    "            self.downsample.add(layers.Conv2D(fliter_num, (1, 1), strides=stride))\n",
    "        else:\n",
    "            # ç›´æ¥è¿æ¥\n",
    "            self.downsample = lambda x:x\n",
    "            \n",
    "    def call(self, x):\n",
    "        # å‰å‘ä¼ æ’­  H(x) = x + F(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        identity = self.downsample(x)\n",
    "        \n",
    "        output = layers.add([out, identity])\n",
    "        # å¾—åˆ°H(x)åå†è¿›è¿‡æ¿€æ´»å‡½æ•° \n",
    "        output = tf.nn.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(Model):\n",
    "    def __init__(self, layer_dims, num_classe=10):\n",
    "        super().__init__()\n",
    "         # æ ¹ç½‘ç»œ\n",
    "        self.stem = Sequential([\n",
    "            layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=(32, 32, 3)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')\n",
    "        ])\n",
    "        # 4ä¸ªblock æ¯ä¸ªblockæœ‰å¤šä¸ªæ®‹å·®æ¨¡å—\n",
    "        self.layer1 = self.build_resblock(64, layer_dims[0])\n",
    "        self.layer2 = self.build_resblock(128, layer_dims[1], stride=2)\n",
    "        self.layer3 = self.build_resblock(256, layer_dims[2], stride=2)\n",
    "        self.layer4 = self.build_resblock(512, layer_dims[3], stride=2)\n",
    "        \n",
    "        self.avgpool = layers.GlobalAveragePooling2D()\n",
    "        self.fc = layers.Dense(num_classe)\n",
    "    \n",
    "    def build_resblock(self, fliter_num, block_num, stride=1):\n",
    "        res_block = Sequential([])\n",
    "        # ç¬¬ä¸€ä¸ªblock è¦æ³¨æ„è¿›è¡Œ 1x1å·ç§¯å¤„ç†\n",
    "        res_block.add(ResBlock(fliter_num, stride))\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # å…¶ä»–çš„resblock  æ­¥é•¿å…¨ä¸º1\n",
    "            res_block.add(ResBlock(fliter_num, stride=1))\n",
    "        return res_block\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # æ ¹ç½‘ç»œ\n",
    "        x = self.stem(inputs)\n",
    "        # 4ä¸ªæ¨¡å—\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # æ± åŒ–å±‚\n",
    "        x = self.avgpool(x)\n",
    "        # å…¨è¿æ¥å±‚\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(layer_dims, input_shape, num_classe=10):\n",
    "    def resblock(X, fliter_num, stride=1):\n",
    "        conv = layers.Conv2D(fliter_num, (3,3), strides=stride, padding='SAME')\n",
    "        bn1 = layers.BatchNormalization()\n",
    "        relu = layers.ReLU()\n",
    "\n",
    "        # ç¬¬äºŒä¸ªå·ç§¯å±‚æ­¥é•¿ä¸º1\n",
    "        conv2 = layers.Conv2D(fliter_num, (3,3), strides=1, padding='SAME')\n",
    "        bn2 = layers.BatchNormalization()\n",
    "\n",
    "        if stride != 1:  # F ä¸ xçš„å½¢çŠ¶ä¸ç›¸åŒ\n",
    "            downsample = layers.Conv2D(fliter_num, (1, 1), strides=stride)\n",
    "            # ä½¿ç”¨ 1X1 å·ç§¯æ ¸\n",
    "        else:\n",
    "            # ç›´æ¥è¿æ¥\n",
    "            downsample = lambda x:x\n",
    "\n",
    "        out = conv(X)\n",
    "        out = bn1(out)\n",
    "        out = relu(out)\n",
    "        out = conv2(out)\n",
    "        out = bn2(out)\n",
    "        identity = downsample(X)\n",
    "        out = layers.add([out, identity])\n",
    "        out = layers.ReLU()(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def build_resblock(X, fliter_num, block_num, stride=1):\n",
    "\n",
    "        # ç¬¬ä¸€ä¸ªblock è¦æ³¨æ„è¿›è¡Œ 1x1å·ç§¯å¤„ç†\n",
    "\n",
    "        out = resblock(X, fliter_num, stride)\n",
    "        \n",
    "        for _ in range(1, block_num):\n",
    "            # å…¶ä»–çš„resblock  æ­¥é•¿å…¨ä¸º1\n",
    "            out = resblock(out, fliter_num, stride=1)\n",
    "        return out\n",
    "    \n",
    "    X_inputs = Input(input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), input_shape=(32, 32, 3))(X_inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding='same')(x)\n",
    "    x = build_resblock(x, 64, layer_dims[0])\n",
    "    x = build_resblock(x, 128, layer_dims[1], stride=2)\n",
    "    x = build_resblock(x, 256, layer_dims[2], stride=2)\n",
    "    x = build_resblock(x, 512, layer_dims[3], stride=2)\n",
    "    \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    out = layers.Dense(num_classe)(x)\n",
    "    \n",
    "    model = Model(inputs=X_inputs, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = resnet([2,2,2,2], (32, 32, 3), 10)\n",
    "plot_model(model2, show_shapes=True, to_file='ResNet18.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_dot(model2, show_shapes=True).write('ResNet18', prog='dot', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydot.Dot.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphviz.Source(model_to_dot(model2, show_shapes=True)).render('ResNet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18([2, 2, 2, 2], 10)\n",
    "model.build(input_shape=(None, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3*3*3+1)*64 + 4*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((3*3*64 +1) *64 *2 + 4*64*2)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_db, epochs=20, validation_data=test_db, validation_freq=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "DenseNet å°†å‰é¢æ‰€æœ‰å±‚çš„ç‰¹å¾å›¾ä¿¡æ¯é€šè¿‡Skip Connection ä¸å½“å‰å±‚è¾“å‡ºè¿›è¡Œèšåˆï¼Œä¸ResNetçš„å¯¹åº”ä½ç½®ç›¸åŠ æ–¹å¼ä¸åŒï¼ŒDenseNet é‡‡ç”¨åœ¨é€šé“è½´ğ‘ç»´åº¦è¿›è¡Œæ‹¼æ¥æ“ä½œï¼Œèšåˆç‰¹å¾ä¿¡æ¯ã€‚\n",
    "\n",
    "DenseNet:\n",
    "\n",
    "https://github.com/liuzhuang13/DenseNet"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
