{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœºå™¨å­¦ä¹ çš„ä¸¤ç§åŸºæœ¬èŒƒå¼: ç›‘ç£å­¦ä¹ (Supervised Learning)å’Œæ— ç›‘ç£å­¦ä¹ (Unsupervised Learning).\n",
    "\n",
    "ä¸¤è€…æœ€ä¸»è¦çš„åŒºåˆ«æ˜¯åœ¨äºæ¨¡å‹åœ¨è®­ç»ƒæ—¶æ˜¯å¦éœ€è¦**äººå·¥æ ‡æ³¨**çš„**æ ‡ç­¾ä¿¡æ¯**ã€‚\n",
    "\n",
    "è‡ªç›‘ç£å­¦ä¹ (Self-Supervised Learning): ç®—æ³•æŠŠæ•°æ®**$x$æœ¬èº«**ä½œä¸ºç›‘ç£ä¿¡å·æ¥å­¦ä¹ . åˆ©ç”¨è¾…åŠ©ä»»åŠ¡ï¼ˆpretextï¼‰ä»å¤§è§„æ¨¡çš„æ— ç›‘ç£æ•°æ®ä¸­æŒ–æ˜è‡ªèº«çš„ç›‘ç£ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§æ„é€ çš„ç›‘ç£ä¿¡æ¯å¯¹ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œä»è€Œå¯ä»¥å­¦ä¹ åˆ°å¯¹ä¸‹æ¸¸ä»»åŠ¡æœ‰ä»·å€¼çš„è¡¨å¾.\n",
    "\n",
    "\n",
    "[è‡ªç›‘ç£å­¦ä¹ ](https://blog.csdn.net/sdu_hao/article/details/104515917) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªç¼–ç å™¨åŸç†\n",
    "\n",
    "æœ‰ç›‘ç£å­¦ä¹ ä¸­ç¥ç»ç½‘ç»œçš„åŠŸèƒ½å¯ä»¥çœ‹åšæ˜¯ç‰¹ç§é™ç»´(Dimensionality Reduction)çš„è¿‡ç¨‹: $é«˜ç»´è¾“å…¥ç‰¹å¾x \\rightarrow ä½ç»´å˜é‡o$.\n",
    "\n",
    "è‡ªç›‘ç£å­¦ä¹ åˆ©ç”¨æ•°æ®$x$æœ¬èº«ä½œä¸ºç›‘ç£ä¿¡å·æ¥æŒ‡å¯¼ç½‘ç»œçš„è®­ç»ƒï¼Œå³å¸Œæœ›ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°æ˜ å°„$f_{\\theta}: x \\rightarrow \\bar x$. å°†ç½‘ç»œåˆ†æˆä¸¤éƒ¨åˆ†:\n",
    "- $g_{\\theta_1}:x \\rightarrow z$, Encoderç½‘ç»œ: è¾“å…¥$x$æ•°æ®ç¼–ç æˆä½ç»´éšå˜é‡(Latent Variable).\n",
    "- $h_{\\theta_2}:z \\rightarrow \\bar x$, Decoderç½‘ç»œ: ç¼–ç è¿‡åçš„è¾“å…¥$z$è§£ç ä¸ºé«˜ç»´åº¦çš„$\\bar x$\n",
    "æŠŠæ•´ä¸ªæ¨¡å‹$f_{\\theta}$ç§°ä¸ºè‡ªåŠ¨ç¼–ç å™¨(Auto-Encoder)\n",
    "\n",
    "![è‡ªç¼–ç å™¨æ¨¡å‹](è‡ªç¼–ç å™¨æ¨¡å‹.png)\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›è§£ç å™¨çš„è¾“å‡ºèƒ½å¤Ÿå®Œç¾åœ°æˆ–è€…è¿‘ä¼¼é‡å»º(Reconstruct, æˆ–æ¢å¤)å‡ºåŸæ¥çš„è¾“å…¥, å³$\\bar x \\approx x$. ä¼˜åŒ–ç›®æ ‡å¯ä»¥å†™æˆ:\n",
    "$$\n",
    "Minimize L = dist(x, \\bar x) \\\\\n",
    "\\bar x = h_{\\theta_2}(g_{\\theta_1}(x))\n",
    "$$\n",
    "\n",
    "$dist$è·ç¦»åº¦é‡, å¸¸ç”¨æ¬§æ°è·ç¦»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "        tf.config.experimential.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32) / 255. \n",
    "X_test = X_test.astype(np.float32)/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åªéœ€è¦å›¾ç‰‡åŸå§‹æ•°æ® ä¸éœ€è¦æ ‡ç­¾y\n",
    "train_db = tf.data.Dataset.from_tensor_slices((X_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_db.take(1):\n",
    "    print(x.shape)\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_db = train_db.shuffle(10000).batch(BATCH_SIZE)\n",
    "test_db = test_db.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        # 784 -> 20\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(hid_dim)\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(784)\n",
    "        ])\n",
    "    def call(self, inputs, training=None):\n",
    "        hidden = self.encoder(inputs)\n",
    "        x = self.decoder(hidden)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.sigmoid_cross_entropy_with_logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_rec_logist = model(inp)\n",
    "        # æˆ–è€…ç›´æ¥ä½¿ç”¨MSEæŸå¤±\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=inp, logits=x_rec_logist)\n",
    "        loss =tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(images, name):\n",
    "    new_im  = Image.new('L', (280, 280))\n",
    "    index = 0\n",
    "    # 10è¡Œ 10åˆ—  100å¼  = 50 + 50 \n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = images[index] \n",
    "            im = Image.fromarray(im, mode='L')\n",
    "            # å°†å°å›¾ç‰‡å†™å…¥å¯¹åº”ä½ç½®  åˆ—æ–¹å‘æ’å¸ƒ\n",
    "            new_im.paste(im, (i, j))  # (xè½´, yè½´) ä¸€åˆ—\n",
    "            index += 1\n",
    "    new_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        loss = train_step(x)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {step}, Loss {float(loss)}\")\n",
    "    \n",
    "    # æ¯ä¸ªepoch è¿›è¡Œä¸€æ¬¡é‡å»º\n",
    "    x = next(iter(test_db))\n",
    "    logits = model(tf.reshape(x, [-1, 784]))\n",
    "    x_hat = tf.sigmoid(logits)  # å°†è¾“å‡ºè½¬æ¢ä¸º0è‡³1çš„åƒç´ å€¼ï¼Œä½¿ç”¨sigmoid å‡½æ•°\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28])  # æ¢å¤åŸæ¥å½¢çŠ¶\n",
    "    \n",
    "    # åŸå§‹å›¾ç‰‡ + é‡å»ºå›¾ç‰‡ å¯¹æ¯”\n",
    "    x_concat = tf.concat([x[:50], x_hat[:50]], axis=0)\n",
    "    x_concat = x_concat.numpy() * 255  # åƒç´ å€¼æ¢å¤\n",
    "    x_concat = x_concat.astype(np.uint8)\n",
    "    \n",
    "    save_image(x_concat, f\"ae_images/rec_epoch_{epoch}.png\")\n",
    "print('Time taken for {EPOCHS} epochs {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('ae_images/rec_epoch_99.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "b = tf.constant([[1, 1, 1], [0, 0, 0]])\n",
    "tf.concat([a, b], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªç¼–ç å™¨å˜ç§\n",
    "### Denising Auto-Encoder\n",
    "é˜²æ­¢ç¥ç»ç½‘ç»œè®°å¿†ä½è¾“å…¥æ•°æ®çš„åº•å±‚ç‰¹å¾, ç»™è¾“å…¥æ•°æ®æ·»åŠ éšæœºçš„å™ªå£°æ‰°åŠ¨:\n",
    "$$\n",
    "\\tilde x = x + \\epsilon, \\epsilon \\sim \\mathcal N(0, var)\n",
    "$$\n",
    "\n",
    "### Dropout Auto-Encoder\n",
    "åœ¨ç½‘ç»œå±‚ä¹‹é—´æ’å…¥Dropout å±‚å®ç°ç½‘ç»œè¿æ¥çš„éšå³æ–­å¼€, é˜²æ­¢è¿‡æ‹Ÿåˆ.\n",
    "\n",
    "### Adversarial Auto-Encoder\n",
    "å¯¹æŠ—è‡ªç¼–ç å™¨åˆ©ç”¨é¢å¤–çš„åˆ¤åˆ«å™¨ç½‘ç»œæ¥åˆ¤æ–­é™ç»´çš„éšè—å˜é‡$z$æ˜¯å¦é‡‡æ ·è‡ªå…ˆéªŒåˆ†å¸ƒ$P(z)$, æ–¹ä¾¿åˆ©ç”¨$P(z)$æ¥é‡å»ºè¾“å…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Auto-Encoder\n",
    "åŸºæœ¬çš„è‡ªç¼–ç å™¨æ˜¯ä¸€ä¸ªåˆ¤åˆ«æ¨¡å‹, è€Œä¸æ˜¯ç”Ÿæˆæ¨¡å‹. \n",
    "\n",
    "å˜åˆ†è‡ªç¼–ç å™¨(VAE)å¯ä»¥å®ç°ç»™å®šéšè—å˜é‡çš„åˆ†å¸ƒ$P(z)$, é€šè¿‡å­¦ä¹ æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$P(x|z)$, å¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(x, z) = P(x|z)P(z)$è¿›è¡Œé‡‡æ ·, ç”Ÿæˆä¸åŒçš„æ ·æœ¬.\n",
    "\n",
    "![VAE](VAE.png)\n",
    "\n",
    "å¯¹æ¯”è‡ªç¼–ç å™¨, VAEæ¨¡å‹å¯¹éšè—å˜é‡$z$çš„åˆ†å¸ƒæœ‰æ˜¾ç¤ºçš„çº¦æŸ, å¸Œæœ›å…¶ç¬¦åˆé¢„è®¾çš„å…ˆéªŒåˆ†å¸ƒ$P(z)$. å› æ­¤ï¼Œåœ¨æŸå¤±å‡½æ•°çš„è®¾è®¡ä¸Šï¼Œé™¤äº†åŸæœ‰çš„é‡å»ºè¯¯å·®é¡¹å¤–ï¼Œè¿˜æ·»åŠ äº†éšå˜é‡ğ’›åˆ†å¸ƒçš„çº¦æŸé¡¹ã€‚\n",
    "\n",
    "æœ€å¤§åŒ–ç›®æ ‡  \n",
    "$$L(\\phi, \\theta) = -D_{KL}(q_{\\phi}(z|x)||p(z)) + E_{z \\sim q}[log p_{\\theta}(x|z)]$$\n",
    "\n",
    "ç”¨ç¼–ç å™¨ç½‘ç»œå‚æ•°åŒ–$q_{\\phi}(z|x)$å‡½æ•°, è§£ç å™¨ç½‘ç»œå‚æ•°åŒ–$p_{\\theta}(x|z)$.\n",
    "\n",
    "ç‰¹åˆ«åœ°, å½“$q_{\\phi}(z|x)$å’Œ$p(z)$éƒ½ä¸º**æ­£æ€åˆ†å¸ƒ**æ—¶, ç¬¬ä¸€é¡¹æ•£åº¦çš„è®¡ç®—å¯ä»¥ç®€åŒ–ä¸º:\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p(z)) = log\\frac {\\sigma_2}{\\sigma_1} + \\frac {\\sigma_1^2 + (\\mu_1-\\mu_2)^2}{x\\sigma_2^2} - \\frac 1 2\n",
    "$$\n",
    "\n",
    "è¯¦ç»†æ¨å¯¼è¿‡ç¨‹: [KLæ•£åº¦æ¨å¯¼](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
