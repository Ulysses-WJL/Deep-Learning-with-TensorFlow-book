{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手写数字识别\n",
    "\n",
    "**图片的表示方法**\n",
    "\n",
    "一张图片包含了ℎ行(Height/Row)，𝑤列\n",
    "(Width/Column)，每个位置保存了像素(Pixel)值，像素值一般使用 0~255 的整形数值来表达\n",
    "颜色强度信息，例如 0 表示强度最低，255 表示强度最高。如果是彩色图片，则每个像素\n",
    "点包含了 R、G、B 三个通道的强度信息，分别代表红色通道、绿色通道、蓝色通道的颜\n",
    "色强度，所以与灰度图片不同，它的每个像素点使用一个 1 维、长度为 3 的向量(Vector)来\n",
    "表示，向量的 3 个元素依次代表了当前像素点上面的 R、G、B 颜色强值，因此彩色图片\n",
    "需要保存为形状是[ℎ, 𝑤, 3]的张量(Tensor，可以通俗地理解为 3 维数组)。如果是灰度图\n",
    "片，则使用一个数值来表示灰度强度，例如 0 表示纯黑，255 表示纯白，因此它只需要一\n",
    "个形状为[ℎ, 𝑤]的二维矩阵(Matrix)来表示一张图片信息(也可以保存为[ℎ, 𝑤, 1]形状的张\n",
    "量)。\n",
    "\n",
    "我们用形状为[ℎ, 𝑤]的矩阵来表示一张图片，\n",
    "对于多张图片来说，我们在前面添加一个数量维度(Dimension)，使用形状为[𝑏, ℎ, 𝑤]的张量\n",
    "来表示，其中𝑏代表了批量(Batch Size)；多张彩色图片可以使用形状为[𝑏, ℎ, 𝑤, 𝑐]的张量来\n",
    "表示，其中𝑐表示通道数量(Channel)，彩色图片𝑐 = 3。通过 TensorFlow 的 Dataset 对象可\n",
    "以方便完成模型的批量训练，只需要调用 batch()函数即可构建带 batch 功能的数据集对\n",
    "象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集 测试集\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()  # 加载 MNIST 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  # 60000个样本 每个28行28列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转为浮点张量 归一化 再缩放到-1 ~ 1\n",
    "x = 2 * tf.convert_to_tensor(x, dtype=tf.float32) / 255. - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(28, 28), dtype=float32, numpy=\n",
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.6       ,  0.24705887,  0.9843137 ,  0.24705887, -0.60784316,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.62352943,\n",
       "         0.8666667 ,  0.9764706 ,  0.9764706 ,  0.9764706 ,  0.85882354,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.5764706 ,  0.78039217,\n",
       "         0.9843137 ,  0.9764706 ,  0.8745098 ,  0.827451  ,  0.9764706 ,\n",
       "        -0.5529412 , -0.9529412 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.92156863, -0.5294118 ,  0.75686276,  0.9764706 ,\n",
       "         0.9843137 ,  0.9764706 ,  0.58431375, -0.34117645,  0.9764706 ,\n",
       "         0.9843137 , -0.04313725, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.27843142,  0.9764706 ,  0.9764706 ,  0.9764706 ,\n",
       "         0.9843137 ,  0.9764706 ,  0.9764706 , -0.24705881,  0.48235297,\n",
       "         0.9843137 ,  0.30980396, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.6       ,  0.8666667 ,  0.9843137 ,  0.9843137 ,  0.4901961 ,\n",
       "        -0.10588235,  0.9843137 ,  0.7882353 , -0.6313726 , -0.38039213,\n",
       "         1.        ,  0.3176471 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.62352943,\n",
       "         0.8666667 ,  0.9764706 ,  0.9764706 ,  0.4039216 , -0.90588236,\n",
       "        -0.41176468, -0.05098039, -0.8352941 , -1.        , -1.        ,\n",
       "         0.9843137 ,  0.90588236, -0.60784316, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.7019608 ,  0.2941177 ,\n",
       "         0.9843137 ,  0.827451  ,  0.6313726 , -0.34117645, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.9843137 ,  0.9764706 ,  0.2941177 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.94509804,  0.39607847,  0.9764706 ,\n",
       "         0.88235295, -0.44313723, -0.8509804 , -0.78039217, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.9843137 ,  0.9764706 ,  0.5294118 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.5529412 ,  0.9764706 ,  0.9764706 ,\n",
       "        -0.5058824 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.9843137 ,  0.9764706 ,  0.5294118 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.5529412 ,  0.9843137 ,  0.4901961 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         1.        ,  0.9843137 ,  0.5372549 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.40392154,  0.92941177,  0.9764706 , -0.12156862,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.9843137 ,  0.9764706 ,  0.16078436, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3333333 ,  0.9764706 ,  0.8039216 , -0.8039216 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.94509804,  0.05882359,\n",
       "         0.9843137 ,  0.45882356, -0.90588236, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3333333 ,  0.9764706 ,  0.7490196 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.94509804,  0.02745104,  0.9764706 ,\n",
       "         0.7647059 , -0.44313723, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3333333 ,  0.9764706 ,  0.13725495, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.62352943,  0.2941177 ,  0.9764706 ,  0.35686278,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.32549018,  0.9843137 ,  0.7647059 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.10588235,  0.8666667 ,  0.9843137 ,  0.27058828, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3333333 ,  0.9764706 ,  0.9529412 ,  0.14509809,\n",
       "        -0.62352943, -0.77254903, -0.3333333 ,  0.39607847,  0.7647059 ,\n",
       "         0.9843137 ,  0.7490196 ,  0.30980396, -0.56078434, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.3333333 ,  0.9764706 ,  0.9764706 ,  0.9764706 ,\n",
       "         0.79607844,  0.6862745 ,  0.9764706 ,  0.9764706 ,  0.9764706 ,\n",
       "         0.5372549 ,  0.0196079 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.78039217,  0.56078434,  0.9764706 ,  0.9764706 ,\n",
       "         0.9843137 ,  0.9764706 ,  0.9764706 ,  0.827451  ,  0.13725495,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.8039216 ,  0.00392163,  0.9764706 ,\n",
       "         0.9843137 ,  0.9764706 ,  0.10588241, -0.70980394, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换为整形张量\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot 独热码\n",
    "y_onehot = tf.one_hot(y, depth=10)\n",
    "y_onehot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "对于多输出节点、批量训练方式，我们将模型写成批量形式：\n",
    "$$Y = X@W + b$$\n",
    "其中$𝑿 \\in 𝑅^{b × 𝑑_{in}}，𝒃 ∈ 𝑅^{d_{out}}，𝒀 ∈ 𝑅^{b \\times d_{out}}，𝑾 \\in R^{d_{in} \\times d_{out}}，d_{in}表示输入节点数，d_{out}表示输出节点数$\n",
    "输出节点数𝑿形状为$[b, d_{in}]$，表示𝑏个样本的输入数据，每个样本的特征长度为$d_{in}$\n",
    "\n",
    "输入特征长度$d_{in} = 3，输出特征长度d_{out} = 2$的模型\n",
    "\n",
    "![模型](../assets/3输入2输出模型.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = tf.constant([0, 1, 2, 3])\n",
    "y4 = tf.one_hot(y, depth=10)  # 指定类别总数为 10\n",
    "y4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入是一张展平后的图片向量$x \\in R^{784}$, 输出是长度为10的向量$o \\in R^{10}$\n",
    "\n",
    "预测模型采用多输入、多输出的线性模型 $o = 𝑾^𝐓𝒙 + 𝒃，$\n",
    "其中模型的输出记为输入的预测值 ，我们希望 越接近真实标签𝒚越好。一般把输入经过\n",
    "一次(线性)变换叫作一层网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 误差计算\n",
    "对于分类问题来说，我们的目标是最大化某个性能指标，比如准确度𝑎𝑐𝑐，但是把准确度当作损失函数去优化时发现$\\frac {\\partial{acc}} {\\partial \\theta}$不可导, 无法利用梯度下降算法优化网络参数.一般的做法是，设立一个平滑可导的代理目标函数，比如优化模型的输出 与 One-hot 编码后的真实标签𝒚之间的**距离**(Distance)，通过优化代理目标函数得到的模型，一般在测试性能上也能有良好的表现。因此，相对回归问题而言，分类问题的优化目标函数和评价目标函数是不一致的。\n",
    "$$W^*, b^* = argmin_{w, b} L(o, y)$$\n",
    "\n",
    "对n个样本的**均方差损失函数**可以表达为\n",
    "$$L(o, y) = \\frac 1 n \\sum_{i=1}^n\\sum_{j=1}^{10}(o_j^{(i)} - y_j^{(i)})^2$$\n",
    "\n",
    "## 存在的问题\n",
    "1. 线性模型过于简单, 逼近复杂的人脑图片识别模型，很显然不能胜任\n",
    "1. 表达能力, 表达能力体现为逼近复杂分布的能力。上面的解决方案只使用了少量神经元组成的一层网络模型，相对于人脑中千亿级别的神经元互联结构，它的表达能力明显偏弱\n",
    "\n",
    "\n",
    "## 解决与优化\n",
    "### 非线性模型\n",
    "给线性模型嵌套一个非线性函数, 将其转为非线性模型, 我们把这个非线性函数称为**激活函数**(Activation Function)，用𝜎表示:\n",
    "$$o = \\sigma(Wx + b)$$\n",
    "![激活函数](../assets/激活函数.png)\n",
    "\n",
    "ReLU 函数非常简单，在𝑦 = 𝑥的基础上面截去了𝑥 < 0的部分，可以直观地理解为\n",
    "ReLU 函数仅保留正的输入部份，清零负的输入，具有单边抑制特性。虽然简单，ReLU 函\n",
    "数却有优良的非线性特性，而且梯度计算简单，训练稳定，是深度学习模型使用最广泛的\n",
    "激活函数之一。\n",
    "### 表达能力\n",
    "通过重复堆叠多次变换来增加其表达能力:\n",
    "$$h_1 = ReLU(W_1x + b_1) \\\\\n",
    "h_2 = ReLU(W_2h_1 + b_2) \\\\\n",
    "o = W_3x + b_3 \\\\\n",
    "$$\n",
    "这种由大量神经元模型连接形成的网络结构称为 **神经网络**(Neural Network)。\n",
    "![3层神经网络](../assets/神经网络.png)\n",
    "\n",
    "### 自动求导(Autograd)技术\n",
    "深度学习框架在计算神经网络每层的输出以及损失函数的过程中，会构建神经网络的计算图模\n",
    "型，并自动完成任意参数𝜃的偏导数$\\frac {\\partial L}{\\partial \\theta}$的计算."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络搭建与模型训练\n",
    "Tensorflow创建网络:\n",
    "```\n",
    "# 创建一层网络，设置输出节点数为 256，激活函数类型为 ReLU\n",
    "layers.Dense(256, activation='relu')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 Sequential 容器封装 3 个网络层，前网络层的输出默认作为下一层的输入\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(256, activation='relu'),  # 隐藏层1\n",
    "    layers.Dense(128, activation='relu'),  # 隐藏层2\n",
    "    layers.Dense(10)  # 输出层\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    # 打平操作，[b, 28, 28] => [b, 784]\n",
    "    x = tf.reshape(x, (-1, 28 * 28))\n",
    "    # 1. 得到输出 [b, 784] -> [b, 10]\n",
    "    out = model(x)\n",
    "    # 标记 转为独热码\n",
    "    y_onehot = tf.one_hot(y, depth=10)\n",
    "    # 2. 计算MSE [b, 10]\n",
    "    loss = tf.square(out - y_onehot)\n",
    "    # 计算每个样本的平均误差，[b]\n",
    "    loss = tf.reduce_sum(loss) / x.shape[0]\n",
    "\n",
    "# 3. 自动求参数的梯度 w1, w2, b1, b2, b3\n",
    "grads = tape.gradient(loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(784, 256), dtype=float32, numpy=\n",
       " array([[-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ],\n",
       "        [-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ],\n",
       "        [-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ],\n",
       "        ...,\n",
       "        [-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ],\n",
       "        [-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ],\n",
       "        [-0.08695788,  0.19670847,  0.1478161 , ..., -0.11330766,\n",
       "         -0.14674997, -0.1735056 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(256,), dtype=float32, numpy=\n",
       " array([ 8.69578794e-02, -1.96708366e-01, -1.47816166e-01,  8.03603418e-03,\n",
       "         5.00847772e-02, -1.84981555e-01,  3.93848836e-01,  2.42552996e-01,\n",
       "         7.53916427e-02,  1.08437844e-01, -2.36854747e-01,  4.14955488e-04,\n",
       "        -1.01505868e-01,  9.33763087e-02, -5.51615022e-02, -4.94455367e-01,\n",
       "        -9.64955986e-02, -6.91962540e-02,  5.14428735e-01,  2.58474232e-04,\n",
       "         3.44481841e-02,  4.72093970e-01,  1.55329123e-01, -6.35847868e-03,\n",
       "        -2.82190204e-01,  2.86034048e-01,  3.46703112e-01, -2.95182839e-02,\n",
       "         4.76536416e-02,  7.31955543e-02,  4.98122513e-01, -1.13264896e-01,\n",
       "         5.19565167e-03, -5.04475320e-03,  4.23062682e-01, -4.39122990e-02,\n",
       "        -9.87800770e-04, -2.21238643e-01,  1.78306177e-02,  3.28227013e-01,\n",
       "        -4.15215082e-02, -5.92432693e-02,  1.62543014e-01,  1.39876232e-01,\n",
       "        -1.71086788e-02, -1.07585661e-01,  3.42058927e-01,  2.22106338e-01,\n",
       "         1.53713319e-02,  1.10416114e-02, -4.69182730e-02,  1.01575720e+00,\n",
       "         8.07199836e-01, -1.24517962e-01, -4.72994596e-02,  1.66105181e-01,\n",
       "        -1.69382542e-02, -2.09291473e-01, -7.93207623e-03,  7.19078034e-02,\n",
       "        -6.91771694e-03,  1.17878513e-02, -1.95475947e-02,  6.90978672e-03,\n",
       "         1.35404672e-02,  9.73487869e-02, -3.61296594e-01, -1.76752731e-02,\n",
       "        -1.41946543e-02, -8.41533616e-02, -2.61493683e-01,  3.74731757e-02,\n",
       "         7.72943022e-05,  1.07110694e-01,  4.03709263e-02,  2.00712960e-03,\n",
       "         9.95224714e-01,  7.13074300e-03,  1.00734003e-03, -1.06374882e-02,\n",
       "        -1.94345444e-01,  4.23208475e-02, -2.02946588e-01,  9.97437760e-02,\n",
       "         6.81419373e-01, -5.69663569e-02,  2.29888722e-01,  3.09246359e-03,\n",
       "         1.65225148e-01, -3.11013181e-02,  2.97024280e-01,  4.63230014e-02,\n",
       "         3.76088887e-01,  1.98055580e-02,  4.68116999e-01, -1.36083141e-01,\n",
       "         2.77951756e-03,  3.88169765e-01,  2.36040418e-04, -1.80726454e-01,\n",
       "         3.33718993e-02, -3.72991338e-02, -5.03678918e-01, -1.19184010e-01,\n",
       "        -1.90550759e-01,  1.00466505e-01,  3.39717954e-01,  4.65909280e-02,\n",
       "        -4.34699059e-01,  5.81350783e-03, -3.01332355e-01,  4.58646655e-01,\n",
       "        -2.02241745e-02,  2.30142772e-01,  9.67186131e-03, -8.30595374e-01,\n",
       "         1.95754960e-01,  5.18569905e-05,  7.38787591e-01,  8.39896649e-02,\n",
       "        -2.41846517e-01,  1.00734895e-02,  3.99037171e-03, -2.02345625e-02,\n",
       "         2.94970989e-01, -1.58451259e-01, -1.89679937e-04,  1.29732937e-01,\n",
       "         5.06259799e-01,  2.60663964e-03,  2.43217379e-01, -1.76412299e-01,\n",
       "        -2.34127194e-01, -2.34232706e-04, -3.49693358e-01, -2.20937636e-02,\n",
       "        -5.00872098e-02,  2.88538039e-01,  2.63757646e-01, -2.63982266e-01,\n",
       "         4.52163965e-02,  9.00683105e-02, -2.73501039e-01,  2.33973376e-04,\n",
       "        -5.21576777e-02,  5.19439168e-02,  5.19771278e-02, -5.61910570e-02,\n",
       "         1.32498308e-03, -2.59768427e-03,  6.24357939e-01,  7.93583021e-02,\n",
       "        -2.18085185e-01,  3.64392251e-02,  3.52734029e-01, -2.09552925e-02,\n",
       "         5.19804731e-02,  3.86747956e-01,  4.24557328e-02,  1.69704989e-01,\n",
       "        -6.11944171e-03, -1.87325776e-01,  3.79853472e-02,  9.82677098e-03,\n",
       "         7.04184026e-02,  1.35578156e-01,  1.45750195e-02,  3.25408429e-02,\n",
       "        -6.97501469e-03, -4.91478277e-05,  2.81917572e-01,  1.65051475e-01,\n",
       "         1.05672423e-02, -5.30414321e-02, -4.99875098e-02, -2.51547098e-02,\n",
       "        -8.31772611e-02,  6.54649734e-02,  1.26293987e-01, -3.45515199e-02,\n",
       "        -9.64670908e-03, -4.23654728e-03,  1.56612635e-01, -4.76788759e-04,\n",
       "         2.01094728e-02, -1.25809722e-02,  5.43837667e-01, -3.99097681e-01,\n",
       "         1.05031826e-01,  3.17450583e-01, -4.63978723e-02, -3.14067714e-02,\n",
       "        -2.89402604e-01,  2.52075697e-04,  5.80625683e-02, -6.78258166e-02,\n",
       "        -5.15781045e-02, -1.13104507e-01, -2.55886585e-01, -4.45427179e-01,\n",
       "        -1.85445294e-01,  1.30438595e-03, -1.64738074e-02,  1.23470500e-01,\n",
       "         4.79952842e-01, -6.48208335e-02, -1.59630194e-01,  1.66003525e-01,\n",
       "         0.00000000e+00, -1.87462598e-01,  3.07774574e-01, -5.29257238e-01,\n",
       "        -9.84906480e-02,  1.89396596e-04, -2.36945376e-02,  1.06409140e-01,\n",
       "        -6.79061487e-02,  8.31337199e-02,  7.70973980e-01,  4.52442765e-01,\n",
       "        -1.07822202e-01, -9.17879632e-04,  2.41981879e-01,  1.05583726e-03,\n",
       "        -2.09511770e-03,  8.66596401e-02,  4.12290916e-03,  1.68553591e-02,\n",
       "        -5.27874641e-02,  5.06514609e-02, -1.63224876e-01, -6.64842362e-03,\n",
       "         2.93295920e-01,  2.30684966e-01,  5.83726764e-01, -1.64888367e-01,\n",
       "        -2.26123765e-01, -2.51107752e-01, -7.93155208e-02, -7.68058971e-02,\n",
       "        -2.43352558e-02,  7.74934053e-01,  4.50883895e-01,  1.50792435e-01,\n",
       "        -1.63114257e-02, -1.44083500e-01,  4.35976714e-01, -7.79106840e-02,\n",
       "        -1.82701811e-01,  4.46939290e-01, -4.10729051e-01, -2.19288483e-01,\n",
       "         4.46832359e-01,  1.13307655e-01,  1.46750063e-01,  1.73505425e-01],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(256, 128), dtype=float32, numpy=\n",
       " array([[-2.87385006e-02, -1.67959649e-03, -1.10338486e-04, ...,\n",
       "          1.76973140e-03, -2.51133833e-02, -7.27472478e-04],\n",
       "        [-9.44836065e-02, -2.54136254e-03, -7.21237855e-04, ...,\n",
       "          4.89918962e-02,  2.90175099e-02,  2.81325600e-04],\n",
       "        [-1.04065128e-01, -4.59046615e-03, -3.36963683e-04, ...,\n",
       "          3.49275060e-02, -3.72301191e-02, -5.11116406e-04],\n",
       "        ...,\n",
       "        [-3.46294008e-02, -1.16622832e-03, -1.59720621e-05, ...,\n",
       "          1.84270348e-02, -7.61073641e-03, -2.32995575e-04],\n",
       "        [-2.53267109e-01, -4.37453622e-03, -1.76948158e-03, ...,\n",
       "          1.43986791e-02, -3.03863790e-02, -9.57951008e-04],\n",
       "        [-4.57167625e-01, -5.13284234e-03, -2.32820376e-03, ...,\n",
       "          9.98292863e-02,  1.64602976e-02, -2.31245952e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-4.6126962e-01, -9.5842239e-03, -2.7583931e-03, -3.6417041e-02,\n",
       "        -3.4346664e-01, -1.2184125e-02,  9.5746613e-01, -1.5893198e+00,\n",
       "        -4.3361783e-02,  7.2266531e-01,  5.8153892e-01,  1.0346619e+00,\n",
       "         6.6990215e-01,  2.6425235e-03,  8.0051282e-03, -2.5866416e-03,\n",
       "         2.7365448e-02,  8.8905001e-01,  3.9252979e-01, -7.0310585e-02,\n",
       "         1.5736859e-01,  7.2261691e-01,  4.4997454e-01,  4.6828756e-01,\n",
       "        -1.1492572e-01, -2.7523616e-02,  3.1474873e-01,  3.2765529e-04,\n",
       "         4.3967348e-03,  1.0648995e-01, -5.9088913e-04,  2.0578197e-01,\n",
       "        -4.0338747e-03,  2.9889499e-03,  8.8775826e-01, -1.9458175e-02,\n",
       "        -5.2548611e-01,  5.1400460e-02,  1.7017072e-01,  1.2999299e-01,\n",
       "        -5.2441216e-01, -3.2813314e-01,  2.2329107e-02, -4.3096441e-01,\n",
       "         8.4912658e-01,  4.7640126e-02, -2.6362517e-01,  1.3422501e-01,\n",
       "         6.0193878e-01, -1.6208446e-01, -6.6114545e-01,  1.4140984e-01,\n",
       "         7.8908473e-02, -2.8256157e-01, -5.4290849e-01,  4.7171224e-02,\n",
       "         1.9298217e+00,  2.8051937e-01, -3.1182337e-01,  1.1032815e-03,\n",
       "        -2.3342454e-01, -1.0687439e-01, -6.5999497e-03,  7.9426929e-02,\n",
       "        -2.1129777e-01,  4.4224150e-02, -7.0607588e-02,  7.6176846e-01,\n",
       "         1.2607335e-01, -1.5558164e-01, -1.4357234e-05, -6.6844687e-02,\n",
       "         6.3426316e-02, -3.7721789e-01,  7.2906397e-02,  3.3895154e-03,\n",
       "         8.2257336e-01,  1.8854834e-02,  1.3213885e+00,  5.2858794e-01,\n",
       "         1.5903299e-01,  2.6669225e-01, -6.8175077e-01,  5.0715792e-01,\n",
       "         2.4775299e-01,  4.3658084e-01,  3.8097656e-01,  5.5098099e-01,\n",
       "         2.1860385e-01, -2.2688694e-03,  1.7841591e-01,  1.5265158e-01,\n",
       "        -2.0464750e-02, -3.7498141e-03,  1.1404705e-03,  3.8869041e-01,\n",
       "         3.1581444e-01,  7.1736097e-01, -4.0615422e-01, -1.1119562e-01,\n",
       "         1.1144091e-01, -1.8566466e-03,  7.6530409e-01, -8.0140671e-03,\n",
       "        -3.6377487e-01,  2.0903642e-01,  5.8268631e-01, -3.6344059e-02,\n",
       "        -4.9834853e-01,  5.7848042e-01,  4.6486744e-01, -5.7614434e-01,\n",
       "        -1.3804051e-01, -2.2000238e-01,  6.0264492e-01, -3.9377981e-01,\n",
       "         3.1328678e-01,  1.2859297e-01,  1.4357302e-01,  3.3983302e-01,\n",
       "         8.2662070e-01,  4.5059246e-01, -7.8512740e-01,  4.9858462e-02,\n",
       "        -3.2799637e-01,  3.7616275e-02, -3.5337619e-02, -1.8893360e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(128, 10), dtype=float32, numpy=\n",
       " array([[-3.3759423e-02, -1.2118455e+00,  6.6449147e-01, ...,\n",
       "         -2.1099499e-01, -1.4495118e+00, -8.4521472e-01],\n",
       "        [ 1.0379939e-03, -3.2739356e-02,  1.7132979e-02, ...,\n",
       "         -2.7448728e-03, -5.6138001e-02, -3.8834337e-02],\n",
       "        [-3.2568678e-05, -1.1179280e-03,  5.9852633e-04, ...,\n",
       "          4.0136230e-05, -1.1809258e-03, -8.4979023e-04],\n",
       "        ...,\n",
       "        [ 2.1916160e-02, -5.5025512e-01,  2.3215924e-01, ...,\n",
       "         -9.4778217e-02, -6.9556773e-01, -4.1208184e-01],\n",
       "        [-3.2368690e-02, -3.8561387e+00,  1.9699702e+00, ...,\n",
       "         -6.5690887e-01, -5.0020933e+00, -2.7507229e+00],\n",
       "        [-1.2500968e-03, -7.5086928e-03,  2.9811764e-03, ...,\n",
       "         -2.4943501e-03, -1.6220525e-02, -4.9523311e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-0.04020382, -2.460812  ,  1.1754091 ,  1.3764904 , -1.1156306 ,\n",
       "         1.0392774 , -1.3699034 , -0.39252993, -3.2938404 , -1.8595289 ],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w' = w - lr * grad  更新网络参数\n",
    "optimizer = optimizers.SGD(learning_rate=0.001)\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n",
      "batch: (128, 28, 28) (128,)\n",
      "0 0 loss: 0.31656497716903687\n",
      "0 100 loss: 0.1851351261138916\n",
      "0 200 loss: 0.1665676087141037\n",
      "0 300 loss: 0.15423361957073212\n",
      "0 400 loss: 0.14350882172584534\n",
      "1 0 loss: 0.14270949363708496\n",
      "1 100 loss: 0.1403971165418625\n",
      "1 200 loss: 0.13887163996696472\n",
      "1 300 loss: 0.13398948311805725\n",
      "1 400 loss: 0.12479253113269806\n",
      "2 0 loss: 0.12567129731178284\n",
      "2 100 loss: 0.12432394176721573\n",
      "2 200 loss: 0.12286865711212158\n",
      "2 300 loss: 0.12174089252948761\n",
      "2 400 loss: 0.11251477897167206\n",
      "3 0 loss: 0.11412574350833893\n",
      "3 100 loss: 0.11319521814584732\n",
      "3 200 loss: 0.11169705539941788\n",
      "3 300 loss: 0.11286316066980362\n",
      "3 400 loss: 0.10379419475793839\n",
      "4 0 loss: 0.10550825297832489\n",
      "4 100 loss: 0.1049845814704895\n",
      "4 200 loss: 0.10344429314136505\n",
      "4 300 loss: 0.10603471100330353\n",
      "4 400 loss: 0.09719939529895782\n",
      "5 0 loss: 0.09885609894990921\n",
      "5 100 loss: 0.09863182157278061\n",
      "5 200 loss: 0.09711115062236786\n",
      "5 300 loss: 0.10061417520046234\n",
      "5 400 loss: 0.09209538996219635\n",
      "6 0 loss: 0.09358290582895279\n",
      "6 100 loss: 0.09351484477519989\n",
      "6 200 loss: 0.09205757081508636\n",
      "6 300 loss: 0.09616579860448837\n",
      "6 400 loss: 0.08798085153102875\n",
      "7 0 loss: 0.08927859365940094\n",
      "7 100 loss: 0.08931329101324081\n",
      "7 200 loss: 0.08790389448404312\n",
      "7 300 loss: 0.09243370592594147\n",
      "7 400 loss: 0.08463039249181747\n",
      "8 0 loss: 0.08565458655357361\n",
      "8 100 loss: 0.08578512817621231\n",
      "8 200 loss: 0.08441809564828873\n",
      "8 300 loss: 0.08922435343265533\n",
      "8 400 loss: 0.08181606233119965\n",
      "9 0 loss: 0.08256666362285614\n",
      "9 100 loss: 0.08276521414518356\n",
      "9 200 loss: 0.0814698114991188\n",
      "9 300 loss: 0.08644679933786392\n",
      "9 400 loss: 0.07942043244838715\n",
      "10 0 loss: 0.07988886535167694\n",
      "10 100 loss: 0.08016091585159302\n",
      "10 200 loss: 0.07893936336040497\n",
      "10 300 loss: 0.08396411687135696\n",
      "10 400 loss: 0.07734760642051697\n",
      "11 0 loss: 0.07756723463535309\n",
      "11 100 loss: 0.0779024213552475\n",
      "11 200 loss: 0.07672754675149918\n",
      "11 300 loss: 0.08173669874668121\n",
      "11 400 loss: 0.0755334123969078\n",
      "12 0 loss: 0.07551909983158112\n",
      "12 100 loss: 0.07593132555484772\n",
      "12 200 loss: 0.07477987557649612\n",
      "12 300 loss: 0.07975266873836517\n",
      "12 400 loss: 0.07392998784780502\n",
      "13 0 loss: 0.07368417829275131\n",
      "13 100 loss: 0.07418185472488403\n",
      "13 200 loss: 0.07303376495838165\n",
      "13 300 loss: 0.07795868813991547\n",
      "13 400 loss: 0.0725010484457016\n",
      "14 0 loss: 0.07203736156225204\n",
      "14 100 loss: 0.07262076437473297\n",
      "14 200 loss: 0.0714549869298935\n",
      "14 300 loss: 0.07632244378328323\n",
      "14 400 loss: 0.07119409739971161\n",
      "15 0 loss: 0.07053513824939728\n",
      "15 100 loss: 0.0712004005908966\n",
      "15 200 loss: 0.07000833749771118\n",
      "15 300 loss: 0.07482288777828217\n",
      "15 400 loss: 0.07000330835580826\n",
      "16 0 loss: 0.0691709965467453\n",
      "16 100 loss: 0.06990877538919449\n",
      "16 200 loss: 0.06867992877960205\n",
      "16 300 loss: 0.07345627248287201\n",
      "16 400 loss: 0.06891745328903198\n",
      "17 0 loss: 0.06791158765554428\n",
      "17 100 loss: 0.06872321665287018\n",
      "17 200 loss: 0.0674705058336258\n",
      "17 300 loss: 0.07219807058572769\n",
      "17 400 loss: 0.06792698800563812\n",
      "18 0 loss: 0.06673573702573776\n",
      "18 100 loss: 0.06762875616550446\n",
      "18 200 loss: 0.06636061519384384\n",
      "18 300 loss: 0.07102148979902267\n",
      "18 400 loss: 0.06701134145259857\n",
      "19 0 loss: 0.06564213335514069\n",
      "19 100 loss: 0.06661330163478851\n",
      "19 200 loss: 0.06533607840538025\n",
      "19 300 loss: 0.06992682069540024\n",
      "19 400 loss: 0.06616182625293732\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load forward.py\n",
    "import  matplotlib\n",
    "from \tmatplotlib import pyplot as plt\n",
    "# Default parameters for plots\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "matplotlib.rcParams['figure.titlesize'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 7]\n",
    "matplotlib.rcParams['font.family'] = ['Noto Sans CJK JP']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False \n",
    "\n",
    "import  tensorflow as tf\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import datasets\n",
    "import  os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# x: [60k, 28, 28],\n",
    "# y: [60k]\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "# x: [0~255] => [0~1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "print(x.shape, y.shape, x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print('batch:', sample[0].shape, sample[1].shape)\n",
    "\n",
    "\n",
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(20): # iterate db for 10\n",
    "    for step, (x, y) in enumerate(train_db): # for every batch\n",
    "        # x:[128, 28, 28]\n",
    "        # y: [128]\n",
    "\n",
    "        # [b, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "\n",
    "        with tf.GradientTape() as tape: # tf.Variable\n",
    "            # x: [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 + b3\n",
    "\n",
    "            # compute loss\n",
    "            # out: [b, 10]\n",
    "            # y: [b] => [b, 10]\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "\n",
    "            # mse = mean(sum(y-out)^2)\n",
    "            # [b, 10]\n",
    "            loss = tf.square(y_onehot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grad\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss:', float(loss))\n",
    "\n",
    "    losses.append(float(loss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses, color='C0', marker='s', label='训练')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylabel('MSE')\n",
    "plt.savefig('forward.svg')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
