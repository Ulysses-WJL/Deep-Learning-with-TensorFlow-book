{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœºå™¨å­¦ä¹ çš„ä¸¤ç§åŸºæœ¬èŒƒå¼: ç›‘ç£å­¦ä¹ (Supervised Learning)å’Œæ— ç›‘ç£å­¦ä¹ (Unsupervised Learning).\n",
    "\n",
    "ä¸¤è€…æœ€ä¸»è¦çš„åŒºåˆ«æ˜¯åœ¨äºæ¨¡å‹åœ¨è®­ç»ƒæ—¶æ˜¯å¦éœ€è¦**äººå·¥æ ‡æ³¨**çš„**æ ‡ç­¾ä¿¡æ¯**ã€‚\n",
    "\n",
    "è‡ªç›‘ç£å­¦ä¹ (Self-Supervised Learning): ç®—æ³•æŠŠæ•°æ®**$x$æœ¬èº«**ä½œä¸ºç›‘ç£ä¿¡å·æ¥å­¦ä¹ . åˆ©ç”¨è¾…åŠ©ä»»åŠ¡ï¼ˆpretextï¼‰ä»å¤§è§„æ¨¡çš„æ— ç›‘ç£æ•°æ®ä¸­æŒ–æ˜è‡ªèº«çš„ç›‘ç£ä¿¡æ¯ï¼Œé€šè¿‡è¿™ç§æ„é€ çš„ç›‘ç£ä¿¡æ¯å¯¹ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œä»è€Œå¯ä»¥å­¦ä¹ åˆ°å¯¹ä¸‹æ¸¸ä»»åŠ¡æœ‰ä»·å€¼çš„è¡¨å¾.\n",
    "\n",
    "\n",
    "[è‡ªç›‘ç£å­¦ä¹ ](https://blog.csdn.net/sdu_hao/article/details/104515917) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªç¼–ç å™¨åŸç†\n",
    "\n",
    "æœ‰ç›‘ç£å­¦ä¹ ä¸­ç¥ç»ç½‘ç»œçš„åŠŸèƒ½å¯ä»¥çœ‹åšæ˜¯ç‰¹ç§é™ç»´(Dimensionality Reduction)çš„è¿‡ç¨‹: $é«˜ç»´è¾“å…¥ç‰¹å¾x \\rightarrow ä½ç»´å˜é‡o$.\n",
    "\n",
    "è‡ªç›‘ç£å­¦ä¹ åˆ©ç”¨æ•°æ®$x$æœ¬èº«ä½œä¸ºç›‘ç£ä¿¡å·æ¥æŒ‡å¯¼ç½‘ç»œçš„è®­ç»ƒï¼Œå³å¸Œæœ›ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°æ˜ å°„$f_{\\theta}: x \\rightarrow \\bar x$. å°†ç½‘ç»œåˆ†æˆä¸¤éƒ¨åˆ†:\n",
    "- $g_{\\theta_1}:x \\rightarrow z$, Encoderç½‘ç»œ: è¾“å…¥$x$æ•°æ®ç¼–ç æˆä½ç»´éšå˜é‡(Latent Variable).\n",
    "- $h_{\\theta_2}:z \\rightarrow \\bar x$, Decoderç½‘ç»œ: ç¼–ç è¿‡åçš„è¾“å…¥$z$è§£ç ä¸ºé«˜ç»´åº¦çš„$\\bar x$\n",
    "æŠŠæ•´ä¸ªæ¨¡å‹$f_{\\theta}$ç§°ä¸ºè‡ªåŠ¨ç¼–ç å™¨(Auto-Encoder)\n",
    "\n",
    "![è‡ªç¼–ç å™¨æ¨¡å‹](è‡ªç¼–ç å™¨æ¨¡å‹.png)\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›è§£ç å™¨çš„è¾“å‡ºèƒ½å¤Ÿå®Œç¾åœ°æˆ–è€…è¿‘ä¼¼é‡å»º(Reconstruct, æˆ–æ¢å¤)å‡ºåŸæ¥çš„è¾“å…¥, å³$\\bar x \\approx x$. ä¼˜åŒ–ç›®æ ‡å¯ä»¥å†™æˆ:\n",
    "$$\n",
    "Minimize L = dist(x, \\bar x) \\\\\n",
    "\\bar x = h_{\\theta_2}(g_{\\theta_1}(x))\n",
    "$$\n",
    "\n",
    "\n",
    "$dist$è·ç¦»åº¦é‡, å¸¸ç”¨æ¬§æ°è·ç¦»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.diag([1, 2, 3, 4, 5, 6])\n",
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(np.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32) / 255. \n",
    "X_test = X_test.astype(np.float32)/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åªéœ€è¦å›¾ç‰‡åŸå§‹æ•°æ® ä¸éœ€è¦æ ‡ç­¾y\n",
    "train_db = tf.data.Dataset.from_tensor_slices((X_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_db.take(1):\n",
    "    print(x.shape)\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_db = train_db.shuffle(10000).batch(BATCH_SIZE)\n",
    "test_db = test_db.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        # 784 -> 20\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(hid_dim)\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(784)\n",
    "        ])\n",
    "    def call(self, inputs, training=None):\n",
    "        hidden = self.encoder(inputs)\n",
    "        x = self.decoder(hidden)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.sigmoid_cross_entropy_with_logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal([4, 10])\n",
    "b = tf.random.normal([4, 10])\n",
    "c = tf.nn.sigmoid_cross_entropy_with_logits(labels=a, logits=b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.categorical_crossentropy(a, b, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z * -log(sigmoid(x)) + (1-z) * -log(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_rec_logist = model(inp)\n",
    "        # æˆ–è€…ç›´æ¥ä½¿ç”¨MSEæŸå¤±\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=inp, logits=x_rec_logist)\n",
    "        loss =tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(images, name):\n",
    "    # 'L': 8-bit pixels, black and white\n",
    "    new_im  = Image.new('L', (280, 280))\n",
    "    index = 0\n",
    "    # 10è¡Œ 10åˆ—  100å¼  = 50 + 50 \n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = images[index] \n",
    "            im = Image.fromarray(im, mode='L')\n",
    "            # å°†å°å›¾ç‰‡å†™å…¥å¯¹åº”ä½ç½®  åˆ—æ–¹å‘æ’å¸ƒ\n",
    "            new_im.paste(im, (i, j))  # (xè½´, yè½´) ä¸€åˆ—\n",
    "            index += 1\n",
    "    new_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './check_point/ae.ckpt'\n",
    "if os.path.exists(os.path.join(save_path, '.index')):\n",
    "    model.load_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        loss = train_step(x)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {step}, Loss {float(loss)}\")\n",
    "    \n",
    "    # æ¯ä¸ªepoch è¿›è¡Œä¸€æ¬¡é‡å»º\n",
    "    x = next(iter(test_db))\n",
    "    logits = model(tf.reshape(x, [-1, 784]))\n",
    "    x_hat = tf.sigmoid(logits)  # å°†è¾“å‡ºè½¬æ¢ä¸º0è‡³1çš„åƒç´ å€¼ï¼Œä½¿ç”¨sigmoid å‡½æ•°\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28])  # æ¢å¤åŸæ¥å½¢çŠ¶\n",
    "    \n",
    "    # åŸå§‹å›¾ç‰‡ + é‡å»ºå›¾ç‰‡ å¯¹æ¯”\n",
    "    x_concat = tf.concat([x[:50], x_hat[:50]], axis=0)\n",
    "    x_concat = x_concat.numpy() * 255  # åƒç´ å€¼æ¢å¤\n",
    "    x_concat = x_concat.astype(np.uint8)\n",
    "    \n",
    "    save_image(x_concat, f\"ae_images/rec_epoch_{epoch}.png\")\n",
    "model.save_weights(save_path)\n",
    "print('Time taken for {} epochs {} sec\\n'.format(EPOCHS, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('ae_images/rec_epoch_99.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªç¼–ç å™¨å˜ç§\n",
    "### Denising Auto-Encoder\n",
    "é˜²æ­¢ç¥ç»ç½‘ç»œè®°å¿†ä½è¾“å…¥æ•°æ®çš„åº•å±‚ç‰¹å¾, ç»™è¾“å…¥æ•°æ®æ·»åŠ éšæœºçš„å™ªå£°æ‰°åŠ¨:\n",
    "$$\n",
    "\\tilde x = x + \\epsilon, \\epsilon \\sim \\mathcal N(0, var)\n",
    "$$\n",
    "\n",
    "### Dropout Auto-Encoder\n",
    "åœ¨ç½‘ç»œå±‚ä¹‹é—´æ’å…¥Dropout å±‚å®ç°ç½‘ç»œè¿æ¥çš„éšå³æ–­å¼€, é˜²æ­¢è¿‡æ‹Ÿåˆ.\n",
    "\n",
    "### Adversarial Auto-Encoder\n",
    "å¯¹æŠ—è‡ªç¼–ç å™¨åˆ©ç”¨é¢å¤–çš„åˆ¤åˆ«å™¨ç½‘ç»œæ¥åˆ¤æ–­é™ç»´çš„éšè—å˜é‡$z$æ˜¯å¦é‡‡æ ·è‡ªå…ˆéªŒåˆ†å¸ƒ$P(z)$, æ–¹ä¾¿åˆ©ç”¨$P(z)$æ¥é‡å»ºè¾“å…¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Auto-Encoder\n",
    "\n",
    "è§†é¢‘æ•™å­¦: https://www.bilibili.com/video/BV15E411w7Pz\n",
    "\n",
    "åŸºæœ¬çš„è‡ªç¼–ç å™¨æ˜¯ä¸€ä¸ªåˆ¤åˆ«æ¨¡å‹, è€Œä¸æ˜¯ç”Ÿæˆæ¨¡å‹. \n",
    "\n",
    "å˜åˆ†è‡ªç¼–ç å™¨(VAE)å¯ä»¥å®ç°ç»™å®šéšè—å˜é‡çš„åˆ†å¸ƒ$P(z)$, é€šè¿‡å­¦ä¹ æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ$P(x|z)$, å¯¹è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(x, z) = P(x|z)P(z)$è¿›è¡Œé‡‡æ ·, ç”Ÿæˆä¸åŒçš„æ ·æœ¬.\n",
    "\n",
    "![VAE](VAE.png)\n",
    "\n",
    "å¯¹æ¯”è‡ªç¼–ç å™¨, VAEæ¨¡å‹å¯¹éšè—å˜é‡$z$çš„åˆ†å¸ƒæœ‰æ˜¾ç¤ºçš„çº¦æŸ, å¸Œæœ›å…¶ç¬¦åˆé¢„è®¾çš„å…ˆéªŒåˆ†å¸ƒ$P(z)$. å› æ­¤ï¼Œåœ¨æŸå¤±å‡½æ•°çš„è®¾è®¡ä¸Šï¼Œé™¤äº†åŸæœ‰çš„é‡å»ºè¯¯å·®é¡¹å¤–ï¼Œè¿˜æ·»åŠ äº†éšå˜é‡ğ’›åˆ†å¸ƒçš„çº¦æŸé¡¹ã€‚\n",
    "\n",
    "æœ€å¤§åŒ–ç›®æ ‡  \n",
    "$$L(\\phi, \\theta) = -D_{KL}(q_{\\phi}(z|x)||p(z)) + E_{z \\sim q}[log p_{\\theta}(x|z)]$$\n",
    "\n",
    "ç”¨ç¼–ç å™¨ç½‘ç»œå‚æ•°åŒ–$q_{\\phi}(z|x)$å‡½æ•°, è§£ç å™¨ç½‘ç»œå‚æ•°åŒ–$p_{\\theta}(x|z)$.\n",
    "\n",
    "ç‰¹åˆ«åœ°, å½“$q_{\\phi}(z|x)$å’Œ$p(z)$éƒ½ä¸º**æ­£æ€åˆ†å¸ƒ**æ—¶, ç¬¬ä¸€é¡¹æ•£åº¦çš„è®¡ç®—å¯ä»¥ç®€åŒ–ä¸º:\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p(z)) = log\\frac {\\sigma_2}{\\sigma_1} + \\frac {\\sigma_1^2 + (\\mu_1-\\mu_2)^2}{x\\sigma_2^2} - \\frac 1 2\n",
    "$$\n",
    "\n",
    "æ›´ç‰¹åˆ«åœ°, å½“$p(z) \\sim \\mathcal N(0, 1)$æ—¶, å³$\\mu_2=0, \\sigma_2=1$\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p(z)) = -log\\sigma_1 + \\frac {\\sigma_1^2 + \\mu_1^2}{2} - \\frac 1 2\n",
    "$$\n",
    "\n",
    "\n",
    "å¤šç»´:\n",
    "$$D_{KL}(q_{\\phi}(z|x)||p(z)) = 0.5*(-log|\\Sigma_1| + tr(\\Sigma_1) + u_1^Tu_1 - D)$$\n",
    "å‡è®¾$\\Sigma_1$æ˜¯ä¸ªå¯¹è§’çŸ©é˜µ(diagonal covariance structure)æ—¶, ç»“æœå’Œä¸Šé¢çš„ç›¸åŒ\n",
    "\n",
    "ä¾¿äºè®¡ç®—, ç¬¬äºŒé¡¹$E_{z \\sim q}[log p_{\\theta}(x|z)]$åŒæ ·å¯ä»¥åŸºäºè‡ªç¼–ç å™¨ä¸­çš„é‡å»ºè¯¯å·®å‡½æ•°å®ç°.\n",
    "\n",
    "VAEæ¨¡å‹çš„ä¼˜åŒ–ç›®æ ‡è½¬æ¢ä¸º:\n",
    "$$\n",
    "min D_{KL}(q_{\\phi}(z|x)||p(z)) \\\\\n",
    "max E_{z \\sim q}[log p_{\\theta}(x|z)]\n",
    "$$\n",
    "\n",
    "è¯¦ç»†æ¨å¯¼è¿‡ç¨‹: [KLæ•£åº¦æ¨å¯¼](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)\n",
    "\n",
    "[ä¸¤ä¸ªå¤šç»´é«˜æ–¯åˆ†å¸ƒçš„Kullback-Leibler divergence(KLæ•£åº¦)](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é‡å‚æ•°æŠ€å·§\n",
    "\n",
    "\n",
    "![](é‡å‚æ•°.png)\n",
    "\n",
    "Reparameterization Trick\n",
    "\n",
    "ç›¸å…³è®ºæ–‡ https://arxiv.org/pdf/1312.6114v10.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = layers.Dense(128)\n",
    "        self.fc2 = layers.Dense(h_dim)\n",
    "        self.fc3 = layers.Dense(h_dim)\n",
    "\n",
    "        self.fc4 = layers.Dense(128)\n",
    "        self.fc5 = layers.Dense(784)\n",
    "   \n",
    "    def encoder(self, x):\n",
    "        # ç¼–ç å™¨\n",
    "        h = tf.nn.relu(self.fc1(x))\n",
    "        # å‡å€¼\n",
    "        mu = self.fc2(h)\n",
    "        # æ–¹å·®\n",
    "        log_var = self.fc3(h)\n",
    "\n",
    "        return mu, log_var\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        # è§£ç å™¨\n",
    "        out = tf.nn.relu(self.fc4(z))\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "    \n",
    "    def reparamentize(self, mu, log_var):\n",
    "        # ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒé‡‡æ ·\n",
    "        eps = tf.random.normal(log_var.shape)\n",
    "        var = tf.exp(log_var * 0.5)\n",
    "        z = mu + var * eps\n",
    "        return z\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        mu, log_var = self.encoder(inputs)\n",
    "\n",
    "        z = self.reparamentize(mu, log_var)\n",
    "\n",
    "        out = self.decoder(z)\n",
    "\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 10\n",
    "vae_model = VAE(h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.build(input_shape=(4, 784))  # tf.random.normal(log_var.shape) éœ€è¦ç¡®å®šçš„shape\n",
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_vae_step(model, inp):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # æ¯ä¸ªæ ·æœ¬çš„mu, sigma éƒ½ä¸åŒ\n",
    "        x_rec_logist, mu, log_var = model(inp)\n",
    "        # é‡å»ºæŸå¤±  [b, 784]\n",
    "        rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=inp, logits=x_rec_logist)\n",
    "        rec_loss = tf.reduce_sum(rec_loss) / inp.shape[0]\n",
    "        # éœ€è¦åŠ ä¸Šçº¦æŸéšå˜é‡z  (b, h_dim)\n",
    "        # log_var = log(sigma ** 2) = 2log(sigma)\n",
    "        kl = 0.5 * (tf.exp(log_var) + mu ** 2 - 1 - log_var)\n",
    "        kl = tf.reduce_sum(kl) / inp.shape[0]\n",
    "        loss = rec_loss + kl * 1.0\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return rec_loss, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        rec_loss, kl = train_vae_step(vae_model, x)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {step}, rec loss {float(rec_loss)}, kl {float(kl)}\")\n",
    "    # ç”Ÿæˆ\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        z = tf.random.normal([100, h_dim])\n",
    "        logits = vae_model.decoder(z)\n",
    "        x = tf.sigmoid(logits)  # 0è‡³1çš„åƒç´ å€¼\n",
    "        img = tf.reshape(x, [-1, 28, 28]).numpy() * 255 # 0-255\n",
    "        img = img.astype(np.uint8)\n",
    "        save_image(img, f'vae_images/gen_image_{epoch}.png')\n",
    "\n",
    "        inp = next(iter(test_db))[:100]\n",
    "        inp = tf.reshape(inp, [-1, 784])\n",
    "        out, _, _ = vae_model(inp)\n",
    "        out = tf.sigmoid(out)  # 0è‡³1çš„åƒç´ å€¼\n",
    "        img = tf.reshape(out, [-1, 28, 28]).numpy() * 255 # 0-255\n",
    "        img = img.astype(np.uint8)\n",
    "        save_image(img, f'vae_images/test_image_{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
