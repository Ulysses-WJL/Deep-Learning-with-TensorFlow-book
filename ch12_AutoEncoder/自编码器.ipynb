{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习的两种基本范式: 监督学习(Supervised Learning)和无监督学习(Unsupervised Learning).\n",
    "\n",
    "两者最主要的区别是在于模型在训练时是否需要**人工标注**的**标签信息**。\n",
    "\n",
    "自监督学习(Self-Supervised Learning): 算法把数据**$x$本身**作为监督信号来学习. 利用辅助任务（pretext）从大规模的无监督数据中挖掘自身的监督信息，通过这种构造的监督信息对网络进行训练，从而可以学习到对下游任务有价值的表征.\n",
    "\n",
    "\n",
    "[自监督学习](https://blog.csdn.net/sdu_hao/article/details/104515917) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自编码器原理\n",
    "\n",
    "有监督学习中神经网络的功能可以看做是特种降维(Dimensionality Reduction)的过程: $高维输入特征x \\rightarrow 低维变量o$.\n",
    "\n",
    "自监督学习利用数据$x$本身作为监督信号来指导网络的训练，即希望神经网络能够学习到映射$f_{\\theta}: x \\rightarrow \\bar x$. 将网络分成两部分:\n",
    "- $g_{\\theta_1}:x \\rightarrow z$, Encoder网络: 输入$x$数据编码成低维隐变量(Latent Variable).\n",
    "- $h_{\\theta_2}:z \\rightarrow \\bar x$, Decoder网络: 编码过后的输入$z$解码为高维度的$\\bar x$\n",
    "把整个模型$f_{\\theta}$称为自动编码器(Auto-Encoder)\n",
    "\n",
    "![自编码器模型](自编码器模型.png)\n",
    "\n",
    "我们希望解码器的输出能够完美地或者近似重建(Reconstruct, 或恢复)出原来的输入, 即$\\bar x \\approx x$. 优化目标可以写成:\n",
    "$$\n",
    "Minimize L = dist(x, \\bar x) \\\\\n",
    "\\bar x = h_{\\theta_2}(g_{\\theta_1}(x))\n",
    "$$\n",
    "\n",
    "\n",
    "$dist$距离度量, 常用欧氏距离."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.diag([1, 2, 3, 4, 5, 6])\n",
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, Sequential, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(np.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32) / 255. \n",
    "X_test = X_test.astype(np.float32)/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只需要图片原始数据 不需要标签y\n",
    "train_db = tf.data.Dataset.from_tensor_slices((X_train))\n",
    "test_db = tf.data.Dataset.from_tensor_slices((X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_db.take(1):\n",
    "    print(x.shape)\n",
    "    plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "train_db = train_db.shuffle(10000).batch(BATCH_SIZE)\n",
    "test_db = test_db.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(Model):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        # 784 -> 20\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(hid_dim)\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(784)\n",
    "        ])\n",
    "    def call(self, inputs, training=None):\n",
    "        hidden = self.encoder(inputs)\n",
    "        x = self.decoder(hidden)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.sigmoid_cross_entropy_with_logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal([4, 10])\n",
    "b = tf.random.normal([4, 10])\n",
    "c = tf.nn.sigmoid_cross_entropy_with_logits(labels=a, logits=b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.losses.categorical_crossentropy(a, b, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z * -log(sigmoid(x)) + (1-z) * -log(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_rec_logist = model(inp)\n",
    "        # 或者直接使用MSE损失\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=inp, logits=x_rec_logist)\n",
    "        loss =tf.reduce_mean(loss)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(images, name):\n",
    "    # 'L': 8-bit pixels, black and white\n",
    "    new_im  = Image.new('L', (280, 280))\n",
    "    index = 0\n",
    "    # 10行 10列  100张 = 50 + 50 \n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = images[index] \n",
    "            im = Image.fromarray(im, mode='L')\n",
    "            # 将小图片写入对应位置  列方向排布\n",
    "            new_im.paste(im, (i, j))  # (x轴, y轴) 一列\n",
    "            index += 1\n",
    "    new_im.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './check_point/ae.ckpt'\n",
    "if os.path.exists(os.path.join(save_path, '.index')):\n",
    "    model.load_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "start = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        loss = train_step(x)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {step}, Loss {float(loss)}\")\n",
    "    \n",
    "    # 每个epoch 进行一次重建\n",
    "    x = next(iter(test_db))\n",
    "    logits = model(tf.reshape(x, [-1, 784]))\n",
    "    x_hat = tf.sigmoid(logits)  # 将输出转换为0至1的像素值，使用sigmoid 函数\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28])  # 恢复原来形状\n",
    "    \n",
    "    # 原始图片 + 重建图片 对比\n",
    "    x_concat = tf.concat([x[:50], x_hat[:50]], axis=0)\n",
    "    x_concat = x_concat.numpy() * 255  # 像素值恢复\n",
    "    x_concat = x_concat.astype(np.uint8)\n",
    "    \n",
    "    save_image(x_concat, f\"ae_images/rec_epoch_{epoch}.png\")\n",
    "model.save_weights(save_path)\n",
    "print('Time taken for {} epochs {} sec\\n'.format(EPOCHS, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('ae_images/rec_epoch_99.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.new?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自编码器变种\n",
    "### Denising Auto-Encoder\n",
    "防止神经网络记忆住输入数据的底层特征, 给输入数据添加随机的噪声扰动:\n",
    "$$\n",
    "\\tilde x = x + \\epsilon, \\epsilon \\sim \\mathcal N(0, var)\n",
    "$$\n",
    "\n",
    "### Dropout Auto-Encoder\n",
    "在网络层之间插入Dropout 层实现网络连接的随即断开, 防止过拟合.\n",
    "\n",
    "### Adversarial Auto-Encoder\n",
    "对抗自编码器利用额外的判别器网络来判断降维的隐藏变量$z$是否采样自先验分布$P(z)$, 方便利用$P(z)$来重建输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Auto-Encoder\n",
    "\n",
    "视频教学: https://www.bilibili.com/video/BV15E411w7Pz\n",
    "\n",
    "基本的自编码器是一个判别模型, 而不是生成模型. \n",
    "\n",
    "变分自编码器(VAE)可以实现给定隐藏变量的分布$P(z)$, 通过学习条件概率分布$P(x|z)$, 对联合概率分布$P(x, z) = P(x|z)P(z)$进行采样, 生成不同的样本.\n",
    "\n",
    "![VAE](VAE.png)\n",
    "\n",
    "对比自编码器, VAE模型对隐藏变量$z$的分布有显示的约束, 希望其符合预设的先验分布$P(z)$. 因此，在损失函数的设计上，除了原有的重建误差项外，还添加了隐变量𝒛分布的约束项。\n",
    "\n",
    "最大化目标  \n",
    "$$L(\\phi, \\theta) = -D_{KL}(q_{\\phi}(z|x)||p(z)) + E_{z \\sim q}[log p_{\\theta}(x|z)]$$\n",
    "\n",
    "用编码器网络参数化$q_{\\phi}(z|x)$函数, 解码器网络参数化$p_{\\theta}(x|z)$.\n",
    "\n",
    "特别地, 当$q_{\\phi}(z|x)$和$p(z)$都为**正态分布**时, 第一项散度的计算可以简化为:\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p(z)) = log\\frac {\\sigma_2}{\\sigma_1} + \\frac {\\sigma_1^2 + (\\mu_1-\\mu_2)^2}{x\\sigma_2^2} - \\frac 1 2\n",
    "$$\n",
    "\n",
    "更特别地, 当$p(z) \\sim \\mathcal N(0, 1)$时, 即$\\mu_2=0, \\sigma_2=1$\n",
    "$$\n",
    "D_{KL}(q_{\\phi}(z|x)||p(z)) = -log\\sigma_1 + \\frac {\\sigma_1^2 + \\mu_1^2}{2} - \\frac 1 2\n",
    "$$\n",
    "\n",
    "\n",
    "多维:\n",
    "$$D_{KL}(q_{\\phi}(z|x)||p(z)) = 0.5*(-log|\\Sigma_1| + tr(\\Sigma_1) + u_1^Tu_1 - D)$$\n",
    "假设$\\Sigma_1$是个对角矩阵(diagonal covariance structure)时, 结果和上面的相同\n",
    "\n",
    "便于计算, 第二项$E_{z \\sim q}[log p_{\\theta}(x|z)]$同样可以基于自编码器中的重建误差函数实现.\n",
    "\n",
    "VAE模型的优化目标转换为:\n",
    "$$\n",
    "min D_{KL}(q_{\\phi}(z|x)||p(z)) \\\\\n",
    "max E_{z \\sim q}[log p_{\\theta}(x|z)]\n",
    "$$\n",
    "\n",
    "详细推导过程: [KL散度推导](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)\n",
    "\n",
    "[两个多维高斯分布的Kullback-Leibler divergence(KL散度)](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重参数技巧\n",
    "\n",
    "\n",
    "![](重参数.png)\n",
    "\n",
    "Reparameterization Trick\n",
    "\n",
    "相关论文 https://arxiv.org/pdf/1312.6114v10.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, h_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = layers.Dense(128)\n",
    "        self.fc2 = layers.Dense(h_dim)\n",
    "        self.fc3 = layers.Dense(h_dim)\n",
    "\n",
    "        self.fc4 = layers.Dense(128)\n",
    "        self.fc5 = layers.Dense(784)\n",
    "   \n",
    "    def encoder(self, x):\n",
    "        # 编码器\n",
    "        h = tf.nn.relu(self.fc1(x))\n",
    "        # 均值\n",
    "        mu = self.fc2(h)\n",
    "        # 方差\n",
    "        log_var = self.fc3(h)\n",
    "\n",
    "        return mu, log_var\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        # 解码器\n",
    "        out = tf.nn.relu(self.fc4(z))\n",
    "        out = self.fc5(out)\n",
    "        return out\n",
    "    \n",
    "    def reparamentize(self, mu, log_var):\n",
    "        # 从标准正态分布采样\n",
    "        eps = tf.random.normal(log_var.shape)\n",
    "        var = tf.exp(log_var * 0.5)\n",
    "        z = mu + var * eps\n",
    "        return z\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        mu, log_var = self.encoder(inputs)\n",
    "\n",
    "        z = self.reparamentize(mu, log_var)\n",
    "\n",
    "        out = self.decoder(z)\n",
    "\n",
    "        return out, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = 10\n",
    "vae_model = VAE(h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.build(input_shape=(4, 784))  # tf.random.normal(log_var.shape) 需要确定的shape\n",
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_vae_step(model, inp):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 每个样本的mu, sigma 都不同\n",
    "        x_rec_logist, mu, log_var = model(inp)\n",
    "        # 重建损失  [b, 784]\n",
    "        rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=inp, logits=x_rec_logist)\n",
    "        rec_loss = tf.reduce_sum(rec_loss) / inp.shape[0]\n",
    "        # 需要加上约束隐变量z  (b, h_dim)\n",
    "        # log_var = log(sigma ** 2) = 2log(sigma)\n",
    "        kl = 0.5 * (tf.exp(log_var) + mu ** 2 - 1 - log_var)\n",
    "        kl = tf.reduce_sum(kl) / inp.shape[0]\n",
    "        loss = rec_loss + kl * 1.0\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return rec_loss, kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "for epoch in range(EPOCHS):\n",
    "    for step, x in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        rec_loss, kl = train_vae_step(vae_model, x)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {step}, rec loss {float(rec_loss)}, kl {float(kl)}\")\n",
    "    # 生成\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        z = tf.random.normal([100, h_dim])\n",
    "        logits = vae_model.decoder(z)\n",
    "        x = tf.sigmoid(logits)  # 0至1的像素值\n",
    "        img = tf.reshape(x, [-1, 28, 28]).numpy() * 255 # 0-255\n",
    "        img = img.astype(np.uint8)\n",
    "        save_image(img, f'vae_images/gen_image_{epoch}.png')\n",
    "\n",
    "        inp = next(iter(test_db))[:100]\n",
    "        inp = tf.reshape(inp, [-1, 784])\n",
    "        out, _, _ = vae_model(inp)\n",
    "        out = tf.sigmoid(out)  # 0至1的像素值\n",
    "        img = tf.reshape(out, [-1, 28, 28]).numpy() * 255 # 0-255\n",
    "        img = img.astype(np.uint8)\n",
    "        save_image(img, f'vae_images/test_image_{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
