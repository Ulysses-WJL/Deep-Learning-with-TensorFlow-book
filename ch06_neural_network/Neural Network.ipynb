{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¥ç»ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„ŸçŸ¥æœº\n",
    "\n",
    "\n",
    "æ„ŸçŸ¥æœºæ¨¡å‹çš„ç»“æ„å¦‚å›¾æ‰€ç¤ºï¼Œå®ƒæ¥å—é•¿åº¦ä¸ºğ‘›çš„ä¸€ç»´å‘é‡$X = [x_1, x_2, â€¦ , x_n]$ï¼Œæ¯ä¸ªè¾“å…¥èŠ‚ç‚¹é€šè¿‡æƒå€¼ä¸º$w_i, i\\in[1, n]$çš„è¿æ¥æ±‡é›†ä¸ºå˜é‡$z$ï¼Œå³ï¼š\n",
    "$$z = w_1x_1 + w_2x_2 + â‹¯ + ğ‘¤_nx_n + b$$\n",
    "å…¶ä¸­ğ‘ç§°ä¸ºæ„ŸçŸ¥æœºçš„åç½®(Bias)ï¼Œä¸€ç»´å‘é‡$w = [w_1, w_2, â€¦ , w_n]$ç§°ä¸ºæ„ŸçŸ¥æœºçš„æƒå€¼(Weight)ï¼Œ$ğ‘§$ç§°ä¸ºæ„ŸçŸ¥æœºçš„å‡€æ´»æ€§å€¼(Net Activation)ã€‚\n",
    "\n",
    "![](./æ„ŸçŸ¥æœº.png)\n",
    "\n",
    "å‘é‡å½¢å¼:\n",
    "$$z = w^Tx + b$$\n",
    "æ„ŸçŸ¥æœºæ˜¯çº¿æ€§æ¨¡å‹ï¼Œå¹¶ä¸èƒ½å¤„ç†çº¿æ€§ä¸å¯åˆ†é—®é¢˜ã€‚é€šè¿‡åœ¨çº¿æ€§æ¨¡å‹åæ·»åŠ æ¿€æ´»å‡½æ•°åå¾—åˆ°æ´»æ€§å€¼(Activation)$\\alpha$:\n",
    "$$\\alpha = \\sigma(z) = \\sigma(w^T + b)$$\n",
    "\n",
    "$\\sigma$æ¿€æ´»å‡½æ•°å¯ä»¥æ˜¯é˜¶è·ƒå‡½æ•°(Step function)æˆ–ç¬¦å·å‡½æ•°(Sign function)\n",
    "\n",
    "æ·»åŠ æ¿€æ´»å‡½æ•°åï¼Œæ„ŸçŸ¥æœºå¯ä»¥ç”¨æ¥å®ŒæˆäºŒåˆ†ç±»ä»»åŠ¡ã€‚é˜¶è·ƒå‡½æ•°å’Œç¬¦å·å‡½æ•°åœ¨ğ‘§ = 0å¤„æ˜¯ä¸è¿ç»­çš„ï¼Œå…¶ä»–ä½ç½®å¯¼æ•°ä¸º 0ï¼Œæ— æ³•åˆ©ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•è¿›è¡Œå‚æ•°ä¼˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å…¨è¿æ¥å±‚\n",
    "\n",
    "![](./å…¨è¿æ¥å±‚.png)\n",
    "\n",
    "æ•´ä¸ªç½‘ç»œå±‚å…³ç³»:\n",
    "$$\n",
    "\\begin{bmatrix} o_1 & o_2\\end{bmatrix} = \n",
    "\\begin{bmatrix} x_1 & x_2 & x_3 \\end{bmatrix} @\n",
    "\\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22} \\\\ w_{31} & w_{32}\\end{bmatrix} +\n",
    "\\begin{bmatrix} b_1 & b_2\\end{bmatrix}\n",
    "$$\n",
    "å³ $$O = X @ W + b$$\n",
    "è¾“å…¥çŸ©é˜µXçš„shapeå®šä¹‰ä¸º$[b, d_{in}]$ï¼Œğ‘ä¸ºæ ·æœ¬æ•°é‡ï¼Œæ­¤å¤„åªæœ‰1ä¸ªæ ·æœ¬å‚ä¸å‰å‘è¿ç®—ï¼Œ$d_{in}$ä¸ºè¾“å…¥èŠ‚ç‚¹æ•°ï¼›æƒå€¼çŸ©é˜µ W çš„ shape å®šä¹‰ä¸º$[d_{in}, d_{out}]$ï¼Œ$ğ‘‘_{out}$ä¸ºè¾“å‡ºèŠ‚ç‚¹æ•°ï¼Œåç½®å‘é‡ bçš„ shape å®šä¹‰ä¸º$[ğ‘‘_{out}]$ã€‚\n",
    "\n",
    "ç”±äºæ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸å…¨éƒ¨çš„è¾“å…¥èŠ‚ç‚¹ç›¸è¿æ¥ï¼Œè¿™ç§ç½‘ç»œå±‚ç§°ä¸º`å…¨è¿æ¥å±‚(Fully-connected Layer)`ï¼Œæˆ–è€…`ç¨ å¯†è¿æ¥å±‚(Dense Layer)`ï¼Œğ‘¾çŸ©é˜µå«åšå…¨è¿æ¥å±‚çš„æƒå€¼çŸ©é˜µï¼Œğ’ƒå‘é‡å«åšå…¨è¿æ¥å±‚çš„åç½®å‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Default parameters for plots\n",
    "matplotlib.rcParams['font.size'] = 20\n",
    "matplotlib.rcParams['figure.titlesize'] = 20\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 7]\n",
    "matplotlib.rcParams['font.family'] = ['Noto Sans CJK JP']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "try:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨å¼ é‡æ–¹å¼å®ç°å…¨å±‚è¿æ¥\n",
    "\n",
    "x = tf.random.normal([2, 784])\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "o1 = x @ w1 + b1\n",
    "o1 = tf.nn.relu(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow layerså±‚æ–¹å¼å®ç°\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "x = tf.random.normal([4, 28 * 28])\n",
    "# åˆ›å»ºå…¨è¿æ¥å±‚ï¼ŒæŒ‡å®šè¾“å‡ºèŠ‚ç‚¹æ•°å’Œæ¿€æ´»å‡½æ•°\n",
    "fc = layers.Dense(256, activation=tf.nn.relu)\n",
    "h1 = fc(x)  # è¾“å…¥çš„èŠ‚ç‚¹æ•°åœ¨fc(x)è®¡ç®—æ—¶è‡ªåŠ¨è·å–\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.kernel  # è·å– Dense ç±»çš„æƒå€¼çŸ©é˜µ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.bias  # è·å– Dense ç±»çš„åç½®å‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.trainable_variables  # è¿”å›å¾…ä¼˜åŒ–å‚æ•°åˆ—è¡¨\n",
    "# fc.non_trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¥ç»ç½‘ç»œ\n",
    "é€šè¿‡å±‚å±‚å †å å…¨è¿æ¥å±‚ï¼Œä¿è¯å‰ä¸€å±‚çš„è¾“å‡ºèŠ‚ç‚¹æ•°ä¸å½“å‰å±‚çš„è¾“å…¥èŠ‚ç‚¹æ•°åŒ¹é…,å³å¯å †å å‡ºä»»æ„å±‚æ•°çš„ç½‘ç»œ-ç¥ç»ç½‘ç»œ\n",
    "\n",
    "![](./ç¥ç»ç½‘ç»œ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([2, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨å¼ é‡å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128]))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 64]))\n",
    "b3 = tf.Variable(tf.zeros([64]))\n",
    "w4 = tf.Variable(tf.random.truncated_normal([64, 10]))\n",
    "b4 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    h1 = x @ w1 + b1\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    h2 = h1 @ w2 + b2\n",
    "    h2 = tf.nn.relu(h2)\n",
    "    h3 = h2 @ w3 + b3\n",
    "    h3 = tf.nn.relu(h3)\n",
    "    out = h3 @ w4 + b4\n",
    "    # loss = ...\n",
    "    # æœ€åä¸€å±‚æ˜¯å¦éœ€è¦æ·»åŠ æ¿€æ´»å‡½æ•°é€šå¸¸è§†å…·ä½“çš„ä»»åŠ¡è€Œå®šï¼Œè¿™é‡ŒåŠ ä¸åŠ éƒ½å¯ä»¥\n",
    "# grads = tape.gradient(loss, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨å±‚æ–¹å¼å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "# éšè—å±‚\n",
    "fc1 = layers.Dense(256, activation=tf.nn.relu)\n",
    "fc2 = layers.Dense(128, activation=tf.nn.relu)\n",
    "fc3 = layers.Dense(64, activation=tf.nn.relu)\n",
    "# è¾“å…¥å±‚\n",
    "fc4 = layers.Dense(10, activation=None)\n",
    "\n",
    "h1 = fc1(x)\n",
    "h2 = fc2(h1)\n",
    "h3 = fc3(h2)\n",
    "out = fc4(h3)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨Sequentialå°è£…\n",
    "model = Sequential([\n",
    "    layers.Dense(256, activation=tf.nn.relu), \n",
    "    layers.Dense(128, activation=tf.nn.relu), \n",
    "    layers.Dense(64, activation=tf.nn.relu), \n",
    "    layers.Dense(10, activation=tf.nn.relu), \n",
    "])\n",
    "out = model(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä¼˜åŒ–ç›®æ ‡\n",
    "æˆ‘ä»¬æŠŠç¥ç»ç½‘ç»œä»è¾“å…¥åˆ°è¾“å‡ºçš„è®¡ç®—è¿‡ç¨‹å«åš`å‰å‘ä¼ æ’­(Forward Propagation)`æˆ–å‰å‘è®¡ç®—ã€‚ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œä¹Ÿæ˜¯æ•°æ®å¼ é‡(Tensor)ä»ç¬¬ä¸€å±‚æµåŠ¨(Flow)è‡³è¾“å‡ºå±‚çš„è¿‡ç¨‹ï¼Œå³ä»è¾“å…¥æ•°æ®å¼€å§‹ï¼Œé€”å¾„æ¯ä¸ªéšè—å±‚ï¼Œç›´è‡³å¾—åˆ°è¾“å‡ºå¹¶è®¡ç®—è¯¯å·®ï¼Œè¿™ä¹Ÿæ˜¯ TensorFlowæ¡†æ¶åå­—ç”±æ¥ã€‚\n",
    "\n",
    "å‰å‘ä¼ æ’­æœ€åä¸€æ­¥, è¯¯å·®è®¡ç®—:\n",
    "\n",
    "$$ L = g(f_{\\theta}(x), y)$$\n",
    "\n",
    "ä¼˜åŒ–ç›®æ ‡:\n",
    "$$\\theta^*= \\mathop{argmin}_{\\theta} g(f_{\\theta}(x), y), x\\in D^{train}$$\n",
    "ä¸€èˆ¬é‡‡ç”¨è¯¯å·®åå‘ä¼ æ’­(Backward Propagationï¼Œç®€ç§° BP)ç®—æ³•æ¥æ±‚è§£ç½‘ç»œå‚æ•°ğœƒçš„æ¢¯åº¦ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨æ¢¯åº¦ä¸‹é™(Gradient Descentï¼Œç®€ç§° GD)ç®—æ³•è¿­ä»£æ›´æ–°å‚æ•°:\n",
    "$$\\theta'= \\theta - \\eta \\cdot \\nabla_{\\theta}L$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å„ç§æ¿€æ´»å‡½æ•°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoidå‡½æ•°\n",
    "\n",
    "ä¹Ÿå«logisticå‡½æ•°:\n",
    "$$ Sigmoid(x) = \\sigma(x)= \\frac {1} {1+e^{-x}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-6., 6, 100)\n",
    "plt.plot(x, tf.nn.sigmoid(x))\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åƒ Dense å±‚ä¸€æ ·å°†ReLU å‡½æ•°ä½œä¸ºä¸€ä¸ªç½‘ç»œå±‚æ·»åŠ åˆ°ç½‘ç»œä¸­\n",
    "# layers.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLUå‡½æ•°(REctified Linear Unitï¼Œä¿®æ­£çº¿æ€§å•å…ƒ)\n",
    "\n",
    "Sigmoid å‡½æ•°åœ¨è¾“å…¥å€¼è¾ƒå¤§æˆ–è¾ƒå°æ—¶å®¹æ˜“å‡ºç°æ¢¯åº¦å€¼æ¥è¿‘äº 0 çš„ç°è±¡ï¼Œç§°ä¸ºæ¢¯åº¦å¼¥æ•£ç°è±¡ã€‚å‡ºç°`æ¢¯åº¦å¼¥æ•£`(æ¢¯åº¦æ¶ˆå¤±)ç°è±¡æ—¶ï¼Œç½‘ç»œå‚æ•°é•¿æ—¶é—´å¾—ä¸åˆ°æ›´æ–°ï¼Œå¯¼è‡´è®­ç»ƒä¸æ”¶æ•›æˆ–åœæ»ä¸åŠ¨çš„ç°è±¡å‘ç”Ÿï¼Œè¾ƒæ·±å±‚æ¬¡çš„ç½‘ç»œæ¨¡å‹ä¸­æ›´å®¹æ˜“å‡ºç°æ¢¯åº¦å¼¥æ•£ç°è±¡.ReLU å¯¹å°äº 0 çš„å€¼å…¨éƒ¨æŠ‘åˆ¶ä¸º 0ï¼›å¯¹äºæ­£æ•°åˆ™ç›´æ¥è¾“å‡ºï¼Œè¿™ç§å•è¾¹æŠ‘åˆ¶ç‰¹æ€§æ¥æºäºç”Ÿç‰©å­¦.\n",
    "$$Relu(x) = max(0, x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-6., 6, 100)\n",
    "plt.plot(x, tf.nn.relu(x))\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU\n",
    "ReLU å‡½æ•°åœ¨ğ‘¥ < 0æ—¶å¯¼æ•°å€¼æ’ä¸º 0ï¼Œä¹Ÿå¯èƒ½ä¼šé€ æˆæ¢¯åº¦å¼¥æ•£ç°è±¡ï¼Œä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼ŒLeakyReLU å‡½æ•°è¢«æå‡º:\n",
    "$$\n",
    "LeakyReLU = \\begin{cases} x \\quad x \\geq 0  \\\\ px \\quad x < 0\\end{cases} \\\\ \n",
    "g(z) = max(pz, z)\n",
    "$$\n",
    "å…¶ä¸­ğ‘ä¸ºç”¨æˆ·è‡ªè¡Œè®¾ç½®çš„æŸè¾ƒå°æ•°å€¼çš„è¶…å‚æ•°ï¼Œå¦‚ 0.02 ç­‰ã€‚å½“ğ‘ = 0æ—¶ï¼ŒLeayReLU å‡½æ•°é€€åŒ–ä¸º ReLU å‡½æ•°ï¼›å½“ğ‘ â‰  0æ—¶ï¼Œğ‘¥< 0å¤„èƒ½å¤Ÿè·å¾—è¾ƒå°çš„å¯¼æ•°å€¼ğ‘ï¼Œä»è€Œé¿å…å‡ºç°æ¢¯åº¦å¼¥æ•£ç°è±¡.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-6., 6, 100)\n",
    "plt.plot(x, tf.nn.leaky_relu(x, alpha=0.1))\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanhå‡½æ•°èƒ½å°†æ•°æ®å‹ç¼©åˆ°(-1, 1)åŒºé—´\n",
    "$$\n",
    "tanh(x) = \\frac {e^x - e^{-x}} {e^x + e^{-x}} = 2 \\cdot sigmoid(2x) - 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-6., 6, 100)\n",
    "# tf.nn.tanh\n",
    "plt.plot(x, tf.tanh(x))\n",
    "ax = plt.gca()\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['right'].set_color('none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SoftPluså‡½æ•°\n",
    "$$\n",
    "f(x) =\\zeta(x) = ln(1+e^x)\n",
    "$$\n",
    "å®ƒæ˜¯ReLUå‡½æ•°çš„å¹³æ»‘ç‰ˆæœ¬, å€¼åŸŸä¸º$(0, +\\infty)$\n",
    "ä¸€äº›å…¶ä»–æ€§è´¨:\n",
    "$$\n",
    "log\\sigma(x) = -\\zeta(-x) \\\\\n",
    "\\frac {d} {dx}\\zeta(x) = \\sigma(x) \\\\\n",
    "\\zeta(x) = \\int_{-\\infty}^x \\sigma(y)dy  \\\\\n",
    "\\zeta(x) - \\zeta(-x) = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-10., 10., 100)\n",
    "plt.plot(x, tf.nn.softplus(x))\n",
    "# ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¾“å‡ºå±‚çš„è®¾è®¡\n",
    "æœ€åä¸€å±‚éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡åœºæ™¯æ¥å†³å®šæ˜¯å¦ä½¿ç”¨æ¿€æ´»å‡½æ•°, ä»¥åŠä½¿ç”¨ä»€ä¹ˆç±»å‹çš„æ¿€æ´»å‡½æ•°ç­‰:\n",
    "\n",
    "1. æ™®é€šå®æ•°ç©ºé—´$o_i \\in R^d$, è¿™ä¸€ç±»é—®é¢˜æ¯”è¾ƒæ™®éï¼Œåƒæ­£å¼¦å‡½æ•°æ›²çº¿é¢„æµ‹ã€å¹´é¾„çš„é¢„æµ‹ã€è‚¡ç¥¨èµ°åŠ¿çš„é¢„æµ‹ç­‰éƒ½å±äºæ•´ä¸ªæˆ–è€…éƒ¨åˆ†è¿ç»­çš„å®æ•°ç©ºé—´ï¼Œè¾“å‡ºå±‚å¯ä»¥ä¸åŠ æ¿€æ´»å‡½æ•°\n",
    "1. $o_i \\in [0, 1]$, è¾“å‡ºå€¼ç‰¹åˆ«åœ°è½åœ¨\\[0, 1\\]çš„åŒºé—´ï¼Œå¦‚å›¾ç‰‡ç”Ÿæˆï¼Œå›¾ç‰‡åƒç´ å€¼ä¸€èˆ¬ç”¨\\[0, 1\\]åŒºé—´çš„å€¼è¡¨ç¤ºï¼›æˆ–è€…äºŒåˆ†ç±»é—®é¢˜çš„æ¦‚ç‡ï¼Œå¦‚ç¡¬å¸æ­£åé¢çš„æ¦‚ç‡é¢„æµ‹é—®é¢˜, è¾“å‡ºå±‚å¯ä»¥åªè®¾ä¸€ä¸ªèŠ‚ç‚¹, è¡¨ç¤ºäº‹ä»¶å‘ç”Ÿçš„æ¦‚ç‡.å¯ä»¥ä½¿ç”¨Sigmoidå‡½æ•°\n",
    "1. $o_i \\in [0, 1]$, ä¸”$\\sum_i o_i = 1$, å¸¸è§çš„å¦‚å¤šåˆ†ç±»é—®é¢˜ï¼Œå¦‚ MNIST æ‰‹å†™æ•°å­—å›¾ç‰‡è¯†åˆ«ï¼Œå›¾ç‰‡å±äº 10 ä¸ªç±»åˆ«çš„æ¦‚ç‡ä¹‹å’Œåº”ä¸º 1ã€‚åœ¨è¾“å‡ºå±‚æ·»åŠ Softmaxå‡½æ•°å®ç°\n",
    "1. $o_i \\in [-1, 1]$, å¯ä»¥ç®€å•çš„ä½¿ç”¨tf.tanhå‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax å‡½æ•°\n",
    "z = tf.constant([2, 1, 0.1])\n",
    "tf.nn.softmax(z)\n",
    "# æ·»åŠ  Softmax å±‚\n",
    "# layers.Softmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ Softmax å‡½æ•°çš„æ•°å€¼è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œå®¹æ˜“å› è¾“å…¥å€¼åå¤§å‘ç”Ÿæ•°å€¼æº¢å‡ºç°è±¡ï¼›åœ¨è®¡ç®—äº¤\n",
    "å‰ç†µæ—¶ï¼Œä¹Ÿä¼šå‡ºç°æ•°å€¼æº¢å‡ºçš„é—®é¢˜ã€‚ä¸ºäº†æ•°å€¼è®¡ç®—çš„ç¨³å®šæ€§ï¼ŒTensorFlow ä¸­æä¾›äº†ä¸€ä¸ªç»Ÿ\n",
    "ä¸€çš„æ¥å£ï¼Œå°† Softmax ä¸äº¤å‰ç†µæŸå¤±å‡½æ•°åŒæ—¶å®ç°ï¼ŒåŒæ—¶ä¹Ÿå¤„ç†äº†æ•°å€¼ä¸ç¨³å®šçš„å¼‚å¸¸ï¼Œä¸€\n",
    "èˆ¬æ¨èä½¿ç”¨è¿™äº›æ¥å£å‡½æ•°ï¼Œé¿å…åˆ†å¼€ä½¿ç”¨ Softmax å‡½æ•°ä¸äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚å‡½æ•°å¼æ¥å£ä¸º\n",
    "`tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False)`ï¼Œå…¶ä¸­ y_true ä»£è¡¨äº†\n",
    "One-hot ç¼–ç åçš„çœŸå®æ ‡ç­¾ï¼Œy_pred è¡¨ç¤ºç½‘ç»œçš„é¢„æµ‹å€¼ï¼Œå½“ from_logits è®¾ç½®ä¸º True æ—¶ï¼Œ\n",
    "y_pred è¡¨ç¤ºé¡»ä¸ºæœªç»è¿‡ Softmax å‡½æ•°çš„å˜é‡ zï¼›å½“ from_logits è®¾ç½®ä¸º False æ—¶ï¼Œy_pred è¡¨ç¤º\n",
    "ä¸ºç»è¿‡ Softmax å‡½æ•°çš„è¾“å‡ºã€‚ä¸ºäº†æ•°å€¼è®¡ç®—ç¨³å®šæ€§ï¼Œä¸€èˆ¬è®¾ç½® from_logits ä¸º Trueï¼Œæ­¤æ—¶\n",
    "tf.keras.losses.categorical_crossentropy å°†åœ¨å†…éƒ¨è¿›è¡Œ Softmax å‡½æ•°è®¡ç®—ï¼Œæ‰€ä»¥ä¸éœ€è¦åœ¨æ¨¡å‹\n",
    "ä¸­æ˜¾å¼è°ƒç”¨ Softmax å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random.normal([2, 10])  # æ¨¡æ‹Ÿè¾“å‡ºå±‚\n",
    "y_onehot = tf.one_hot(tf.constant([1, 3]), depth=10)\n",
    "# æœªè°ƒç”¨softmaxå‡½æ•°æ—¶, è®¾ç½®from_logists=True\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_onehot, z, from_logits=True)\n",
    "loss = tf.reduce_mean(loss)  # è®¡ç®—å¹³å‡äº¤å‰ç†µæŸå¤±\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteon = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = criteon(y_onehot, z)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯¯å·®è®¡ç®—\n",
    "\n",
    "å¸¸è§çš„è¯¯å·®å‡½æ•°æœ‰å‡æ–¹å·®ã€äº¤å‰ç†µã€KL æ•£åº¦ã€Hinge Loss å‡½æ•°ç­‰ï¼Œå…¶ä¸­å‡æ–¹å·®å‡½æ•°å’Œäº¤å‰ç†µå‡½æ•°åœ¨æ·±åº¦å­¦ä¹ ä¸­æ¯”è¾ƒå¸¸è§ï¼Œå‡æ–¹å·®å‡½æ•°ä¸»è¦ç”¨äºå›å½’é—®é¢˜ï¼Œäº¤å‰ç†µå‡½æ•°ä¸»è¦ç”¨äºåˆ†ç±»é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å‡æ–¹å·®(Mean Squared Error, MSE)\n",
    "\n",
    "$$\n",
    "MSE(y, o) = \\frac 1 {d_{out}} \\sum^{d_{out}}_{i=1}(y_i - o_i)^2\n",
    "$$\n",
    "\n",
    "å‡æ–¹å·®è¯¯å·®å‡½æ•°å¹¿æ³›åº”ç”¨åœ¨å›å½’é—®é¢˜ä¸­ï¼Œå®é™…ä¸Šï¼Œåˆ†ç±»é—®é¢˜ä¸­ä¹Ÿå¯ä»¥åº”ç”¨å‡æ–¹å·®è¯¯å·®å‡½æ•°ã€‚åœ¨ TensorFlow ä¸­ï¼Œå¯ä»¥é€šè¿‡å‡½æ•°æ–¹å¼æˆ–å±‚æ–¹å¼å®ç° MSE è¯¯å·®è®¡ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "out = tf.random.normal([2, 10])\n",
    "y_onehot = tf.one_hot(tf.constant([1, 3]), depth=10)\n",
    "loss = keras.losses.mse(y_onehot, out)  # æ¯ä¸ªæ ·æœ¬çš„MSE\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(loss)  # è®¡ç®— batch å‡æ–¹å·®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»¥layerçš„æ–¹å¼å®ç°\n",
    "criterion = keras.losses.MeanSquaredError()\n",
    "loss = criterion(y_onehot, out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### äº¤å‰ç†µè¯¯å·®\n",
    "\n",
    "æŸä¸ªåˆ†å¸ƒP(i)çš„ç†µ(Entropy)å®šä¹‰ä¸º:\n",
    "$$H(P) = -\\sum_iP(i)log_2P(i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ç±»åˆ†ç±»é—®é¢˜, å››ç§ç­‰å¯èƒ½æƒ…å†µæ—¶ ç†µ\n",
    "p = tf.constant([0.25, 0.25, 0.25, 0.25])\n",
    "entropy = tf.reduce_sum(-tf.math.log(p) / tf.math.log([2., 2, 2, 2]) * p )\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "äº¤å‰ç†µ(Cross Entropy):\n",
    "$$H(p||q) = -\\sum_i p(i)log_2q(i)$$\n",
    "é€šè¿‡å˜æ¢ï¼Œäº¤å‰ç†µå¯ä»¥åˆ†è§£ä¸ºğ‘çš„ç†µğ»(ğ‘)å’Œğ‘ä¸ğ‘çš„ KL æ•£åº¦(Kullback-Leibler Divergence)çš„å’Œ\n",
    "$$H(p||q) = H(p) + D_{KL}(p||q)$$\n",
    "KLæ•£åº¦:\n",
    "$$D_{KL}(p||q) = \\sum_i p(i)log(\\frac {p(i)}{q(i)})$$\n",
    "æ˜¯ç”¨äºè¡¡é‡ 2 ä¸ªåˆ†å¸ƒä¹‹é—´è·ç¦»çš„æŒ‡æ ‡.å½“p=qæ—¶,$D_{KL}(p||q)$å–å¾—æœ€å°å€¼, på’Œqä¹‹é—´çš„å·®è·è¶Šå¤§, $D_{KL}(p||q)$ä¹Ÿå°±è¶Šå¤§.\n",
    "\n",
    "éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œäº¤å‰ç†µå’Œ KL æ•£åº¦éƒ½ä¸æ˜¯å¯¹ç§°çš„.  \n",
    "äº¤å‰ç†µå¯ä»¥å¾ˆå¥½åœ°è¡¡é‡ 2 ä¸ªåˆ†å¸ƒä¹‹é—´çš„â€œè·ç¦»â€ã€‚ç‰¹åˆ«åœ°ï¼Œå½“åˆ†ç±»é—®é¢˜ä¸­yçš„ç¼–ç åˆ†å¸ƒğ‘é‡‡ç”¨One-hotç¼–ç ğ’šæ—¶ï¼šğ»(ğ‘) = 0, æ­¤æ—¶\n",
    "$$H(p||q) = H(p) + D_{KL}(p||q)= D_{KL}(p||q)$$\n",
    "æ¨å¯¼åˆ†ç±»é—®é¢˜ä¸­çš„äº¤å‰ç†µçš„è®¡ç®—è¡¨è¾¾å¼:\n",
    "$$ H(p||q) = D_{KL}(p||q) = \\sum_j y_j log(\\frac {y_j} {o_j}) \\\\\n",
    "= 1 \\cdot log\\frac {1}{o_i} + \\sum_{i \\neq j} 0 \\cdot log\\frac {0}{o_j} \\\\\n",
    "= -logo_i\n",
    "$$\n",
    "å…¶ä¸­ğ‘–ä¸º One-hot ç¼–ç ä¸­ä¸º 1 çš„ç´¢å¼•å·ï¼Œä¹Ÿæ˜¯å½“å‰è¾“å…¥çš„çœŸå®ç±»åˆ«ã€‚å¯ä»¥çœ‹åˆ°ï¼Œâ„’åªä¸çœŸå®ç±»åˆ«ğ‘–ä¸Šçš„æ¦‚ç‡$ğ‘œ_ğ‘–$æœ‰å…³ï¼Œå¯¹åº”æ¦‚ç‡$ğ‘œ_ğ‘–$è¶Šå¤§ï¼Œğ»(ğ‘||ğ‘)è¶Šå°ã€‚å½“å¯¹åº”ç±»åˆ«ä¸Šçš„æ¦‚ç‡ä¸º 1 æ—¶ï¼Œäº¤å‰ç†µğ»(ğ‘||ğ‘)å–å¾—æœ€å°å€¼ 0ï¼Œæ­¤æ—¶ç½‘ç»œè¾“å‡ºğ’ä¸çœŸå®æ ‡ç­¾ğ’šå®Œå…¨ä¸€è‡´ï¼Œç¥ç»ç½‘ç»œå–å¾—æœ€ä¼˜çŠ¶æ€.\n",
    "æœ€å°åŒ–äº¤å‰ç†µæŸå¤±å‡½æ•°çš„è¿‡ç¨‹ä¹Ÿæ˜¯æœ€å¤§åŒ–æ­£ç¡®ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡çš„è¿‡ç¨‹."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random.normal([10])  # æ¨¡æ‹Ÿè¾“å‡ºå±‚\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = tf.nn.softmax(z)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-tf.math.log(s1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot = tf.one_hot(tf.constant([1]), depth=10)\n",
    "# è®¡ç®—äº¤å‰ç†µ\n",
    "# æœªè°ƒç”¨softmaxå‡½æ•°æ—¶, è®¾ç½®from_logists=True\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_onehot, z, from_logits=True)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¥ç»ç½‘ç»œç±»å‹\n",
    "\n",
    "- å·ç§¯ç¥ç»ç½‘ç»œ(Convolutional Neural Network, CNN): åº”ç”¨äºè®¡ç®—æœºè§†è§‰, å¦‚å›¾ç‰‡åˆ†ç±»;\n",
    "- å¾ªç¯ç¥ç»ç½‘ç»œ(Recurrent Neural Network, RNN): åºåˆ—ä¿¡å·å¤„ç†, å¦‚ç†è§£æ–‡æœ¬æ•°æ®, NLP;\n",
    "- æ³¨æ„åŠ›(æœºåˆ¶)ç½‘ç»œ(Attention Mechanism): è‡ªç„¶è¯­è¨€å¤„ç†;\n",
    "- å›¾å·ç§¯ç¥ç»ç½‘ç»œ(Graph Convolution Network, GCN): å¤„ç†ç¤¾äº¤ç½‘ç»œã€é€šä¿¡ç½‘ç»œã€è›‹ç™½è´¨åˆ†å­ç»“æ„ç­‰ä¸€ç³»åˆ—çš„ä¸è§„åˆ™ç©ºé—´æ‹“æ‰‘ç»“æ„çš„æ•°æ®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ±½è½¦è€—æ²¹é¡¹ç›®å®æˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨çº¿ä¸‹è½½æ±½è½¦æ•ˆèƒ½æ•°æ®é›†\n",
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \n",
    "\"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ©ç”¨ pandas è¯»å–æ•°æ®é›†ï¼Œå­—æ®µæœ‰æ•ˆèƒ½ï¼ˆå…¬é‡Œæ•°æ¯åŠ ä»‘ï¼‰ï¼Œæ°”ç¼¸æ•°ï¼Œæ’é‡ï¼Œé©¬åŠ›ï¼Œé‡é‡, åŠ é€Ÿåº¦ï¼Œå‹å·å¹´ä»½ï¼Œäº§åœ°\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', \n",
    "    'Acceleration', 'Model Year', 'Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_daraset = pd.read_csv(dataset_path, names=column_names, \n",
    "    na_values='?', comment='\\t', sep=' ', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_daraset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹éƒ¨åˆ†æ•°æ®\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹ NaN\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›´æ¥èˆå¼ƒç¼ºå¤±çš„æ•°æ®\n",
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç±»åˆ«ç±»å‹æ•°æ® # å¤„ç†ç±»åˆ«å‹æ•°æ®ï¼Œå…¶ä¸­originåˆ—ä»£è¡¨äº†ç±»åˆ«1,2,3,åˆ†å¸ƒä»£è¡¨äº§åœ°ï¼šç¾å›½ã€æ¬§æ´²ã€æ—¥æœ¬\n",
    "# å…¶å¼¹å‡ºè¿™ä¸€åˆ—\n",
    "dataset['Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('Origin')\n",
    "dataset['USA'] = (origin == 1) * 1.0\n",
    "dataset['Europe'] = (origin == 2) * 1.0\n",
    "dataset['Japan'] = (origin == 3) * 1.0\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataset.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ’åˆ†æ•°æ®é›† è®­ç»ƒ:æµ‹è¯• = 8:2\n",
    "X_train = dataset.sample(frac=0.8, random_state=0)\n",
    "X_test = dataset.drop(X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(X_train[[\"Cylinders\", \"Displacement\", \"Weight\", \"MPG\"]], \n",
    "diag_kind=\"kde\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPG æ•°æ®ä½œä¸º labels \n",
    "y_train = X_train.pop('MPG')\n",
    "y_test = X_test.pop('MPG')\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è½¬æˆnumpy\n",
    "X_train, X_test = X_train.values, X_test.values\n",
    "y_train, y_test = y_train.values, y_test.values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normal = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normal = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
    "X_test_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_normal.shape, y_train.shape)\n",
    "print(X_test_normal.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºDatasetå¯¹è±¡\n",
    "train_db = tf.data.Dataset.from_tensor_slices((X_train_normal, y_train))\n",
    "train_db = train_db.shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸€ä¸ª3å±‚çš„å›å½’ç½‘ç»œ \n",
    "# è¾“å…¥ğ‘¿çš„ç‰¹å¾å…±æœ‰ 9 ç§ï¼Œå› æ­¤ç¬¬ä¸€å±‚çš„è¾“å…¥èŠ‚ç‚¹æ•°ä¸º 9ã€‚ç¬¬ä¸€å±‚ã€ç¬¬äºŒå±‚çš„\n",
    "# è¾“å‡ºèŠ‚ç‚¹æ•°è®¾è®¡ä¸º64å’Œ64ï¼Œç”±äºåªæœ‰ä¸€ç§é¢„æµ‹å€¼ï¼Œè¾“å‡ºå±‚è¾“å‡ºèŠ‚ç‚¹è®¾è®¡ä¸º 1\n",
    "\n",
    "class Network(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Sequential([\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "        # self.fc1 = layers.Dense(64, activation='relu')\n",
    "        # self.fc2 = layers.Dense(64, activation='relu')\n",
    "        # self.fc3 = layers.Dense(1)\n",
    "    \n",
    "    # åœ¨å‰å‘è®¡ç®—å‡½æ•° call ä¸­å®ç°è‡ªå®šä¹‰ç½‘ç»œç±»çš„è®¡ç®—é€»è¾‘å³å¯\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        out = self.model(inputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()  # \n",
    "# é€šè¿‡ build å‡½æ•°å®Œæˆå†…éƒ¨å¼ é‡çš„åˆ›å»ºï¼Œå…¶ä¸­ 4 ä¸ºä»»æ„è®¾ç½®çš„ batch æ•°é‡ï¼Œ9 ä¸ºè¾“å…¥ç‰¹å¾é•¿åº¦\n",
    "model.build(input_shape=(4, 9))\n",
    "model.summary() # æ‰“å°ç½‘ç»œä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9 * 64 + 64 + 64 * 64 + 64 + 64 * 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(0.001)  # åˆ›å»ºä¼˜åŒ–å™¨, æŒ‡å®šå­¦ä¹ ç‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$mae = \\frac 1{d_{out}} \\sum_i |y_i - o_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae_losses = []\n",
    "train_losses = []\n",
    "test_mae_losses = []\n",
    "for epoch in range(200):\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = model(x)\n",
    "            loss = tf.reduce_mean(losses.MSE(y, out))  # æœ€å°åŒ–çš„ç›®æ ‡MSE \n",
    "            mae_loss = tf.reduce_mean(losses.MAE(y, out))  # MAEç”¨å¹³å‡ç»å¯¹è¯¯å·®\n",
    "        if step % 10 == 0:\n",
    "            print(epoch, step, float(loss))\n",
    "        \n",
    "        # è‡ªåŠ¨è®¡ç®—æ¢¯åº¦\n",
    "        train_losses.append(loss)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # è®°å½•æ¯ä¸ªepoch çš„maeè¯¯å·®\n",
    "    train_mae_losses.append(float(mae_loss))\n",
    "    out = model(X_test_normal)\n",
    "    test_mae_losses.append(tf.reduce_mean(losses.MAE(out, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mae_losses, label='Train')\n",
    "plt.plot(test_mae_losses, label='Test')\n",
    "# plt.ylim(1, 10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}